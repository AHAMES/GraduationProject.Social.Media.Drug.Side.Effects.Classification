{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports necessary for running the program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'df = pd.read_excel(\"MLDataSet.xlsx\")\\ndf2 = pd.read_excel(\"ADRs.xlsx\")\\ndf3 = pd.read_excel(\"DS.xlsx\")\\ndf4 = pd.read_excel(\"Mental.xlsx\")\\n\\ndf5=[df, df2,  df3, df4]\\n\\nresult = pd.concat([df,df2,df3, df4], axis=1, join_axes=[df.index])'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sun May  5 23:01:42 2019\n",
    "\n",
    "@author: Ahmed\n",
    "\"\"\"\n",
    "from openpyxl import load_workbook\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "'''df = pd.read_excel(\"MLDataSet.xlsx\")\n",
    "df2 = pd.read_excel(\"ADRs.xlsx\")\n",
    "df3 = pd.read_excel(\"DS.xlsx\")\n",
    "df4 = pd.read_excel(\"Mental.xlsx\")\n",
    "\n",
    "df5=[df, df2,  df3, df4]\n",
    "\n",
    "result = pd.concat([df,df2,df3, df4], axis=1, join_axes=[df.index])'''\n",
    "#result.to_excel('result.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeColumns(result):\n",
    "    del result['Pain']\n",
    "    del result['Content']\n",
    "    del result['Filtered']\n",
    "    del result['Stemmed']\n",
    "    del result['big1']\n",
    "    del result['big2']\n",
    "    del result['small1']\n",
    "    del result['small2']\n",
    "    del result['Height']\n",
    "    del result['Joined']\n",
    "    del result['Posted']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorizeCount(result):\n",
    "    '''for i in range(len(result)):\n",
    "        if result[i]==0:\n",
    "            result[i]=0\n",
    "        if result[i]>0 and result[i]<=3:\n",
    "            result[i]=1\n",
    "        if result[i]>3:\n",
    "            result[i]=2'''\n",
    "    for i in range(len(result)):\n",
    "        if result.at[i,'MentalCount']==0:\n",
    "            result.at[i,'MentalCount']=0\n",
    "        if result.at[i,'MentalCount']>0 and result.at[i,'MentalCount']<=3:\n",
    "            result.at[i,'MentalCount']=1\n",
    "        if result.at[i,'MentalCount']>3:\n",
    "            result.at[i,'MentalCount']=2\n",
    "            \n",
    "        if result.at[i,'ADRCount']==0:\n",
    "            result.at[i,'ADRCount']=0\n",
    "        if result.at[i,'ADRCount']>0 and result.at[i,'MentalCount']<=3:\n",
    "            result.at[i,'ADRCount']=1\n",
    "        if result.at[i,'ADRCount']>3:\n",
    "            result.at[i,'ADRCount']=2\n",
    "\n",
    "        if result.at[i,'DieaseCount']==0:\n",
    "            result.at[i,'DieaseCount']=0\n",
    "        if result.at[i,'DieaseCount']>0 and result.at[i,'DieaseCount']<=3:\n",
    "            result.at[i,'DieaseCount']=1\n",
    "        if result.at[i,'DieaseCount']>3:\n",
    "            result.at[i,'DieaseCount']=2\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### manipulating data to prepare for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manipulate(result,labelfile,label):\n",
    "    from collections import Counter\n",
    "    imp_mean = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "    result['Gender']=imp_mean.fit_transform(result['Gender'].values.reshape(-1, 1))\n",
    "    for i in range(len(result)):\n",
    "        if result.at[i,'Gender']=='Male':\n",
    "            result.at[i,'Gender']=0\n",
    "        if result.at[i,'Gender']=='Female':\n",
    "            result.at[i,'Gender']=1\n",
    "    \n",
    "    labels=labelfile.iloc[:][label]\n",
    "    print(Counter(labels))\n",
    "    labels=LabelEncoder().fit_transform(labels)\n",
    "    if 'Unnamed: 0' in result:\n",
    "        del result['Unnamed: 0'] \n",
    "    #removeColumns(result)\n",
    "    imp_mean = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "    result['Age']=imp_mean.fit_transform(result['Age'].values.reshape(-1, 1))\n",
    "    if 'Height' in result:\n",
    "        result['Height']=imp_mean.fit_transform(result['Height'].values.reshape(-1, 1))\n",
    "    result=vectorizeCount(result)\n",
    "    return result,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#asklabel=pd.read_excel('asklabels.xlsx')\n",
    "#labels=asklabel.iloc[:]['MICROCEPHALY , EPILEPSY , AND DIABETES SYNDROME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def SMOTE(begin,columns):\n",
    "    from imblearn.over_sampling import SMOTENC\n",
    "    x=[1]\n",
    "    x.extend(list(range(begin,len(columns))))\n",
    "    sm=SMOTENC(random_state=42, categorical_features=x)\n",
    "    return sm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label='ADRCount'\n",
    "asklabel='ADRCount'\n",
    "\n",
    "#from collections import Counter\n",
    "#X_res, y_res = sm.fit_resample(result, result_labels)\n",
    "#print(Counter(result_labels))\n",
    "#print(Counter(y_res))\n",
    "def prepareDataset(label,asklab):\n",
    "    from imblearn.over_sampling import SMOTENC\n",
    "    \n",
    "    \n",
    "    \n",
    "    result=pd.read_excel('result_reduced.xlsx')\n",
    "    weighted=pd.read_excel('Weighted_reduced.xlsx')\n",
    "    blood=pd.read_excel('blood_reduced.xlsx')\n",
    "    ask=pd.read_excel('askapatient_reduced.xlsx')\n",
    "\n",
    "    resultlabel=pd.read_excel('resultlabels.xlsx')\n",
    "    weightedlabel=pd.read_excel('Weightedlabels.xlsx')\n",
    "    bloodlabel=pd.read_excel('bloodlabels.xlsx')\n",
    "    asklabel=pd.read_excel('asklabels.xlsx')\n",
    "\n",
    "    result,result_labels=manipulate(result,resultlabel,label)\n",
    "    weighted,weighted_labels=manipulate(weighted,weightedlabel,label)\n",
    "    blood,blood_labels=manipulate(blood,bloodlabel,label)\n",
    "    ask,ask_labels=manipulate(ask,asklabel,asklab)\n",
    "    del result['weights2']\n",
    "    del result['Height']\n",
    "    \n",
    "    sm1 = SMOTE(2,result.columns)\n",
    "    sm2 = SMOTE(4,weighted.columns)\n",
    "    sm3 = SMOTE(4,blood.columns)\n",
    "    sm4 = SMOTE(2,ask.columns)\n",
    "    #Applying SMOTENC\n",
    "    result,result_labels=sm1.fit_resample(result,result_labels)\n",
    "    weighted,weighted_labels=sm2.fit_resample(weighted,weighted_labels)\n",
    "    blood,blood_labels=sm3.fit_resample(blood,blood_labels)\n",
    "    ask,ask_labels=sm4.fit_resample(ask,ask_labels)\n",
    "    return result,result_labels,weighted,weighted_labels,blood,blood_labels,ask,ask_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label='ADRCount'\n",
    "asklabel='ADRCount'\n",
    "\n",
    "#from collections import Counter\n",
    "#X_res, y_res = sm.fit_resample(result, result_labels)\n",
    "#print(Counter(result_labels))\n",
    "#print(Counter(y_res))\n",
    "def prepareDatasetNoSmote(label,asklab):\n",
    "    \n",
    "    result=pd.read_excel('result_reduced.xlsx')\n",
    "    weighted=pd.read_excel('Weighted_reduced.xlsx')\n",
    "    blood=pd.read_excel('blood_reduced.xlsx')\n",
    "    ask=pd.read_excel('askapatient_reduced.xlsx')\n",
    "\n",
    "    resultlabel=pd.read_excel('resultlabels.xlsx')\n",
    "    weightedlabel=pd.read_excel('Weightedlabels.xlsx')\n",
    "    bloodlabel=pd.read_excel('bloodlabels.xlsx')\n",
    "    asklabel=pd.read_excel('asklabels.xlsx')\n",
    "\n",
    "    result,result_labels=manipulate(result,resultlabel,label)\n",
    "    weighted,weighted_labels=manipulate(weighted,weightedlabel,label)\n",
    "    blood,blood_labels=manipulate(blood,bloodlabel,label)\n",
    "    ask,ask_labels=manipulate(ask,asklabel,asklab)\n",
    "    if 'Count' in label:\n",
    "        result_labels = vectorizeCount(result_labels)\n",
    "        weighted_labels = vectorizeCount(weighted_labels)\n",
    "        blood_labels=vectorizeCount(blood_labels)\n",
    "    if 'Count' in asklab:\n",
    "        ask_labels = vectorizeCount(ask_labels)\n",
    "    del result['weights2']\n",
    "    del result['Height']\n",
    "    \n",
    "    \n",
    "    #Applying SMOTENC\n",
    "    #result,result_labels=sm.fit_resample(result,result_labels)\n",
    "    #weighted,weighted_labels=sm.fit_resample(weighted,weighted_labels)\n",
    "    #blood,blood_labels=sm.fit_resample(blood,blood_labels)\n",
    "    #ask,ask_labels=sm.fit_resample(ask,ask_labels)\n",
    "    return result,result_labels,weighted,weighted_labels,blood,blood_labels,ask,ask_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"for i in weighted:\\n    if i not in result:\\n        if i != 'weights2':\\n            del weighted[i]\\nweighted.to_excel('Weighted.xlsx')\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''for i in weighted:\n",
    "    if i not in result:\n",
    "        if i != 'weights2':\n",
    "            del weighted[i]\n",
    "weighted.to_excel('Weighted.xlsx')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ask_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for i in weighted:\\n    print (weighted[i])'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''for i in weighted:\n",
    "    print (weighted[i])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(model, X_train,X_test,Y_train,Y_test):\n",
    "    model.fit(X_train,Y_train)\n",
    "    return model.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10-Fold Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.model_selection import cross_val_score\\nfrom sklearn.model_selection import cross_val_fscore\\nnp.average( cross_val_score(RandomForestClassifier(n_estimators=200),result,result_labels,cv=50))'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_fscore\n",
    "np.average( cross_val_score(RandomForestClassifier(n_estimators=200),result,result_labels,cv=50))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This was used for some other no longer existing purposes\n",
    "def getMissingPercentage(feature):\n",
    "    #nancount = int(result[result[feature].isnull()][feature].shape[0])\n",
    "    nancount = int(result[result[feature]==1][feature].shape[0])\n",
    "    size=int(result.shape[0])\n",
    "    print (nancount)\n",
    "    print ((nancount*100)/size)\n",
    "#getMissingPercentage('Pvc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importance(result,result_labels):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.feature_selection import SelectFromModel\n",
    "    from collections import Counter\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(result, result_labels, test_size=0.30, random_state=42)\n",
    "    X_train, X_test, Y_train, Y_test = pd.DataFrame(X_train),pd.DataFrame(X_test),pd.DataFrame(Y_train),pd.DataFrame(Y_test),\n",
    "    #print(Counter(result_labels))\n",
    "    sel = SelectFromModel(RandomForestClassifier(n_estimators = 500))\n",
    "    sel.fit(X_train, Y_train)\n",
    "    #print(sel.get_support())\n",
    "    selected_feat= X_train.columns[(sel.get_support())]\n",
    "    \n",
    "    #print(len(selected_feat))\n",
    "    print(selected_feat)\n",
    "\n",
    "\n",
    "    return selected_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Atenolol': 620, 'Lisinopril': 428, 'Amlodipine': 161, 'Hydrochlorothiazide': 129, 'Nadolol': 119, 'Diltiazem': 100})\n",
      "Counter({'Lisinopril': 51, 'Atenolol': 45, 'Amlodipine': 14, 'Hydrochlorothiazide': 13})\n",
      "Counter({'Atenolol': 186, 'Lisinopril': 134, 'Amlodipine': 63, 'Hydrochlorothiazide': 51, 'Diltiazem': 26})\n",
      "Counter({'Lisinopril': 622, 'Atenolol': 134})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-23ec9e50c250>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mresult_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweighted\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweighted_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mblood\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mblood_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mask_labels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprepareDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0masklabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mres_feat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimportance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mresult_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mwei_feat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimportance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweighted\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweighted_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mblood_feat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimportance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblood\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mblood_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-31-069745e12de4>\u001b[0m in \u001b[0;36mimportance\u001b[1;34m(result, result_labels)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;31m#print(len(selected_feat))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mselected_feat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "'''label='Drug'\n",
    "asklabel='Drug'\n",
    "\n",
    "result,result_labels,weighted,weighted_labels,blood,blood_labels,ask,ask_labels=prepareDataset(label,asklabel)\n",
    "res_feat=importance(result,result_labels)\n",
    "wei_feat=importance(weighted,weighted_labels)\n",
    "blood_feat=importance(blood,blood_labels)\n",
    "ask_feat=importance(ask,ask_labels)'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotResult(name,max_res,max_wei,max_bld,max_ask,x1,x2,x3,x4):\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    fig, ax = plt.subplots()\n",
    "    width = 0.2\n",
    "\n",
    "    acc_m = (max_res['Accuracy'][x1],max_wei['Accuracy'][x2],max_bld['Accuracy'][x3],max_ask['Accuracy'][x4])\n",
    "    pre_m = (max_res['Precision'][x1],max_wei['Precision'][x2],max_bld['Precision'][x3],max_ask['Precision'][x4])\n",
    "    rec_m = (max_res['Recall'][x1],max_wei['Recall'][x2],max_bld['Recall'][x3],max_ask['Recall'][x4])\n",
    "    fse_m = (max_res['FScore'][x1],max_wei['FScore'][x2],max_bld['FScore'][x3],max_ask['FScore'][x4])\n",
    "\n",
    "    ind = np.arange(len(acc_m)) \n",
    "    old_ind =  ind\n",
    "    rects1 = ax.bar(ind,acc_m, width=width ,label='accuracy')\n",
    "    ind = ind + width\n",
    "    rects2 = ax.bar(ind,pre_m, width=width,label='Precision')\n",
    "    ind = ind + width\n",
    "    rects3 = ax.bar(ind,rec_m, width=width,label='recall')\n",
    "    ind = ind + width\n",
    "    rects4 = ax.bar(ind,fse_m, width=width ,label='fscore')\n",
    "\n",
    "\n",
    "    # Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "    ax.set_ylabel('Scores')\n",
    "    ax.set_title(name)\n",
    "    ax.set_xticks(old_ind+ width *2)\n",
    "    ax.set_xticklabels(('complete', 'weighted', 'pressure', 'ask'))\n",
    "    box = ax.get_position()\n",
    "    ax.set_position([box.x0, box.y0,box.width, box.height * 0.6])\n",
    "    ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05), fancybox=True,shadow=True, ncol=4)\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(weighted)[wei_feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from sklearn.model_selection import KFold\\nfrom sklearn.ensemble import RandomForestClassifier\\nkf = KFold(n_splits=10)\\n\\nscores_rf=[]\\n\\nfor train_index, test_index in kf.split(result):\\n    X_train, X_test, Y_train, Y_test = result.iloc[train_index], result.iloc[test_index], result_labels.iloc[train_index],result_labels.iloc[test_index]\\n    scores_rf.append(get_score(RandomForestClassifier(n_estimators=400),X_train, X_test, Y_train, Y_test))'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "kf = KFold(n_splits=10)\n",
    "\n",
    "scores_rf=[]\n",
    "\n",
    "for train_index, test_index in kf.split(result):\n",
    "    X_train, X_test, Y_train, Y_test = result.iloc[train_index], result.iloc[test_index], result_labels.iloc[train_index],result_labels.iloc[test_index]\n",
    "    scores_rf.append(get_score(RandomForestClassifier(n_estimators=400),X_train, X_test, Y_train, Y_test))'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomForest(result,result_labels,estimators,DataSet):\n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn.metrics import f1_score\n",
    "    from collections import Counter\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(result, result_labels, test_size=0.30, random_state=42)\n",
    "    print(Counter(result_labels))\n",
    "    clf = RandomForestClassifier(n_estimators=estimators,random_state=0)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    pred=clf.predict(X_test)\n",
    "    accuracy=(accuracy_score(Y_test, pred))\n",
    "    #print (accuracy)\n",
    "    scores_rf=(precision_recall_fscore_support(Y_test,pred, average='macro'))\n",
    "    #print(DataSet)\n",
    "    #print (pred)\n",
    "    #print(classification_report(Y_test,pred,labels=[0,1,2]))\n",
    "        \n",
    "    return accuracy,scores_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest With Smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Atenolol': 620, 'Lisinopril': 428, 'Amlodipine': 161, 'Hydrochlorothiazide': 129, 'Nadolol': 119, 'Diltiazem': 100})\n",
      "Counter({'Lisinopril': 51, 'Atenolol': 45, 'Amlodipine': 14, 'Hydrochlorothiazide': 13})\n",
      "Counter({'Atenolol': 186, 'Lisinopril': 134, 'Amlodipine': 63, 'Hydrochlorothiazide': 51, 'Diltiazem': 26})\n",
      "Counter({'Lisinopril': 622, 'Atenolol': 134})\n",
      "100\n",
      "Counter({0: 620, 2: 620, 3: 620, 1: 620, 4: 620, 5: 620})\n",
      "Counter({0: 51, 2: 51, 1: 51, 3: 51})\n",
      "Counter({0: 186, 2: 186, 3: 186, 1: 186, 4: 186})\n",
      "Counter({1: 622, 0: 622})\n",
      "Res: Accuracy: 0.532258064516129 # Scores: (0.5274187051505063, 0.5336865809113508, 0.5294807132566177, None)\n",
      "Wei: Accuracy: 0.6129032258064516 # Scores: (0.6031746031746033, 0.614390756302521, 0.6046644088669951, None)\n",
      "Bld: Accuracy: 0.6164874551971327 # Scores: (0.607253837684224, 0.6197660818713451, 0.6115274728278199, None)\n",
      "Ask: Accuracy: 0.7994652406417112 # Scores: (0.8002863688430699, 0.8000028609847509, 0.799452336862877, None)\n",
      "200\n",
      "Counter({0: 620, 2: 620, 3: 620, 1: 620, 4: 620, 5: 620})\n",
      "Counter({0: 51, 2: 51, 1: 51, 3: 51})\n",
      "Counter({0: 186, 2: 186, 3: 186, 1: 186, 4: 186})\n",
      "Counter({1: 622, 0: 622})\n",
      "Res: Accuracy: 0.5340501792114696 # Scores: (0.5303707928700613, 0.5353757873064396, 0.5320690977741045, None)\n",
      "Wei: Accuracy: 0.6290322580645161 # Scores: (0.6081688596491228, 0.6290966386554622, 0.6158730158730159, None)\n",
      "Bld: Accuracy: 0.6164874551971327 # Scores: (0.6094177253478524, 0.6194980506822612, 0.6122195095412661, None)\n",
      "Ask: Accuracy: 0.7994652406417112 # Scores: (0.8002863688430699, 0.8000028609847509, 0.799452336862877, None)\n",
      "300\n",
      "Counter({0: 620, 2: 620, 3: 620, 1: 620, 4: 620, 5: 620})\n",
      "Counter({0: 51, 2: 51, 1: 51, 3: 51})\n",
      "Counter({0: 186, 2: 186, 3: 186, 1: 186, 4: 186})\n",
      "Counter({1: 622, 0: 622})\n",
      "Res: Accuracy: 0.5331541218637993 # Scores: (0.5291276967294495, 0.5344568139705203, 0.5309475549532743, None)\n",
      "Wei: Accuracy: 0.6290322580645161 # Scores: (0.6141825151113077, 0.6290966386554622, 0.6179308579197345, None)\n",
      "Bld: Accuracy: 0.5985663082437276 # Scores: (0.5872403549166335, 0.6018957115009747, 0.5919231597721487, None)\n",
      "Ask: Accuracy: 0.8021390374331551 # Scores: (0.8031514109726401, 0.8027351014219095, 0.8021164021164022, None)\n",
      "400\n",
      "Counter({0: 620, 2: 620, 3: 620, 1: 620, 4: 620, 5: 620})\n",
      "Counter({0: 51, 2: 51, 1: 51, 3: 51})\n",
      "Counter({0: 186, 2: 186, 3: 186, 1: 186, 4: 186})\n",
      "Counter({1: 622, 0: 622})\n",
      "Res: Accuracy: 0.532258064516129 # Scores: (0.5289172841544307, 0.5334947977143863, 0.5303965270858592, None)\n",
      "Wei: Accuracy: 0.6290322580645161 # Scores: (0.6141825151113077, 0.6290966386554622, 0.6179308579197345, None)\n",
      "Bld: Accuracy: 0.6021505376344086 # Scores: (0.5913249659577662, 0.6048586744639376, 0.5959044649478454, None)\n",
      "Ask: Accuracy: 0.8021390374331551 # Scores: (0.8031514109726401, 0.8027351014219095, 0.8021164021164022, None)\n",
      "500\n",
      "Counter({0: 620, 2: 620, 3: 620, 1: 620, 4: 620, 5: 620})\n",
      "Counter({0: 51, 2: 51, 1: 51, 3: 51})\n",
      "Counter({0: 186, 2: 186, 3: 186, 1: 186, 4: 186})\n",
      "Counter({1: 622, 0: 622})\n",
      "Res: Accuracy: 0.5313620071684588 # Scores: (0.5276227064954385, 0.5326131674209913, 0.5292936091686798, None)\n",
      "Wei: Accuracy: 0.6290322580645161 # Scores: (0.6141825151113077, 0.6290966386554622, 0.6179308579197345, None)\n",
      "Bld: Accuracy: 0.6093189964157706 # Scores: (0.6006721606275576, 0.6129239766081871, 0.6045676360440098, None)\n",
      "Ask: Accuracy: 0.8021390374331551 # Scores: (0.8031514109726401, 0.8027351014219095, 0.8021164021164022, None)\n",
      "600\n",
      "Counter({0: 620, 2: 620, 3: 620, 1: 620, 4: 620, 5: 620})\n",
      "Counter({0: 51, 2: 51, 1: 51, 3: 51})\n",
      "Counter({0: 186, 2: 186, 3: 186, 1: 186, 4: 186})\n",
      "Counter({1: 622, 0: 622})\n",
      "Res: Accuracy: 0.5286738351254481 # Scores: (0.5243430797946146, 0.529933674759881, 0.5261579777120314, None)\n",
      "Wei: Accuracy: 0.6290322580645161 # Scores: (0.6141825151113077, 0.6290966386554622, 0.6179308579197345, None)\n",
      "Bld: Accuracy: 0.6093189964157706 # Scores: (0.6012027788109027, 0.6124610136452241, 0.6044321683382099, None)\n",
      "Ask: Accuracy: 0.8021390374331551 # Scores: (0.8031514109726401, 0.8027351014219095, 0.8021164021164022, None)\n",
      "700\n",
      "Counter({0: 620, 2: 620, 3: 620, 1: 620, 4: 620, 5: 620})\n",
      "Counter({0: 51, 2: 51, 1: 51, 3: 51})\n",
      "Counter({0: 186, 2: 186, 3: 186, 1: 186, 4: 186})\n",
      "Counter({1: 622, 0: 622})\n",
      "Res: Accuracy: 0.5268817204301075 # Scores: (0.5221897900856577, 0.528141508261832, 0.5241015901801785, None)\n",
      "Wei: Accuracy: 0.6290322580645161 # Scores: (0.6141825151113077, 0.6290966386554622, 0.6179308579197345, None)\n",
      "Bld: Accuracy: 0.6200716845878136 # Scores: (0.6122991304442137, 0.6236647173489278, 0.6150964196437417, None)\n",
      "Ask: Accuracy: 0.8021390374331551 # Scores: (0.8031514109726401, 0.8027351014219095, 0.8021164021164022, None)\n",
      "800\n",
      "Counter({0: 620, 2: 620, 3: 620, 1: 620, 4: 620, 5: 620})\n",
      "Counter({0: 51, 2: 51, 1: 51, 3: 51})\n",
      "Counter({0: 186, 2: 186, 3: 186, 1: 186, 4: 186})\n",
      "Counter({1: 622, 0: 622})\n",
      "Res: Accuracy: 0.5277777777777778 # Scores: (0.5232569567030685, 0.5290327738589801, 0.5251065779947764, None)\n",
      "Wei: Accuracy: 0.6290322580645161 # Scores: (0.6141825151113077, 0.6290966386554622, 0.6179308579197345, None)\n",
      "Bld: Accuracy: 0.6200716845878136 # Scores: (0.6143058076225045, 0.6240350877192983, 0.6164030086783948, None)\n",
      "Ask: Accuracy: 0.8021390374331551 # Scores: (0.8031514109726401, 0.8027351014219095, 0.8021164021164022, None)\n",
      "900\n",
      "Counter({0: 620, 2: 620, 3: 620, 1: 620, 4: 620, 5: 620})\n",
      "Counter({0: 51, 2: 51, 1: 51, 3: 51})\n",
      "Counter({0: 186, 2: 186, 3: 186, 1: 186, 4: 186})\n",
      "Counter({1: 622, 0: 622})\n",
      "Res: Accuracy: 0.5259856630824373 # Scores: (0.5211607584692192, 0.5272502426646841, 0.5230874401122513, None)\n",
      "Wei: Accuracy: 0.6290322580645161 # Scores: (0.6141825151113077, 0.6290966386554622, 0.6179308579197345, None)\n",
      "Bld: Accuracy: 0.6129032258064516 # Scores: (0.6050995458600276, 0.6166276803118909, 0.6082058447071086, None)\n",
      "Ask: Accuracy: 0.8021390374331551 # Scores: (0.8031514109726401, 0.8027351014219095, 0.8021164021164022, None)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEuCAYAAADbW4YFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XucVXW9//HXeyBQvKDmZFyFU6Sg3AdDScVUwjQ0ipT4lfKz/Pkz9PyyUjLjqNXvV2ZpFmZ0jmGY4u3YocIbHvEWKlAkcpUQhQOnMOTmDXE+vz/WmnEx7BkGnDWzNvN+Ph77Mevy3d/12d+1Z3/297vWXksRgZmZWdFUtHQAZmZmpThBmZlZITlBmZlZITlBmZlZITlBmZlZITlBmZlZITlBWasmaZWkU1o6jnIkaZykhxpYP1zSmuaMyfYuTlBWK/2wfkPSFkkbJf1R0oWSmu19IukqSW9L2pqJ4djm2n5eJE2VtC19XTWPs5s5hgaTsaRlkj6XmR8mKUos2yqpbUT8JiJGZNaFpA+/h/iOkvSQpFfTfT9f0if3tL4GtuPEWSacoKyuT0XEAcDhwPeBy4F/q6+wpDY5xHBnROwPHAo8CtydwzZawrURsX/mcefuVpBTe9d4HDgxM38CsLTEsj9GxPYctv874GHgMOADwCXA5hy2Y2XCCcpKiohNETEDOBs4V9LRUNsT+LmkmZJeA06SNFvSl2qeK+k8SU9m5kek3843SbpJ0mPZ8g3EsB34DdBFUmVa18GSfi9pffpN+/eSuma2NVvSdyQ9lfYEH5J0aGb9FyS9JOkfkr6V3Z6k9pJukLQ2fdwgqX26brikNZIuk/R3SesknSXpk5KWS9og6Yo9aWtJvdO4N0paJGlUZl2p9m4v6TpJL0v6m6SbJe2blj80bZONaUxPSKqQNA3oDvwu7QFdViKUx0kSUI3jgR+UWPZ4uq3a/Szp8XT9X+r2DiV9LdNm4+tpg0OBnsAvI2Jb+ngqImrq3632r29fStoPuB/onOnJdk7baKKkv6bvjbskHdKI3Wc5coKyBkXEs8Aakg+mGp8HvgccADxZ6nk10g+ee4BvAu8HlgHHNWbbktoBXwT+AbyaLq4AfkXSw+sOvAH8rM5TPw+MJ/kW3g74elpfH+DnwBeAzmk8XTPP+xYwFBgA9AeOAa7MrP8gsA/QBZgE/BL4H8BgkvaZJOmfGvPaMq/xfSQ9h4fSeC8GfiPpiDqvJ9vePwA+ksb54Uw8AF8j2V+VJD2RK4CIiC8AL5P0kPePiGtLhPMYcJSkQ5QM61YBdwIHZZYdR5qgsiKiJon1r9M7/CDQMY3xfGCypINLbPsfwArgtjTxHFaizO60f8l9GRGvAacBazM92bUkvbWzSHqLnUneb5NLxGDNKSL88IOIAFgFnFJi+dPAt9LpqcCv66yfDXwpM38e8GQ6/UVgTmadgNXZ8nXqugrYBmwE3iH54BreQMwDgFfrxHJlZv4i4IF0ehIwPbNuv3Rbp6TzfwU+mVn/CWBVOj2cJBm2SecPAAL4aKb8fOCseuKcCryZvq6NwCvp8uOB/wYqMmXvAK4q1d5p+70GfCiz7FjgxXT6GuA/gA83dv+WKHMmMBB4Kl02PbPsTaB93f2czkd2u5k2a5tZ9ndgaD3b7kryZeOvQDVJIuy1J+3fiH25ps62lwAnZ+Y7AW9nY/ej+R/uQVljdAE2ZOZX78ZzO2fLR/Lfv6sD1HdFxEEkPYDnSb4hAyCpg6RfpMN0m0k+xA7Sjsdm/jsz/Tqwfz2xvEaSALOxvpSZfyldVuMfEfFOOv1G+vdvmfVvZLZVynURcVD6qBl27AysjojqOtvtkpnPtncl0AGYnw7jbQQeSJcD/JCkJ/KQpJWSJjYQTyk1w3wnAE+ky57MLHsmIt7ajfr+ETser8rujx1ExJqImBARHyLpIb8G/LpOXY1t/13ty7oOB+7LtOkSki9IpXpy1kycoKxBkoaQfFhmh/LqXgL/NZIPzRofzEyvIzOMJknsOKxWr4h4BfhfwFWSOqWLvwYcQfLN+UDePT6iRlS5DuiWiaUDyTBfjbUkH1Q1uqfL8rQW6KYdz5TsDvxXZj7b3q+QfBAflUl2HSM5qYSI2BIRX4uIfwI+BVwq6eQS9dSnJkEdz7sJ6onMsp2G9/IQEatJhtiO3sMqGtqXpdphNXBapk0Pioh9IuK/SpS1ZuIEZSVJOlDSGSTDO7dFxMIGii8ARqe9mw+THGuo8Qegb3pcoS3wFXZMYA2KiKXAg0DNQf0DSD6gN6YHsf+l0S8qORZ2hqSPpce3rmHH/4E7gCslVabHziYBt+1G/XviGZIEf5mk90kaTpJYppcqnPa0fglcL+kDAJK6SPpEOn2GpA+nXwQ2k/QCanodfwN2dYzscZKhvBOBp9JlC0lOYDiJhhNUY+ovScnJL1ensVek7f8/SYaX90RD+/JvwPsldcyUvxn4nqTD03gqJZ25h9u2JuIEZXX9TtIWkm+U3wJ+THLCQUOuJzmW8zfgVpIz74DaXtAY4FqS4bQ+wDxgd4aJfghckH4g3wDsS9KTeJpkeKtRImIRSYK8naQ39So7Djd+N43tOZIP5T+ly3ITEduAUSQH7l8BbgK+mCbm+lxOMoz3dDrMOYukVwnQK53fCswBboqI2em6/0fyob1R0tfriWc5yXGidRGxMV1WDTwLHAj8sYG4rgJuTev/XAPlStkG9Ehj30wytPsWyXGuPVHvvkzb9g5gZRprZ+AnwAySodEtJO+tj+7htq2JKDkkYNY80qGsNcC4iHi0peMxs+JyD8pyJ+kTkg5S8puiK0iOF+3p0I2ZtRJOUNYcjiU57fcVkuMrZ0XEGw0/xcxaOw/xmZlZIbkHZWZmheQEZWZmhdS2pQPYXYceemj06NGjpcMwM7M9NH/+/FcionJX5couQfXo0YN58+a1dBhmZraHJL2061Ie4jMzs4JygjIzs0JygjIzs0JygjIzs0JygjIzs0JygjIzs0LKNUFJGilpmaQVpe7sKam7pEcl/VnSc5I+mWc8ZmZWPnJLUOktuCeT3OemDzBWUp86xa4kub33QOAcknvhmJmZ5dqDOgZYEREr05uyTQfq3qEySG6CBtCR/G+vbWZmZSLPK0l0Ibkra4017HyHyqtI7mB5MbAfcEqO8ZiZNa+rOu66TCP07dm9SepZeO7CJqmnueSZoFRiWd17e4wFpkbEjyQdC0yTdHR6i+l3K5IuAC4A6N69aXaUmVl9ekz8Q5PUs2qfJqmmySw5svd7rqP30iVNEEnj5DnEtwbolpnvys5DeOcDdwFExBxgH+DQuhVFxJSIqIqIqsrKXV5f0MzM9gJ5Jqi5QC9JPSW1IzkJYkadMi8DJwNI6k2SoNbnGJOZmZWJ3BJURGwHJgAPAktIztZbJOkaSaPSYl8DvizpL8AdwHnhW/yamRk5324jImYCM+ssm5SZXgwMyzMGMzMrT76ShJmZFZITlJmZFZITlJmZFZITlJmZFZITlJmZFZITlJmZFZITlJmZFZITlJmZFZITlJmZFZITlJmZFZITlJmZFZITlJmZFZITlJmZFZITlJmZFZITlJmZFZITlJmZFZITlJmZFZITlJmZFZITlJmZFVKuCUrSSEnLJK2QNLHE+uslLUgfyyVtzDMeMzMrH23zqlhSG2AycCqwBpgraUZELK4pExFfzZS/GBiYVzxmZlZe8uxBHQOsiIiVEbENmA6c2UD5scAdOcZjZmZlJM8E1QVYnZlfky7biaTDgZ7Af+YYj5mZlZE8E5RKLIt6yp4D3BMR75SsSLpA0jxJ89avX99kAZqZWXHlmaDWAN0y812BtfWUPYcGhvciYkpEVEVEVWVlZROGaGZmRZVngpoL9JLUU1I7kiQ0o24hSUcABwNzcozFzMzKTG4JKiK2AxOAB4ElwF0RsUjSNZJGZYqOBaZHRH3Df2Zm1grldpo5QETMBGbWWTapzvxVecZgZmblyVeSMDOzQnKCMjOzQnKCMjOzQnKCMjOzQnKCMjOzQnKCMjOzQnKCMjOzQnKCMjOzQnKCMjOzQnKCMjOzQnKCMjOzQnKCMjOzQnKCMjOzQnKCMjOzQnKCMjOzQsr1flDWOvWY+IcmqWfV909vknr63tq3SepZeO7CJqnHzBrHPSgzMysk96DM7D1xD9Xy4gRl1khLjuz9nuvovXRJE0RSvGFUszw4QVlxXdWxaerp2b1p6tkbNUUbN1H7NsUXAGi6LwHW8nI9BiVppKRlklZImlhPmc9JWixpkaTb84zHzMzKR249KEltgMnAqcAaYK6kGRGxOFOmF/BNYFhEvCrpA3nFY2Zm5SXPHtQxwIqIWBkR24DpwJl1ynwZmBwRrwJExN9zjMfMzMpIngmqC7A6M78mXZb1EeAjkp6S9LSkkaUqknSBpHmS5q1fvz6ncM3MrEjyTFAqsSzqzLcFegHDgbHAv0o6aKcnRUyJiKqIqKqsrGzyQM3MrHjyTFBrgG6Z+a7A2hJl/iMi3o6IF4FlJAnLzMxauTwT1Fygl6SektoB5wAz6pT5LXASgKRDSYb8VuYYk5mZlYncElREbAcmAA8CS4C7ImKRpGskjUqLPQj8Q9Ji4FHgGxHxj7xiMjOz8pHrD3UjYiYws86ySZnpAC5NH2ZmZrV8sVgzMyskJygzMyskJygzMyskJygzMyskJygzMyskJygzMyskJygzMyskJygzMyskJygzMyskJygzMyskJygzMyskJygzMyskJygzMyukXK9mXlQ9Jv6hSepZ9f3T33MdfW/t2wSRwMJzFzZJPWZmRdEqE1STuarje6+jZ/f3Xgew5MjeTVJP76VLmqQeM7P3ykN8ZmZWSE5QZmZWSE5QZmZWSE5QZmZWSLkmKEkjJS2TtELSxBLrz5O0XtKC9PGlPOMxM7PykdtZfJLaAJOBU4E1wFxJMyJicZ2id0bEhLziMDOz8pRnD+oYYEVErIyIbcB04Mwct2dmZnuRPBNUF2B1Zn5Nuqyuz0h6TtI9krrlGI+ZmZWRPBOUSiyLOvO/A3pERD9gFnBryYqkCyTNkzRv/fr1TRymmZkVUZ4Jag2Q7RF1BdZmC0TEPyLirXT2l8DgUhVFxJSIqIqIqsrKylyCNTOzYskzQc0FeknqKakdcA4wI1tAUqfM7CjA19kxMzMgx7P4ImK7pAnAg0Ab4JaIWCTpGmBeRMwALpE0CtgObADOyyseMzMrL7leLDYiZgIz6yyblJn+JvDNPGMwM7Py5CtJmJlZITlBmZlZITUqQUkaI+mAdPpKSf8uaVC+oZmZWWvW2B7UtyNii6SPAZ8g+b3Sz/MLy8zMWrvGJqh30r+nAz+PiP8A2uUTkpmZWeMT1H9J+gXwOWCmpPa78VwzM7Pd1tgk8zmS3zONjIiNwCHAN3KLyszMWr1GJaiIeB34O/CxdNF24IW8gjIzM2vsWXz/AlzOuz+qfR9wW15BmZmZNXaI79Mk18p7DSAi1gIH5BWUmZlZYxPUtogI0ttlSNovv5DMzMwan6DuSs/iO0jSl0nu3fTL/MIyM7PWrlEXi42I6ySdCmwGjgAmRcTDuUZmZmat2i4TlKQ2wIMRcQrgpGRmZs1il0N8EfEO8Lqkjs0Qj5mZGdD4+0G9CSyU9DDpmXwAEXFJLlGZmVmr19gE9Yf0YWZm1iwae5LErZLaAR9JFy2LiLfzC8vMzFq7RiUoScNJbrGxChDQTdK5EfF4fqGZmVlr1tjfQf0IGBERJ0bECST3hLp+V0+SNFLSMkkrJE1soNxnJYWkqkbGY2Zme7nGJqj3RcSympmIWE5yPb56paenTwZOA/oAYyX1KVHuAOAS4JnGBm1mZnu/xiaoeZL+TdLw9PFLYP4unnMMsCIiVkbENmA6cGaJct8BriU5U9DMzAxofIL638Aikp7OPwOLgQt38ZwuwOrM/Jp0WS1JA4FuEfH7RsZhZmatRGNPM28L/CQifgy1w3ftd/EclVgWtSulCpLjWOftauOSLgAuAOjevXvjIjYzs7LW2B7UI8C+mfl9SS4Y25A1QLfMfFdgbWb+AOBoYLakVcBQYEapEyUiYkpEVEVEVWVlZSNDNjOzctbYBLVPRGytmUmnO+ziOXOBXpJ6pr+hOgeYkaljU0QcGhE9IqIH8DQwKiLm7dYrMDOzvVJjE9RrkgbVzKS9nDcaekJEbAcmAA8CS4C7ImKRpGskjdrTgM3MrHVo7DGo/wPcLWktyXGkzsDZu3pSRMwEZtZZNqmessMbGYuZmbUCDfagJA2R9MGImAscCdwJbAceAF5shvjMzKyV2tUQ3y+Aben0scAVJD++fRWYkmNcZmbWyu1qiK9NRGxIp88GpkTEvcC9khbkG5qZmbVmu+pBtZFUk8ROBv4zs66xx6/MzMx2266SzB3AY5JeITlr7wkASR8GNuUcm5mZtWINJqiI+J6kR4BOwEMRUXMliArg4ryDMzOz1muXw3QR8XSJZcvzCcfMzCzR2B/qmpmZNSsnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzK6RcE5SkkZKWSVohaWKJ9RdKWihpgaQnJfXJMx4zMysfuSUoSW1Ibg9/GtAHGFsiAd0eEX0jYgBwLfDjvOIxM7PykmcP6hhgRUSsjIhtwHTgzGyBiNicmd0PCMzMzMj3tu1dgNWZ+TXAR+sWkvQV4FKgHfDxHOMxM7MykmcPSiWW7dRDiojJEfEh4HLgypIVSRdImidp3vr165s4TDMzK6I8E9QaoFtmviuwtoHy04GzSq2IiCkRURURVZWVlU0YopmZFVWeCWou0EtST0ntgHOAGdkCknplZk8HXsgxHjMzKyO5HYOKiO2SJgAPAm2AWyJikaRrgHkRMQOYIOkU4G3gVeDcvOIxM7PykudJEkTETGBmnWWTMtP/nOf2zcysfPlKEmZmVkhOUGZmVkhOUGZmVkhOUGZmVkhOUGZmVkhOUGZmVkhOUGZmVkhOUGZmVkhOUGZmVkhOUGZmVkhOUGZmVkhOUGZmVkhOUGZmVkhOUGZmVkhOUGZmVkhOUGZmVkhOUGZmVkhOUGZmVkhOUGZmVki5JihJIyUtk7RC0sQS6y+VtFjSc5IekXR4nvGYmVn5yC1BSWoDTAZOA/oAYyX1qVPsz0BVRPQD7gGuzSseMzMrL3n2oI4BVkTEyojYBkwHzswWiIhHI+L1dPZpoGuO8ZiZWRnJM0F1AVZn5teky+pzPnB/jvGYmVkZaZtj3SqxLEoWlP4HUAWcWM/6C4ALALp3795U8ZmZWYHl2YNaA3TLzHcF1tYtJOkU4FvAqIh4q1RFETElIqoioqqysjKXYM3MrFjyTFBzgV6SekpqB5wDzMgWkDQQ+AVJcvp7jrGYmVmZyS1BRcR2YALwILAEuCsiFkm6RtKotNgPgf2BuyUtkDSjnurMzKyVyfMYFBExE5hZZ9mkzPQpeW7fzMzKl68kYWZmheQEZWZmheQEZWZmheQEZWZmheQEZWZmheQEZWZmheQEZWZmheQEZWZmheQEZWZmheQEZWZmheQEZWZmheQEZWZmheQEZWZmheQEZWZmheQEZWZmheQEZWZmheQEZWZmheQEZWZmheQEZWZmhZRrgpI0UtIySSskTSyx/gRJf5K0XdJn84zFzMzKS24JSlIbYDJwGtAHGCupT51iLwPnAbfnFYeZmZWntjnWfQywIiJWAkiaDpwJLK4pEBGr0nXVOcZhZmZlKM8hvi7A6sz8mnSZmZnZLuWZoFRiWexRRdIFkuZJmrd+/fr3GJaZmZWDPBPUGqBbZr4rsHZPKoqIKRFRFRFVlZWVTRKcmZkVW54Jai7QS1JPSe2Ac4AZOW7PzMz2IrklqIjYDkwAHgSWAHdFxCJJ10gaBSBpiKQ1wBjgF5IW5RWPmZmVlzzP4iMiZgIz6yyblJmeSzL0Z2ZmtgNfScLMzArJCcrMzArJCcrMzArJCcrMzArJCcrMzArJCcrMzArJCcrMzArJCcrMzArJCcrMzArJCcrMzArJCcrMzArJCcrMzArJCcrMzArJCcrMzArJCcrMzArJCcrMzArJCcrMzArJCcrMzArJCcrMzAop1wQlaaSkZZJWSJpYYn17SXem65+R1CPPeMzMrHzklqAktQEmA6cBfYCxkvrUKXY+8GpEfBi4HvhBXvGYmVl5ybMHdQywIiJWRsQ2YDpwZp0yZwK3ptP3ACdLUo4xmZlZmcgzQXUBVmfm16TLSpaJiO3AJuD9OcZkZmZlom2OdZfqCcUelEHSBcAF6exWScveY2xNomm6es83ptChwCsNFag7drrHCtSBbbpICtTGBWpf8Hs4b34P1+vwxhTKM0GtAbpl5rsCa+sps0ZSW6AjsKFuRRExBZiSU5yFJ2leRFS1dBx7M7dxvty++dsb2zjPIb65QC9JPSW1A84BZtQpMwM4N53+LPCfEbFTD8rMzFqf3HpQEbFd0gTgQaANcEtELJJ0DTAvImYA/wZMk7SCpOd0Tl7xmJlZeclziI+ImAnMrLNsUmb6TWBMnjHsJVrt8GYzchvny+2bv72ujeURNTMzKyJf6sjMzArJCaoMSZoq6bO7KHOepM7NFVORSfrXElcxqVumZJtK6iHp83uwzV3uI7O8SJotqezP6HOC2nudBzhBARHxpYhYvIdP7wHsdoLa26WXMmuubeV6rNyKywmqCUn6oqTnJP1F0jRJh0t6JF32iKTuabmpkn4u6VFJKyWdKOkWSUskTc3Ut1XSjyT9KX1+ZYltDpb0mKT5kh6U1Cn95l4F/EbSAkn7lirXbA3TRCRdJumSdPp6Sf+ZTp8s6TZJIyTNSdvrbkn7p+trv01KOl/S8nTZLyX9LLOJEyT9Md0nNb2f7wPHp+34VUltJP1Q0tx0v/6vtF5J+pmkxZL+AHygudqlqaW9xqWSbk1f4z2SOkhaJWmSpCeBMZI+JOmB9D31hKQj0+ePkfR8+n/weLrsKEnPpu34nKRe6Xaez2z365KuSqdnS/q/kh4D/llSpaR703afK2lYCzRNi5P027S9F0m6IH0/Tk3be6Gkr9YpX5Hux++2VMzvSUT40QQP4ChgGXBoOn8I8Dvg3HT+fwK/TaenklybUCTXI9wM9CX5wjAfGJCWC2BcOj0J+Fnm+Z8F3gf8EahMl59Ncjo/wGygKp2ut1w5PYChwN3p9BPAs+lr+xfgcuBxYL90/eXApGxbkPQoV6X75n1pHdk2vTvdB31IriMJMBz4fSaGC4Ar0+n2wDygJzAaeJjkJxWdgY3AZ1u6zfawnXuk771h6fwtwNfTtrssU+4RoFc6/VGS3zECLAS6pNMHpX9/mnkvtwP2TbfzfKa+rwNXZfbZTZl1twMfS6e7A0taup1aaN8ckv7dl+TyEoOBhzPra9p7dvr/cgfwrZaOe08f7jo3nY8D90TEKwARsUHSsSQfXADTgGsz5X8XESFpIfC3iFgIIGkRyT/uAqAauDMtfxvw73W2eQRwNPCwksuPtAHWlYitseWKbj4wWNIBwFvAn0gSz/EkP/ruAzyVvsZ2wJw6zz8GeCwiNgBIuhv4SGb9byOiGlgs6bB6YhgB9Mv0sDoCvYATgDsi4h1gbU3vroytjoin0unbgEvS6TsB0t7pccDdevfSN+3Tv08BUyXdxbvv2TnAtyR1Bf49Il7Qri+Zc2dm+hSgT+Y5B0o6ICK27PYrK2+XSPp0Ot2N5H3+T5J+CvwBeChT9hfAXRHxvWaOsck4QTUdUeI6gnVk17+V/q3OTNfM17dfSl3LcFFEHNuI2BpTrtAi4m1Jq4DxJD3C54CTgA8BL5J8kxzbQBW7+kTM7of6ygq4OCIe3GGh9El2vf/LSd3XUjP/Wvq3AtgYEQN2emLEhZI+CpwOLJA0ICJul/RMuuxBSV8ClrPjYYZ96lT1Wma6Ajg2It7Ys5dT/iQNJ0nUx0bE65Jmk3wp6A98AvgK8DmS0RpI/kdOkvSjSH5zWnZ8DKrpPAJ8TtL7ASQdQvIGqbk6xjjgyd2ss4JkKA+SA/V1n78MqEx7akh6n6Sj0nVbgAMaUa7cPE4yFPQ4yRDdhSS9zaeBYZI+DJAeM/lInec+C5wo6WAlB94/04jtZdsRkiuj/G9J70u38xFJ+6XxnJMeE+hEkjjLWfea9wswljrvvYjYDLwoaQzUHoPrn05/KCKeieRH+a8A3ST9E7AyIm4k6e32A/4GfEDS+yW1B85oIJ6HgAk1M5J2SoytQEeS++e9nh7vG0pygdiKiLgX+DYwKFP+30gulHC3yvREEyeoJhIRi4DvAY9J+gvwY5JhkfGSngO+APzzblb7GnCUpPkkQ4jX1NnmNpIE9oN0mwtIhl0gOaZys6QFJEN69ZUrN08AnYA5EfE34E3giYhYT3Lm4h1pez8NHJl9YkT8F/B/gWeAWcBiklu8NOQ5YHt6wP+rwL+mz/tTeoD/FyQ93vuAF0iOv/wceOy9v9QWtQQ4N23LQ0heU13jgPPT99Qi3r3f2w/TA/bPkyTuv5Ac93w+fT8eCfw6It4meU8/A/weWNpAPJcAVekJFotJvpi0Ng8AbdN98h2S93gXYHbarlOBb2afEBE/JhkKnyap7D7vfSWJApO0NSL2b+k49iaS9o+Irek3yvtITha5r6XjKhJJPUhODDm6hUOxVq7sMqrZe3RV+m3zeZLjVr9t4XjMrB7uQQHz58/vWlFR8VB1dfWRNOU9xszMyldUVFQsra6uHjF48OA1LRFAWR44a2oVFRUPffCDH+x12GGHqaLCnUozs+rqaq1bt+6Il1566dlRo0adNWPGjGebOwZ/GgPV1dVHHnbYYW2dnMzMEhUVFXTq1KmiXbt2nYAJo0aNOr7ZY2juDRaUe05mZnVUVFSQ/jj6FeDEZt9+c2/QrCjatGnDgAEDOProoxkzZgyvv/76e65z3rx5XHLJJfWuX7t2LZ/9rC9y3pRWrVrF0UcnJxzOnj2bM85o6OdU5eXGG2+kd+/ejBs3rqVD2c7OP6TOnY9BldBj4h+atL5V3z+9SevbU9u3b6dkw44+AAAJBklEQVRt24Lu8qs6NnF9u/p5E+y7774sWLAAgHHjxnHzzTdz6aWX1q6vuR7Y7vSuq6qqqKqq/y4HnTt35p577ml0fXnqe2vfJq1v4bkLd6v8nrRvS1pyZO8mra/30iW7LHPTTTdx//3307NnzybddqE/CzLK453RCpx11lkMHjyYo446iilTkjs3P/DAAwwaNIj+/ftz8sknA7B161bGjx9P37596devH/feey8A++//7s+l7rnnHs477zwAzjvvPC699FJOOukkLr/8cp599lmOO+44Bg4cyHHHHceyZcsAeOedd/j6179eW+9Pf/pTHnnkET796U/X1vvwww8zevRo9kbHH388K1asYNWqVfTu3ZuLLrqIQYMGsXr1ah566CGOPfZYBg0axJgxY9i6dSsAc+fO5bjjjqN///4cc8wxbNmyZYdv8I899hgDBgxgwIABDBw4kC1btuzwbf/NN9+s3ZcDBw7k0UcfBWDq1KmMHj2akSNH0qtXLy677LKWaZQc1G3fadOmNbptV61axfHHH8+gQYMYNGgQf/zjH1v41eTrwgsvZOXKlYwaNYqrr756p/cSwLXXXkvfvn3p378/EydOBGDBggUMHTqUfv368elPf5pXX30VgOHDh3PFFVdw4okn8pOf/IT169fzmc98hiFDhjBkyBCeeuqpemNpKcVPoa3ELbfcwiGHHMIbb7zBkCFDOPPMM/nyl7/M448/Ts+ePdmwYQMA3/nOd+jYsSMLFybfVmvefA1Zvnw5s2bNok2bNmzevJnHH3+ctm3bMmvWLK644gruvfdepkyZwosvvsif//xn2rZty4YNGzj44IP5yle+wvr166msrORXv/oV48ePz7UdWsL27du5//77GTlyJADLli3jV7/6FTfddBOvvPIK3/3ud5k1axb77bcfP/jBD/jxj3/MxIkTOfvss7nzzjsZMmQImzdvZt99992h3uuuu47JkyczbNgwtm7dyj777DhCMnnyZAAWLlzI0qVLGTFiBMuXLweSD5k///nPtG/fniOOOIKLL76Ybt26NUNr5K+mfa+55hpGjx7d6Lb9wAc+wMMPP8w+++zDCy+8wNixY5k3b15Lv5zc3HzzzTzwwAM8+uijjB8/fqf30v33389vf/tbnnnmGTp06FD7GfHFL36Rn/70p5x44olMmjSJq6++mhtuuAGAjRs38thjyUVOPv/5z/PVr36Vj33sY7z88st84hOfYMmSXffqmpMTVEHceOON3HdfckGD1atXM2XKFE444YTarv0hhxwCwKxZs5g+fXrt8w4++OBd1j1mzBjatEnuL7dp0ybOPfdcXnjhBSTx9ttv19Z74YUX1nb7a7b3hS98gdtuu43x48czZ84cfv3rXzfRK255b7zxBgMGJJd0O/744zn//PNZu3Ythx9+OEOHDgXg6aefZvHixQwbltx+aNu2bRx77LEsW7aMTp06MWTIEAAOPPDAneofNmwYl156KePGjWP06NF07dp1h/VPPvkkF198MQBHHnkkhx9+eG2COvnkk+nYMRn27NOnDy+99NJek6Bq2vf3v//9brXta6+9xoQJE1iwYAFt2rSpbavWoNR7adasWYwfP54OHToAyf/spk2b2LhxIyeemJzPcO655zJmzJjaes4+++za6VmzZrF48bv38dy8eTNbtmzhgAOyl55sWU5QBTB79mxmzZrFnDlz6NChA8OHD6d///61w29ZEVFzVs0OssvefHPHCxfvt99+tdPf/va3Oemkk7jvvvtYtWoVw4cPb7De8ePH86lPfYp99tmHMWPGlMW4dWNlj0FlZdsrIjj11FO54447dijz3HPPlWyvrIkTJ3L66aczc+ZMhg4dyqxZs3boRTX0I/n27dvXTrdp04bt27fv8vWUi5r23d22vf766znssMP4y1/+QnV19U490r1ZqfdSff+zDcm+t6urq5kzZ85OPf8i8TGoAti0aRMHH3wwHTp0YOnSpTz99NO89dZbPPbYY7z44osAtd33ESNG8LOfvXsT2JohvsMOO4wlS5ZQXV1d2xOrb1tdunQBkmMdNUaMGMHNN99c+0FYs73OnTvTuXNnvvvd79Ye12pNhg4dylNPPcWKFSsAeP3111m+fDlHHnkka9euZe7cuQBs2bJlpyTy17/+lb59+3L55ZdTVVXF0qU7Xgv1hBNO4De/+Q2QDMO+/PLLHHHEEc3wqophd9t206ZNdOrUiYqKCqZNm8Y777zTkuE3q1LvpREjRnDLLbfUnn26YcMGOnbsyMEHH8wTTzwBwLRp02p7U3XV/Swp9WWtpTlBFcDIkSPZvn07/fr149vf/jZDhw6lsrKSKVOmMHr0aPr371/bNb/yyit59dVXOfroo+nfv3/tgfXvf//7nHHGGXz84x+nU6f67+Z+2WWX8c1vfpNhw4bt8A/+pS99ie7du9OvXz/69+/P7bffXrtu3LhxdOvWjT59+uTUAsVVWVnJ1KlTGTt2LP369WPo0KEsXbqUdu3aceedd3LxxRfTv39/Tj311J16rjfccEPtftp333057bTTdlh/0UUX8c4779C3b1/OPvtspk6dukPPaW+3u2170UUXceuttzJ06FCWL1++Q29gb1fqvTRy5EhGjRpFVVUVAwYM4LrrrgPg1ltv5Rvf+Ab9+vVjwYIFTJo0qWSdN954I/PmzaNfv3706dOHm2++uTlfUqP4WnzA/PnzY/DgwS0dRmFNmDCBgQMHcv7557d0KGbWzObPn8/VV1/9Q2DbjBkzrmzObe89BxQsF4MHD2a//fbjRz/6UUuHYmatjBOUNWj+/PktHYKZtVI+BmVmZoXkBJWI6urqlo7BzKxQqqurG/w5RN6coICKioql69atq3aSMjNLVFdXs27duuo333zzFVroRq4+BgVUV1ePWL169Zx169Z13d0fvpmZ7Y0igjfffHPDtGnTpgEHAs83dwxOUMDgwYPXjBo1qjdwKXA44HPvzcwSBwKbgbuae8P+HVTGqFGj2gOdgXYtHYuZWUFsB/57xowZrzX3hp2gzMyskHyShJmZFZITlJmZFZITlJmZFdL/B3A3ko06TI1nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "label='Drug'\n",
    "asklabel='Drug'\n",
    "res_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "wei_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "bld_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "ask_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "\n",
    "result,result_labels,weighted,weighted_labels,blood,blood_labels,ask,ask_labels=prepareDataset(label,asklabel)\n",
    "for estimators in range (100,1000,100):\n",
    "    print (estimators)\n",
    "    res_acc,res_scores=randomForest(result,result_labels,estimators,\"Result\")\n",
    "    wei_acc,wei_scores=randomForest(weighted,weighted_labels,estimators,\"Weighted\")\n",
    "    blood_acc,blood_scores=randomForest(blood,blood_labels,estimators,\"Blood\")\n",
    "    ask_acc,ask_scores=randomForest(ask,ask_labels,estimators,\"Ask\")\n",
    "    print(\"Res: Accuracy: \" + str(res_acc)+\" # \"+ \"Scores: \"+str(res_scores))\n",
    "    print(\"Wei: Accuracy: \" + str(wei_acc)+\" # \"+ \"Scores: \"+str(wei_scores))\n",
    "    print(\"Bld: Accuracy: \" + str(blood_acc)+\" # \"+ \"Scores: \"+str(blood_scores))\n",
    "    print(\"Ask: Accuracy: \" + str(ask_acc)+\" # \"+ \"Scores: \"+str(ask_scores))\n",
    "    res_Stats=res_Stats.append({'Estimators':estimators,'Accuracy':res_acc,'Precision':res_scores[0],'Recall':res_scores[1],'FScore':res_scores[2]},ignore_index=True)\n",
    "    wei_Stats=wei_Stats.append({'Estimators':estimators,'Accuracy':wei_acc,'Precision':wei_scores[0],'Recall':wei_scores[1],'FScore':wei_scores[2]},ignore_index=True)\n",
    "    bld_Stats=bld_Stats.append({'Estimators':estimators,'Accuracy':blood_acc,'Precision':blood_scores[0],'Recall':blood_scores[1],'FScore':blood_scores[2]},ignore_index=True)\n",
    "    ask_Stats=ask_Stats.append({'Estimators':estimators,'Accuracy':ask_acc,'Precision':ask_scores[0],'Recall':ask_scores[1],'FScore':ask_scores[2]},ignore_index=True)\n",
    "'''writer = pd.ExcelWriter('Forrest_Stats'+label+'.xlsx', engine='xlsxwriter')\n",
    "res_Stats.to_excel(writer, sheet_name='Sheet1') \n",
    "wei_Stats.to_excel(writer, sheet_name='Sheet2') \n",
    "bld_Stats.to_excel(writer, sheet_name='Sheet3') \n",
    "ask_Stats.to_excel(writer, sheet_name='Sheet4')\n",
    "writer.save()'''\n",
    "x1=res_Stats['FScore'].tolist().index(max(res_Stats['FScore'].tolist()))\n",
    "x2=wei_Stats['FScore'].tolist().index(max(wei_Stats['FScore'].tolist()))\n",
    "x3=bld_Stats['FScore'].tolist().index(max(bld_Stats['FScore'].tolist()))\n",
    "x4=ask_Stats['FScore'].tolist().index(max(ask_Stats['FScore'].tolist()))\n",
    "max_res=res_Stats.iloc[x1].to_frame().transpose()\n",
    "max_wei=wei_Stats.iloc[x2].to_frame().transpose()\n",
    "max_bld=bld_Stats.iloc[x3].to_frame().transpose()\n",
    "max_ask=ask_Stats.iloc[x4].to_frame().transpose()\n",
    "stats=pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "max_res['Estimators']=\"Complete\"\n",
    "max_wei['Estimators']=\"Weighted\"\n",
    "max_bld['Estimators']=\"Pressure\"\n",
    "max_ask['Estimators']=\"Ask\"\n",
    "stats=stats.append(max_res)\n",
    "stats=stats.append(max_wei)\n",
    "stats=stats.append(max_bld)\n",
    "stats=stats.append(max_ask)\n",
    "\n",
    "plotResult(label+\" Random Forest With Smote\",max_res,max_wei,max_bld,max_ask,x1,x2,x3,x4)\n",
    "\n",
    "import os.path\n",
    "if not os.path.exists('Forrest_StatsTotal'+'.xlsx'):\n",
    "    writer = pd.ExcelWriter('Forrest_StatsTotal'+'.xlsx', engine = 'xlsxwriter')\n",
    "\n",
    "    writer.save()\n",
    "    writer.close()\n",
    "writer = pd.ExcelWriter('Forrest_StatsTotal'+'.xlsx', engine='openpyxl')\n",
    "book = load_workbook('Forrest_StatsTotal'+'.xlsx')\n",
    "writer.book = book\n",
    "writer.sheets = dict((ws.title, ws) for ws in book.worksheets)\n",
    "\n",
    "stats.to_excel(writer, sheet_name=label)\n",
    "writer.save()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest With Importance Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Beta': 739, 'Angiotensin': 428, 'Calcium': 261, 'Diuretics': 129})\n",
      "Counter({'Angiotensin': 51, 'Beta': 45, 'Calcium': 14, 'Diuretics': 13})\n",
      "Counter({'Beta': 186, 'Angiotensin': 134, 'Calcium': 89, 'Diuretics': 51})\n",
      "Counter({'Angiotensin': 622, 'Beta': 134})\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 4, 13], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 2, 3, 5, 6, 15], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 1, 2, 3, 6], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 6], dtype='int64')\n",
      "Counter({2: 739, 3: 739, 1: 739, 0: 739})\n",
      "Counter({2: 51, 3: 51, 1: 51, 0: 51})\n",
      "Counter({2: 186, 3: 186, 1: 186, 0: 186})\n",
      "Counter({0: 622, 1: 622})\n",
      "Res: Accuracy: 0.3923337091319053 # Scores: (0.39108389210592576, 0.39321456201844135, 0.3851436230791696, None)\n",
      "Wei: Accuracy: 0.5806451612903226 # Scores: (0.5614219114219114, 0.581827731092437, 0.5650793650793651, None)\n",
      "Bld: Accuracy: 0.47767857142857145 # Scores: (0.4784396762657632, 0.4787992923586144, 0.47621779859484775, None)\n",
      "Ask: Accuracy: 0.8288770053475936 # Scores: (0.8393965491640187, 0.8269676422624668, 0.8268969307761289, None)\n",
      "200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 4, 13], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 2, 3, 5, 6, 15, 17], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 1, 2, 3, 6], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 6], dtype='int64')\n",
      "Counter({2: 739, 3: 739, 1: 739, 0: 739})\n",
      "Counter({2: 51, 3: 51, 1: 51, 0: 51})\n",
      "Counter({2: 186, 3: 186, 1: 186, 0: 186})\n",
      "Counter({0: 622, 1: 622})\n",
      "Res: Accuracy: 0.38444193912063135 # Scores: (0.3827628952978234, 0.3855217899494015, 0.3776169816326511, None)\n",
      "Wei: Accuracy: 0.6129032258064516 # Scores: (0.5894793523469994, 0.6155812324929972, 0.5983300264550264, None)\n",
      "Bld: Accuracy: 0.4642857142857143 # Scores: (0.4636694030594449, 0.4660874279518347, 0.46264084490894664, None)\n",
      "Ask: Accuracy: 0.8262032085561497 # Scores: (0.8359708392603129, 0.8243498412153463, 0.8242925806801344, None)\n",
      "300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 4, 13], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 2, 3, 5, 6, 15], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 1, 2, 3, 6], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 6], dtype='int64')\n",
      "Counter({2: 739, 3: 739, 1: 739, 0: 739})\n",
      "Counter({2: 51, 3: 51, 1: 51, 0: 51})\n",
      "Counter({2: 186, 3: 186, 1: 186, 0: 186})\n",
      "Counter({0: 622, 1: 622})\n",
      "Res: Accuracy: 0.3855693348365276 # Scores: (0.3838742720514909, 0.3866914968905334, 0.37813951621643815, None)\n",
      "Wei: Accuracy: 0.5967741935483871 # Scores: (0.5739219114219114, 0.5965336134453781, 0.5797160797160796, None)\n",
      "Bld: Accuracy: 0.45535714285714285 # Scores: (0.457388904596119, 0.45803515379786564, 0.4556240924750164, None)\n",
      "Ask: Accuracy: 0.8262032085561497 # Scores: (0.8359708392603129, 0.8243498412153463, 0.8242925806801344, None)\n",
      "400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 4, 13], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 2, 3, 5, 6, 15], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 1, 2, 3, 6, 15], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 6], dtype='int64')\n",
      "Counter({2: 739, 3: 739, 1: 739, 0: 739})\n",
      "Counter({2: 51, 3: 51, 1: 51, 0: 51})\n",
      "Counter({2: 186, 3: 186, 1: 186, 0: 186})\n",
      "Counter({0: 622, 1: 622})\n",
      "Res: Accuracy: 0.3855693348365276 # Scores: (0.38386037447686056, 0.3865842258654125, 0.3787951829729562, None)\n",
      "Wei: Accuracy: 0.5967741935483871 # Scores: (0.5739219114219114, 0.5965336134453781, 0.5797160797160796, None)\n",
      "Bld: Accuracy: 0.47767857142857145 # Scores: (0.4754135734467573, 0.4849141128802146, 0.47616223651269596, None)\n",
      "Ask: Accuracy: 0.8262032085561497 # Scores: (0.8359708392603129, 0.8243498412153463, 0.8242925806801344, None)\n",
      "500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 4, 13], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 2, 3, 5, 6, 15, 17], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 1, 2, 3, 6], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 6], dtype='int64')\n",
      "Counter({2: 739, 3: 739, 1: 739, 0: 739})\n",
      "Counter({2: 51, 3: 51, 1: 51, 0: 51})\n",
      "Counter({2: 186, 3: 186, 1: 186, 0: 186})\n",
      "Counter({0: 622, 1: 622})\n",
      "Res: Accuracy: 0.3855693348365276 # Scores: (0.3840353129235892, 0.38663786137797296, 0.37847189553476424, None)\n",
      "Wei: Accuracy: 0.5967741935483871 # Scores: (0.5752840909090909, 0.5977240896358543, 0.5823415183815628, None)\n",
      "Bld: Accuracy: 0.45089285714285715 # Scores: (0.4496187722374317, 0.4560420590081607, 0.45018971955396464, None)\n",
      "Ask: Accuracy: 0.8262032085561497 # Scores: (0.8359708392603129, 0.8243498412153463, 0.8242925806801344, None)\n",
      "600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 4, 13], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 2, 3, 5, 6, 15], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 1, 2, 3, 6, 15], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 6], dtype='int64')\n",
      "Counter({2: 739, 3: 739, 1: 739, 0: 739})\n",
      "Counter({2: 51, 3: 51, 1: 51, 0: 51})\n",
      "Counter({2: 186, 3: 186, 1: 186, 0: 186})\n",
      "Counter({0: 622, 1: 622})\n",
      "Res: Accuracy: 0.3855693348365276 # Scores: (0.38368791296422877, 0.38667634659964784, 0.37798234243882556, None)\n",
      "Wei: Accuracy: 0.5967741935483871 # Scores: (0.5727368220015279, 0.5965336134453781, 0.5801068926068926, None)\n",
      "Bld: Accuracy: 0.4732142857142857 # Scores: (0.46900823381054824, 0.47935855732465904, 0.4707425085377841, None)\n",
      "Ask: Accuracy: 0.8262032085561497 # Scores: (0.8359708392603129, 0.8243498412153463, 0.8242925806801344, None)\n",
      "700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 4, 13], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 2, 3, 5, 6, 15, 17], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 1, 2, 3, 6], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 6], dtype='int64')\n",
      "Counter({2: 739, 3: 739, 1: 739, 0: 739})\n",
      "Counter({2: 51, 3: 51, 1: 51, 0: 51})\n",
      "Counter({2: 186, 3: 186, 1: 186, 0: 186})\n",
      "Counter({0: 622, 1: 622})\n",
      "Res: Accuracy: 0.38669673055242393 # Scores: (0.38527509493934176, 0.3877002972939839, 0.3796513457464604, None)\n",
      "Wei: Accuracy: 0.5806451612903226 # Scores: (0.5604031385281385, 0.5798669467787114, 0.565403203348874, None)\n",
      "Bld: Accuracy: 0.45089285714285715 # Scores: (0.4534319044978761, 0.4560420590081607, 0.45154692556634307, None)\n",
      "Ask: Accuracy: 0.8262032085561497 # Scores: (0.8359708392603129, 0.8243498412153463, 0.8242925806801344, None)\n",
      "800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 4, 13], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 2, 3, 5, 6, 15, 17], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 1, 2, 3, 6, 15], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 6], dtype='int64')\n",
      "Counter({2: 739, 3: 739, 1: 739, 0: 739})\n",
      "Counter({2: 51, 3: 51, 1: 51, 0: 51})\n",
      "Counter({2: 186, 3: 186, 1: 186, 0: 186})\n",
      "Counter({0: 622, 1: 622})\n",
      "Res: Accuracy: 0.3878241262683202 # Scores: (0.3863682494807722, 0.38877788350088044, 0.38099486266498805, None)\n",
      "Wei: Accuracy: 0.5967741935483871 # Scores: (0.5752840909090909, 0.5977240896358543, 0.5823415183815628, None)\n",
      "Bld: Accuracy: 0.4642857142857143 # Scores: (0.4603933805265773, 0.47009929806539974, 0.46178908364008675, None)\n",
      "Ask: Accuracy: 0.8288770053475936 # Scores: (0.8369126528207395, 0.8271965210425429, 0.8272766632991775, None)\n",
      "900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 4, 13], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 2, 3, 5, 6, 15, 17], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 1, 2, 3, 6], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 6], dtype='int64')\n",
      "Counter({2: 739, 3: 739, 1: 739, 0: 739})\n",
      "Counter({2: 51, 3: 51, 1: 51, 0: 51})\n",
      "Counter({2: 186, 3: 186, 1: 186, 0: 186})\n",
      "Counter({0: 622, 1: 622})\n",
      "Res: Accuracy: 0.3878241262683202 # Scores: (0.3861081417033337, 0.388766645583963, 0.38005715182497735, None)\n",
      "Wei: Accuracy: 0.5967741935483871 # Scores: (0.5752840909090909, 0.5977240896358543, 0.5823415183815628, None)\n",
      "Bld: Accuracy: 0.44642857142857145 # Scores: (0.44845513593726033, 0.4522541802202819, 0.4469767625990032, None)\n",
      "Ask: Accuracy: 0.8262032085561497 # Scores: (0.8359708392603129, 0.8243498412153463, 0.8242925806801344, None)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'Forrest_StatsImportanceTotal.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-d9dcc82282bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msheet_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1226\u001b[0m         \u001b[0mSave\u001b[0m \u001b[0mworkbook\u001b[0m \u001b[0mto\u001b[0m \u001b[0mdisk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1227\u001b[0m         \"\"\"\n\u001b[1;32m-> 1228\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1230\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\openpyxl\\workbook\\workbook.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m    394\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_only\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mworksheets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_sheet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 396\u001b[1;33m         \u001b[0msave_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\openpyxl\\writer\\excel.py\u001b[0m in \u001b[0;36msave_workbook\u001b[1;34m(workbook, filename)\u001b[0m\n\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m     \"\"\"\n\u001b[1;32m--> 292\u001b[1;33m     \u001b[0marchive\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mZipFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mZIP_DEFLATED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallowZip64\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m     \u001b[0mwriter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExcelWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mworkbook\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marchive\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, file, mode, compression, allowZip64)\u001b[0m\n\u001b[0;32m   1111\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1113\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1114\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1115\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'Forrest_StatsImportanceTotal.xlsx'"
     ]
    }
   ],
   "source": [
    "label='DrugFamily'\n",
    "asklabel='DrugFamily'\n",
    "res_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "wei_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "bld_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "ask_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "result,result_labels,weighted,weighted_labels,blood,blood_labels,ask,ask_labels=prepareDataset(label,asklabel)\n",
    "\n",
    "for estimators in range (100,1000,100):\n",
    "    print (estimators)\n",
    "    res_feat=importance(result,result_labels)\n",
    "    wei_feat=importance(weighted,weighted_labels)\n",
    "    blood_feat=importance(blood,blood_labels)\n",
    "    ask_feat=importance(ask,ask_labels)\n",
    "    res_acc,res_scores=randomForest(pd.DataFrame(result)[res_feat],result_labels,estimators,\"Result\")\n",
    "    wei_acc,wei_scores=randomForest(pd.DataFrame(weighted)[wei_feat],weighted_labels,estimators,\"Weighted\")\n",
    "    blood_acc,blood_scores=randomForest(pd.DataFrame(blood)[blood_feat],blood_labels,estimators,\"Blood\")\n",
    "    ask_acc,ask_scores=randomForest(pd.DataFrame(ask)[ask_feat],ask_labels,estimators,\"Ask\")\n",
    "    print(\"Res: Accuracy: \" + str(res_acc)+\" # \"+ \"Scores: \"+str(res_scores))\n",
    "    print(\"Wei: Accuracy: \" + str(wei_acc)+\" # \"+ \"Scores: \"+str(wei_scores))\n",
    "    print(\"Bld: Accuracy: \" + str(blood_acc)+\" # \"+ \"Scores: \"+str(blood_scores))\n",
    "    print(\"Ask: Accuracy: \" + str(ask_acc)+\" # \"+ \"Scores: \"+str(ask_scores))\n",
    "    res_Stats=res_Stats.append({'Estimators':estimators,'Accuracy':res_acc,'Precision':res_scores[0],'Recall':res_scores[1],'FScore':res_scores[2]},ignore_index=True)\n",
    "    wei_Stats=wei_Stats.append({'Estimators':estimators,'Accuracy':wei_acc,'Precision':wei_scores[0],'Recall':wei_scores[1],'FScore':wei_scores[2]},ignore_index=True)\n",
    "    bld_Stats=bld_Stats.append({'Estimators':estimators,'Accuracy':blood_acc,'Precision':blood_scores[0],'Recall':blood_scores[1],'FScore':blood_scores[2]},ignore_index=True)\n",
    "    ask_Stats=ask_Stats.append({'Estimators':estimators,'Accuracy':ask_acc,'Precision':ask_scores[0],'Recall':ask_scores[1],'FScore':ask_scores[2]},ignore_index=True)\n",
    "'''writer = pd.ExcelWriter('Forrest_Stats'+label+'.xlsx', engine='xlsxwriter')\n",
    "res_Stats.to_excel(writer, sheet_name='Sheet1') \n",
    "wei_Stats.to_excel(writer, sheet_name='Sheet2') \n",
    "bld_Stats.to_excel(writer, sheet_name='Sheet3') \n",
    "ask_Stats.to_excel(writer, sheet_name='Sheet4')\n",
    "writer.save()'''\n",
    "x1=res_Stats['FScore'].tolist().index(max(res_Stats['FScore'].tolist()))\n",
    "x2=wei_Stats['FScore'].tolist().index(max(wei_Stats['FScore'].tolist()))\n",
    "x3=bld_Stats['FScore'].tolist().index(max(bld_Stats['FScore'].tolist()))\n",
    "x4=ask_Stats['FScore'].tolist().index(max(ask_Stats['FScore'].tolist()))\n",
    "max_res=res_Stats.iloc[x1].to_frame().transpose()\n",
    "max_wei=wei_Stats.iloc[x2].to_frame().transpose()\n",
    "max_bld=bld_Stats.iloc[x3].to_frame().transpose()\n",
    "max_ask=ask_Stats.iloc[x4].to_frame().transpose()\n",
    "stats=pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "max_res['Estimators']=\"Complete\"\n",
    "max_wei['Estimators']=\"Weighted\"\n",
    "max_bld['Estimators']=\"Pressure\"\n",
    "max_ask['Estimators']=\"Ask\"\n",
    "stats=stats.append(max_res)\n",
    "stats=stats.append(max_wei)\n",
    "stats=stats.append(max_bld)\n",
    "stats=stats.append(max_ask)\n",
    "\n",
    "plotResult(label+\" Random Forest With Feature Filtering\",max_res,max_wei,max_bld,max_ask,x1,x2,x3,x4)\n",
    "\n",
    "import os.path\n",
    "if not os.path.exists('Forrest_StatsImportanceTotal'+'.xlsx'):\n",
    "    writer = pd.ExcelWriter('Forrest_StatsImportanceTotal'+'.xlsx', engine = 'xlsxwriter')\n",
    "\n",
    "    writer.save()\n",
    "    writer.close()\n",
    "writer = pd.ExcelWriter('Forrest_StatsImportanceTotal'+'.xlsx', engine='openpyxl')\n",
    "book = load_workbook('Forrest_StatsImportanceTotal'+'.xlsx')\n",
    "writer.book = book\n",
    "writer.sheets = dict((ws.title, ws) for ws in book.worksheets)\n",
    "\n",
    "stats.to_excel(writer, sheet_name=label)\n",
    "writer.save()\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Without Smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Atenolol': 620, 'Lisinopril': 428, 'Amlodipine': 161, 'Hydrochlorothiazide': 129, 'Nadolol': 119, 'Diltiazem': 100})\n",
      "Counter({'Lisinopril': 51, 'Atenolol': 45, 'Amlodipine': 14, 'Hydrochlorothiazide': 13})\n",
      "Counter({'Atenolol': 186, 'Lisinopril': 134, 'Amlodipine': 63, 'Hydrochlorothiazide': 51, 'Diltiazem': 26})\n",
      "Counter({'Lisinopril': 622, 'Atenolol': 134})\n",
      "100\n",
      "Counter({1: 620, 4: 428, 0: 161, 3: 129, 5: 119, 2: 100})\n",
      "Counter({3: 51, 1: 45, 0: 14, 2: 13})\n",
      "Counter({1: 186, 4: 134, 0: 63, 3: 51, 2: 26})\n",
      "Counter({1: 622, 0: 134})\n",
      "Res: Accuracy: 0.3055555555555556 # Scores: (0.1830162210618924, 0.1877610513191222, 0.18294342166741184, None)\n",
      "Wei: Accuracy: 0.4864864864864865 # Scores: (0.265625, 0.3375, 0.29707792207792205, None)\n",
      "Bld: Accuracy: 0.3695652173913043 # Scores: (0.2984892300681774, 0.2624586363716798, 0.25506949191159717, None)\n",
      "Ask: Accuracy: 0.7665198237885462 # Scores: (0.5437975347495411, 0.5599425699928212, 0.5471108601543384, None)\n",
      "200\n",
      "Counter({1: 620, 4: 428, 0: 161, 3: 129, 5: 119, 2: 100})\n",
      "Counter({3: 51, 1: 45, 0: 14, 2: 13})\n",
      "Counter({1: 186, 4: 134, 0: 63, 3: 51, 2: 26})\n",
      "Counter({1: 622, 0: 134})\n",
      "Res: Accuracy: 0.3162393162393162 # Scores: (0.1914634019987486, 0.1932307273924728, 0.1886655420890573, None)\n",
      "Wei: Accuracy: 0.4864864864864865 # Scores: (0.26842105263157895, 0.3375, 0.2990196078431372, None)\n",
      "Bld: Accuracy: 0.3695652173913043 # Scores: (0.3061111111111111, 0.2616782573304312, 0.2541114621114621, None)\n",
      "Ask: Accuracy: 0.775330396475771 # Scores: (0.5586808287437713, 0.5803122756640344, 0.5642010163749295, None)\n",
      "300\n",
      "Counter({1: 620, 4: 428, 0: 161, 3: 129, 5: 119, 2: 100})\n",
      "Counter({3: 51, 1: 45, 0: 14, 2: 13})\n",
      "Counter({1: 186, 4: 134, 0: 63, 3: 51, 2: 26})\n",
      "Counter({1: 622, 0: 134})\n",
      "Res: Accuracy: 0.31196581196581197 # Scores: (0.1863615906000856, 0.1914670589621377, 0.18582844283191033, None)\n",
      "Wei: Accuracy: 0.4864864864864865 # Scores: (0.2744360902255639, 0.3333333333333333, 0.3009049773755656, None)\n",
      "Bld: Accuracy: 0.37681159420289856 # Scores: (0.31051948051948053, 0.26758684149988493, 0.2604932867977018, None)\n",
      "Ask: Accuracy: 0.7709251101321586 # Scores: (0.5557915057915058, 0.5777997128499641, 0.5608630952380952, None)\n",
      "400\n",
      "Counter({1: 620, 4: 428, 0: 161, 3: 129, 5: 119, 2: 100})\n",
      "Counter({3: 51, 1: 45, 0: 14, 2: 13})\n",
      "Counter({1: 186, 4: 134, 0: 63, 3: 51, 2: 26})\n",
      "Counter({1: 622, 0: 134})\n",
      "Res: Accuracy: 0.30982905982905984 # Scores: (0.18638026494249668, 0.19058522474697015, 0.18558942802622655, None)\n",
      "Wei: Accuracy: 0.4864864864864865 # Scores: (0.27297794117647056, 0.3375, 0.3013392857142857, None)\n",
      "Bld: Accuracy: 0.37681159420289856 # Scores: (0.31051948051948053, 0.26758684149988493, 0.2604932867977018, None)\n",
      "Ask: Accuracy: 0.7797356828193832 # Scores: (0.5616978609625669, 0.5828248384781048, 0.5675861017982322, None)\n",
      "500\n",
      "Counter({1: 620, 4: 428, 0: 161, 3: 129, 5: 119, 2: 100})\n",
      "Counter({3: 51, 1: 45, 0: 14, 2: 13})\n",
      "Counter({1: 186, 4: 134, 0: 63, 3: 51, 2: 26})\n",
      "Counter({1: 622, 0: 134})\n",
      "Res: Accuracy: 0.31196581196581197 # Scores: (0.18216357401293962, 0.18764488716096328, 0.18184750386279525, None)\n",
      "Wei: Accuracy: 0.4594594594594595 # Scores: (0.2517543859649123, 0.31666666666666665, 0.2805010893246187, None)\n",
      "Bld: Accuracy: 0.36231884057971014 # Scores: (0.2844871794871795, 0.25505122896427246, 0.24380617671756913, None)\n",
      "Ask: Accuracy: 0.7929515418502202 # Scores: (0.5803327877795963, 0.6057071069633884, 0.5885302171313973, None)\n",
      "600\n",
      "Counter({1: 620, 4: 428, 0: 161, 3: 129, 5: 119, 2: 100})\n",
      "Counter({3: 51, 1: 45, 0: 14, 2: 13})\n",
      "Counter({1: 186, 4: 134, 0: 63, 3: 51, 2: 26})\n",
      "Counter({1: 622, 0: 134})\n",
      "Res: Accuracy: 0.31196581196581197 # Scores: (0.18260483843284622, 0.18807538890380102, 0.18229949551400412, None)\n",
      "Wei: Accuracy: 0.4594594594594595 # Scores: (0.2583333333333333, 0.31666666666666665, 0.2845117845117845, None)\n",
      "Bld: Accuracy: 0.36231884057971014 # Scores: (0.28836295283663704, 0.2581108102847233, 0.2494859437050982, None)\n",
      "Ask: Accuracy: 0.7929515418502202 # Scores: (0.5803327877795963, 0.6057071069633884, 0.5885302171313973, None)\n",
      "700\n",
      "Counter({1: 620, 4: 428, 0: 161, 3: 129, 5: 119, 2: 100})\n",
      "Counter({3: 51, 1: 45, 0: 14, 2: 13})\n",
      "Counter({1: 186, 4: 134, 0: 63, 3: 51, 2: 26})\n",
      "Counter({1: 622, 0: 134})\n",
      "Res: Accuracy: 0.31196581196581197 # Scores: (0.18556479599681577, 0.18807538890380102, 0.18329422162499487, None)\n",
      "Wei: Accuracy: 0.4864864864864865 # Scores: (0.2744360902255639, 0.3333333333333333, 0.3009049773755656, None)\n",
      "Bld: Accuracy: 0.36231884057971014 # Scores: (0.28836295283663704, 0.2581108102847233, 0.2494859437050982, None)\n",
      "Ask: Accuracy: 0.788546255506608 # Scores: (0.5768716577540107, 0.6031945441493181, 0.5848826577263029, None)\n",
      "800\n",
      "Counter({1: 620, 4: 428, 0: 161, 3: 129, 5: 119, 2: 100})\n",
      "Counter({3: 51, 1: 45, 0: 14, 2: 13})\n",
      "Counter({1: 186, 4: 134, 0: 63, 3: 51, 2: 26})\n",
      "Counter({1: 622, 0: 134})\n",
      "Res: Accuracy: 0.3076923076923077 # Scores: (0.18486811303445036, 0.18950388901996515, 0.1842879822944483, None)\n",
      "Wei: Accuracy: 0.4864864864864865 # Scores: (0.2744360902255639, 0.3333333333333333, 0.3009049773755656, None)\n",
      "Bld: Accuracy: 0.36231884057971014 # Scores: (0.28836295283663704, 0.2581108102847233, 0.2494859437050982, None)\n",
      "Ask: Accuracy: 0.788546255506608 # Scores: (0.5768716577540107, 0.6031945441493181, 0.5848826577263029, None)\n",
      "900\n",
      "Counter({1: 620, 4: 428, 0: 161, 3: 129, 5: 119, 2: 100})\n",
      "Counter({3: 51, 1: 45, 0: 14, 2: 13})\n",
      "Counter({1: 186, 4: 134, 0: 63, 3: 51, 2: 26})\n",
      "Counter({1: 622, 0: 134})\n",
      "Res: Accuracy: 0.3076923076923077 # Scores: (0.18374439880720705, 0.1863117204734659, 0.18181003525254683, None)\n",
      "Wei: Accuracy: 0.4594594594594595 # Scores: (0.2583333333333333, 0.31666666666666665, 0.2845117845117845, None)\n",
      "Bld: Accuracy: 0.36231884057971014 # Scores: (0.2897566810596336, 0.2581108102847233, 0.2502266844458389, None)\n",
      "Ask: Accuracy: 0.7841409691629956 # Scores: (0.5554765291607398, 0.5699928212491027, 0.5600949179355349, None)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "label='Drug'\n",
    "asklabel='Drug'\n",
    "res_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "wei_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "bld_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "ask_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "result,result_labels,weighted,weighted_labels,blood,blood_labels,ask,ask_labels=prepareDatasetNoSmote(label,asklabel)\n",
    "   \n",
    "for estimators in range (100,1000,100):\n",
    "    print (estimators)\n",
    "    res_acc,res_scores=randomForest(result,result_labels,estimators,\"Result\")\n",
    "    wei_acc,wei_scores=randomForest(weighted,weighted_labels,estimators,\"Weighted\")\n",
    "    blood_acc,blood_scores=randomForest(blood,blood_labels,estimators,\"Blood\")\n",
    "    ask_acc,ask_scores=randomForest(ask,ask_labels,estimators,\"Ask\")\n",
    "    print(\"Res: Accuracy: \" + str(res_acc)+\" # \"+ \"Scores: \"+str(res_scores))\n",
    "    print(\"Wei: Accuracy: \" + str(wei_acc)+\" # \"+ \"Scores: \"+str(wei_scores))\n",
    "    print(\"Bld: Accuracy: \" + str(blood_acc)+\" # \"+ \"Scores: \"+str(blood_scores))\n",
    "    print(\"Ask: Accuracy: \" + str(ask_acc)+\" # \"+ \"Scores: \"+str(ask_scores))\n",
    "    res_Stats=res_Stats.append({'Estimators':estimators,'Accuracy':res_acc,'Precision':res_scores[0],'Recall':res_scores[1],'FScore':res_scores[2]},ignore_index=True)\n",
    "    wei_Stats=wei_Stats.append({'Estimators':estimators,'Accuracy':wei_acc,'Precision':wei_scores[0],'Recall':wei_scores[1],'FScore':wei_scores[2]},ignore_index=True)\n",
    "    bld_Stats=bld_Stats.append({'Estimators':estimators,'Accuracy':blood_acc,'Precision':blood_scores[0],'Recall':blood_scores[1],'FScore':blood_scores[2]},ignore_index=True)\n",
    "    ask_Stats=ask_Stats.append({'Estimators':estimators,'Accuracy':ask_acc,'Precision':ask_scores[0],'Recall':ask_scores[1],'FScore':ask_scores[2]},ignore_index=True)\n",
    "'''writer = pd.ExcelWriter('Forrest_Stats'+label+'.xlsx', engine='xlsxwriter')\n",
    "res_Stats.to_excel(writer, sheet_name='Sheet1') \n",
    "wei_Stats.to_excel(writer, sheet_name='Sheet2') \n",
    "bld_Stats.to_excel(writer, sheet_name='Sheet3') \n",
    "ask_Stats.to_excel(writer, sheet_name='Sheet4')\n",
    "writer.save()'''\n",
    "\n",
    "x1=res_Stats['FScore'].tolist().index(max(res_Stats['FScore'].tolist()))\n",
    "x2=wei_Stats['FScore'].tolist().index(max(wei_Stats['FScore'].tolist()))\n",
    "x3=bld_Stats['FScore'].tolist().index(max(bld_Stats['FScore'].tolist()))\n",
    "x4=ask_Stats['FScore'].tolist().index(max(ask_Stats['FScore'].tolist()))\n",
    "max_res=res_Stats.iloc[x1].to_frame().transpose()\n",
    "max_wei=wei_Stats.iloc[x2].to_frame().transpose()\n",
    "max_bld=bld_Stats.iloc[x3].to_frame().transpose()\n",
    "max_ask=ask_Stats.iloc[x4].to_frame().transpose()\n",
    "stats=pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "max_res['Estimators']=\"Complete\"\n",
    "max_wei['Estimators']=\"Weighted\"\n",
    "max_bld['Estimators']=\"Pressure\"\n",
    "max_ask['Estimators']=\"Ask\"\n",
    "stats=stats.append(max_res)\n",
    "stats=stats.append(max_wei)\n",
    "stats=stats.append(max_bld)\n",
    "stats=stats.append(max_ask)\n",
    "\n",
    "plotResult(label+\" Random Forest Without Smote\",max_res,max_wei,max_bld,max_ask,x1,x2,x3,x4)\n",
    "\n",
    "\n",
    "import os.path\n",
    "if not os.path.exists('Forrest_StatsSmotelessTotal'+'.xlsx'):\n",
    "    writer = pd.ExcelWriter('Forrest_StatsSmotelessTotal'+'.xlsx', engine = 'xlsxwriter')\n",
    "\n",
    "    writer.save()\n",
    "    writer.close()\n",
    "writer = pd.ExcelWriter('Forrest_StatsSmotelessTotal'+'.xlsx', engine='openpyxl')\n",
    "book = load_workbook('Forrest_StatsSmotelessTotal'+'.xlsx')\n",
    "writer.book = book\n",
    "writer.sheets = dict((ws.title, ws) for ws in book.worksheets)\n",
    "\n",
    "stats.to_excel(writer, sheet_name=label)\n",
    "writer.save()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest With Importance Filtering and Without Smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "Counter({'Atenolol': 620, 'Lisinopril': 428, 'Amlodipine': 161, 'Hydrochlorothiazide': 129, 'Nadolol': 119, 'Diltiazem': 100})\n",
      "Counter({'Lisinopril': 51, 'Atenolol': 45, 'Amlodipine': 14, 'Hydrochlorothiazide': 13})\n",
      "Counter({'Atenolol': 186, 'Lisinopril': 134, 'Amlodipine': 63, 'Hydrochlorothiazide': 51, 'Diltiazem': 26})\n",
      "Counter({'Lisinopril': 622, 'Atenolol': 134})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 620, 4: 428, 0: 161, 3: 129, 5: 119, 2: 100})\n",
      "Counter({3: 51, 1: 45, 0: 14, 2: 13})\n",
      "Counter({1: 186, 4: 134, 0: 63, 3: 51, 2: 26})\n",
      "Counter({1: 622, 0: 134})\n",
      "Res: Accuracy: 0.3333333333333333 # Scores: (0.23483491292957312, 0.21227430914110704, 0.21088343660003803, None)\n",
      "Wei: Accuracy: 0.43243243243243246 # Scores: (0.2957983193277311, 0.3291666666666667, 0.3086206896551724, None)\n",
      "Bld: Accuracy: 0.34057971014492755 # Scores: (0.23772910188403146, 0.24122737166215424, 0.2304187120931307, None)\n",
      "Ask: Accuracy: 0.8061674008810573 # Scores: (0.5518664752333093, 0.5518664752333093, 0.5518664752333093, None)\n",
      "200\n",
      "Counter({'Atenolol': 620, 'Lisinopril': 428, 'Amlodipine': 161, 'Hydrochlorothiazide': 129, 'Nadolol': 119, 'Diltiazem': 100})\n",
      "Counter({'Lisinopril': 51, 'Atenolol': 45, 'Amlodipine': 14, 'Hydrochlorothiazide': 13})\n",
      "Counter({'Atenolol': 186, 'Lisinopril': 134, 'Amlodipine': 63, 'Hydrochlorothiazide': 51, 'Diltiazem': 26})\n",
      "Counter({'Lisinopril': 622, 'Atenolol': 134})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 620, 4: 428, 0: 161, 3: 129, 5: 119, 2: 100})\n",
      "Counter({3: 51, 1: 45, 0: 14, 2: 13})\n",
      "Counter({1: 186, 4: 134, 0: 63, 3: 51, 2: 26})\n",
      "Counter({1: 622, 0: 134})\n",
      "Res: Accuracy: 0.344017094017094 # Scores: (0.23297433346536486, 0.21364848632729208, 0.20917717927261828, None)\n",
      "Wei: Accuracy: 0.43243243243243246 # Scores: (0.3177083333333333, 0.36250000000000004, 0.3365987460815047, None)\n",
      "Bld: Accuracy: 0.3333333333333333 # Scores: (0.24312573443008226, 0.23765992461644636, 0.22989323786667093, None)\n",
      "Ask: Accuracy: 0.7929515418502202 # Scores: (0.5406517445687953, 0.5443287867910983, 0.5422012443681613, None)\n",
      "300\n",
      "Counter({'Atenolol': 620, 'Lisinopril': 428, 'Amlodipine': 161, 'Hydrochlorothiazide': 129, 'Nadolol': 119, 'Diltiazem': 100})\n",
      "Counter({'Lisinopril': 51, 'Atenolol': 45, 'Amlodipine': 14, 'Hydrochlorothiazide': 13})\n",
      "Counter({'Atenolol': 186, 'Lisinopril': 134, 'Amlodipine': 63, 'Hydrochlorothiazide': 51, 'Diltiazem': 26})\n",
      "Counter({'Lisinopril': 622, 'Atenolol': 134})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 620, 4: 428, 0: 161, 3: 129, 5: 119, 2: 100})\n",
      "Counter({3: 51, 1: 45, 0: 14, 2: 13})\n",
      "Counter({1: 186, 4: 134, 0: 63, 3: 51, 2: 26})\n",
      "Counter({1: 622, 0: 134})\n",
      "Res: Accuracy: 0.34615384615384615 # Scores: (0.22059604564848798, 0.21569565631245421, 0.2080620013031572, None)\n",
      "Wei: Accuracy: 0.43243243243243246 # Scores: (0.3177083333333333, 0.36250000000000004, 0.3365987460815047, None)\n",
      "Bld: Accuracy: 0.32608695652173914 # Scores: (0.23200604331039115, 0.23253171948824125, 0.22323635174893758, None)\n",
      "Ask: Accuracy: 0.7929515418502202 # Scores: (0.5406517445687953, 0.5443287867910983, 0.5422012443681613, None)\n",
      "400\n",
      "Counter({'Atenolol': 620, 'Lisinopril': 428, 'Amlodipine': 161, 'Hydrochlorothiazide': 129, 'Nadolol': 119, 'Diltiazem': 100})\n",
      "Counter({'Lisinopril': 51, 'Atenolol': 45, 'Amlodipine': 14, 'Hydrochlorothiazide': 13})\n",
      "Counter({'Atenolol': 186, 'Lisinopril': 134, 'Amlodipine': 63, 'Hydrochlorothiazide': 51, 'Diltiazem': 26})\n",
      "Counter({'Lisinopril': 622, 'Atenolol': 134})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 620, 4: 428, 0: 161, 3: 129, 5: 119, 2: 100})\n",
      "Counter({3: 51, 1: 45, 0: 14, 2: 13})\n",
      "Counter({1: 186, 4: 134, 0: 63, 3: 51, 2: 26})\n",
      "Counter({1: 622, 0: 134})\n",
      "Res: Accuracy: 0.3418803418803419 # Scores: (0.24351237328043415, 0.21061414339793605, 0.20732007833474184, None)\n",
      "Wei: Accuracy: 0.43243243243243246 # Scores: (0.24812030075187969, 0.3, 0.26696329254727474, None)\n",
      "Bld: Accuracy: 0.3333333333333333 # Scores: (0.23295429208472687, 0.23687954557519775, 0.22575923271575443, None)\n",
      "Ask: Accuracy: 0.7929515418502202 # Scores: (0.5406517445687953, 0.5443287867910983, 0.5422012443681613, None)\n",
      "500\n",
      "Counter({'Atenolol': 620, 'Lisinopril': 428, 'Amlodipine': 161, 'Hydrochlorothiazide': 129, 'Nadolol': 119, 'Diltiazem': 100})\n",
      "Counter({'Lisinopril': 51, 'Atenolol': 45, 'Amlodipine': 14, 'Hydrochlorothiazide': 13})\n",
      "Counter({'Atenolol': 186, 'Lisinopril': 134, 'Amlodipine': 63, 'Hydrochlorothiazide': 51, 'Diltiazem': 26})\n",
      "Counter({'Lisinopril': 622, 'Atenolol': 134})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 620, 4: 428, 0: 161, 3: 129, 5: 119, 2: 100})\n",
      "Counter({3: 51, 1: 45, 0: 14, 2: 13})\n",
      "Counter({1: 186, 4: 134, 0: 63, 3: 51, 2: 26})\n",
      "Counter({1: 622, 0: 134})\n",
      "Res: Accuracy: 0.33974358974358976 # Scores: (0.2288067079111166, 0.20725676635289494, 0.20190906062055583, None)\n",
      "Wei: Accuracy: 0.43243243243243246 # Scores: (0.3177083333333333, 0.36250000000000004, 0.3365987460815047, None)\n",
      "Bld: Accuracy: 0.32608695652173914 # Scores: (0.2215284062342886, 0.23175134044699258, 0.21924532683153375, None)\n",
      "Ask: Accuracy: 0.7797356828193832 # Scores: (0.5312404754647974, 0.5367910983488873, 0.5329986833443054, None)\n",
      "600\n",
      "Counter({'Atenolol': 620, 'Lisinopril': 428, 'Amlodipine': 161, 'Hydrochlorothiazide': 129, 'Nadolol': 119, 'Diltiazem': 100})\n",
      "Counter({'Lisinopril': 51, 'Atenolol': 45, 'Amlodipine': 14, 'Hydrochlorothiazide': 13})\n",
      "Counter({'Atenolol': 186, 'Lisinopril': 134, 'Amlodipine': 63, 'Hydrochlorothiazide': 51, 'Diltiazem': 26})\n",
      "Counter({'Lisinopril': 622, 'Atenolol': 134})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 620, 4: 428, 0: 161, 3: 129, 5: 119, 2: 100})\n",
      "Counter({3: 51, 1: 45, 0: 14, 2: 13})\n",
      "Counter({1: 186, 4: 134, 0: 63, 3: 51, 2: 26})\n",
      "Counter({1: 622, 0: 134})\n",
      "Res: Accuracy: 0.3482905982905983 # Scores: (0.23886601189878556, 0.21541215475762718, 0.20979932069267146, None)\n",
      "Wei: Accuracy: 0.43243243243243246 # Scores: (0.24812030075187969, 0.3, 0.26696329254727474, None)\n",
      "Bld: Accuracy: 0.32608695652173914 # Scores: (0.22118632502264218, 0.23175134044699258, 0.21938315265546388, None)\n",
      "Ask: Accuracy: 0.7797356828193832 # Scores: (0.5312404754647974, 0.5367910983488873, 0.5329986833443054, None)\n",
      "700\n",
      "Counter({'Atenolol': 620, 'Lisinopril': 428, 'Amlodipine': 161, 'Hydrochlorothiazide': 129, 'Nadolol': 119, 'Diltiazem': 100})\n",
      "Counter({'Lisinopril': 51, 'Atenolol': 45, 'Amlodipine': 14, 'Hydrochlorothiazide': 13})\n",
      "Counter({'Atenolol': 186, 'Lisinopril': 134, 'Amlodipine': 63, 'Hydrochlorothiazide': 51, 'Diltiazem': 26})\n",
      "Counter({'Lisinopril': 622, 'Atenolol': 134})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 620, 4: 428, 0: 161, 3: 129, 5: 119, 2: 100})\n",
      "Counter({3: 51, 1: 45, 0: 14, 2: 13})\n",
      "Counter({1: 186, 4: 134, 0: 63, 3: 51, 2: 26})\n",
      "Counter({1: 622, 0: 134})\n",
      "Res: Accuracy: 0.3482905982905983 # Scores: (0.22061489708548535, 0.21336711367059136, 0.20401709207544527, None)\n",
      "Wei: Accuracy: 0.43243243243243246 # Scores: (0.24812030075187969, 0.3, 0.26696329254727474, None)\n",
      "Bld: Accuracy: 0.3188405797101449 # Scores: (0.21801619433198377, 0.22740351436003609, 0.21604516341358443, None)\n",
      "Ask: Accuracy: 0.7797356828193832 # Scores: (0.5312404754647974, 0.5367910983488873, 0.5329986833443054, None)\n",
      "800\n",
      "Counter({'Atenolol': 620, 'Lisinopril': 428, 'Amlodipine': 161, 'Hydrochlorothiazide': 129, 'Nadolol': 119, 'Diltiazem': 100})\n",
      "Counter({'Lisinopril': 51, 'Atenolol': 45, 'Amlodipine': 14, 'Hydrochlorothiazide': 13})\n",
      "Counter({'Atenolol': 186, 'Lisinopril': 134, 'Amlodipine': 63, 'Hydrochlorothiazide': 51, 'Diltiazem': 26})\n",
      "Counter({'Lisinopril': 622, 'Atenolol': 134})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 620, 4: 428, 0: 161, 3: 129, 5: 119, 2: 100})\n",
      "Counter({3: 51, 1: 45, 0: 14, 2: 13})\n",
      "Counter({1: 186, 4: 134, 0: 63, 3: 51, 2: 26})\n",
      "Counter({1: 622, 0: 134})\n",
      "Res: Accuracy: 0.3418803418803419 # Scores: (0.22978783959785054, 0.21140132130945777, 0.20510178412477265, None)\n",
      "Wei: Accuracy: 0.43243243243243246 # Scores: (0.24812030075187969, 0.3, 0.26696329254727474, None)\n",
      "Bld: Accuracy: 0.3188405797101449 # Scores: (0.21586770717205503, 0.22740351436003609, 0.21539452495974235, None)\n",
      "Ask: Accuracy: 0.7973568281938326 # Scores: (0.5441624365482234, 0.5468413496051687, 0.5453674677812609, None)\n",
      "900\n",
      "Counter({'Atenolol': 620, 'Lisinopril': 428, 'Amlodipine': 161, 'Hydrochlorothiazide': 129, 'Nadolol': 119, 'Diltiazem': 100})\n",
      "Counter({'Lisinopril': 51, 'Atenolol': 45, 'Amlodipine': 14, 'Hydrochlorothiazide': 13})\n",
      "Counter({'Atenolol': 186, 'Lisinopril': 134, 'Amlodipine': 63, 'Hydrochlorothiazide': 51, 'Diltiazem': 26})\n",
      "Counter({'Lisinopril': 622, 'Atenolol': 134})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 620, 4: 428, 0: 161, 3: 129, 5: 119, 2: 100})\n",
      "Counter({3: 51, 1: 45, 0: 14, 2: 13})\n",
      "Counter({1: 186, 4: 134, 0: 63, 3: 51, 2: 26})\n",
      "Counter({1: 622, 0: 134})\n",
      "Res: Accuracy: 0.3504273504273504 # Scores: (0.20486454971047538, 0.21085727782742222, 0.2022710861274368, None)\n",
      "Wei: Accuracy: 0.43243243243243246 # Scores: (0.24812030075187969, 0.3, 0.26696329254727474, None)\n",
      "Bld: Accuracy: 0.3188405797101449 # Scores: (0.21436620567055353, 0.22740351436003609, 0.21469277057377742, None)\n",
      "Ask: Accuracy: 0.7973568281938326 # Scores: (0.5441624365482234, 0.5468413496051687, 0.5453674677812609, None)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "label='Drug'\n",
    "asklabel='Drug'\n",
    "res_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "wei_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "bld_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "ask_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "for estimators in range (100,1000,100):\n",
    "    print (estimators)\n",
    "    result,result_labels,weighted,weighted_labels,blood,blood_labels,ask,ask_labels=prepareDatasetNoSmote(label,asklabel)\n",
    "    res_feat=importance(result,result_labels)\n",
    "    wei_feat=importance(weighted,weighted_labels)\n",
    "    blood_feat=importance(blood,blood_labels)\n",
    "    ask_feat=importance(ask,ask_labels)\n",
    "    res_acc,res_scores=randomForest(pd.DataFrame(result)[res_feat],result_labels,estimators,\"Result\")\n",
    "    wei_acc,wei_scores=randomForest(pd.DataFrame(weighted)[wei_feat],weighted_labels,estimators,\"Weighted\")\n",
    "    blood_acc,blood_scores=randomForest(pd.DataFrame(blood)[blood_feat],blood_labels,estimators,\"Blood\")\n",
    "    ask_acc,ask_scores=randomForest(pd.DataFrame(ask)[ask_feat],ask_labels,estimators,\"Ask\")\n",
    "    print(\"Res: Accuracy: \" + str(res_acc)+\" # \"+ \"Scores: \"+str(res_scores))\n",
    "    print(\"Wei: Accuracy: \" + str(wei_acc)+\" # \"+ \"Scores: \"+str(wei_scores))\n",
    "    print(\"Bld: Accuracy: \" + str(blood_acc)+\" # \"+ \"Scores: \"+str(blood_scores))\n",
    "    print(\"Ask: Accuracy: \" + str(ask_acc)+\" # \"+ \"Scores: \"+str(ask_scores))\n",
    "    res_Stats=res_Stats.append({'Estimators':estimators,'Accuracy':res_acc,'Precision':res_scores[0],'Recall':res_scores[1],'FScore':res_scores[2]},ignore_index=True)\n",
    "    wei_Stats=wei_Stats.append({'Estimators':estimators,'Accuracy':wei_acc,'Precision':wei_scores[0],'Recall':wei_scores[1],'FScore':wei_scores[2]},ignore_index=True)\n",
    "    bld_Stats=bld_Stats.append({'Estimators':estimators,'Accuracy':blood_acc,'Precision':blood_scores[0],'Recall':blood_scores[1],'FScore':blood_scores[2]},ignore_index=True)\n",
    "    ask_Stats=ask_Stats.append({'Estimators':estimators,'Accuracy':ask_acc,'Precision':ask_scores[0],'Recall':ask_scores[1],'FScore':ask_scores[2]},ignore_index=True)\n",
    "\n",
    "'''writer = pd.ExcelWriter('Forrest_Stats'+label+'.xlsx', engine='xlsxwriter')\n",
    "res_Stats.to_excel(writer, sheet_name='Sheet1') \n",
    "wei_Stats.to_excel(writer, sheet_name='Sheet2') \n",
    "bld_Stats.to_excel(writer, sheet_name='Sheet3') \n",
    "ask_Stats.to_excel(writer, sheet_name='Sheet4')\n",
    "writer.save()'''\n",
    "\n",
    "x1=res_Stats['FScore'].tolist().index(max(res_Stats['FScore'].tolist()))\n",
    "x2=wei_Stats['FScore'].tolist().index(max(wei_Stats['FScore'].tolist()))\n",
    "x3=bld_Stats['FScore'].tolist().index(max(bld_Stats['FScore'].tolist()))\n",
    "x4=ask_Stats['FScore'].tolist().index(max(ask_Stats['FScore'].tolist()))\n",
    "max_res=res_Stats.iloc[x1].to_frame().transpose()\n",
    "max_wei=wei_Stats.iloc[x2].to_frame().transpose()\n",
    "max_bld=bld_Stats.iloc[x3].to_frame().transpose()\n",
    "max_ask=ask_Stats.iloc[x4].to_frame().transpose()\n",
    "stats=pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "max_res['Estimators']=\"Complete\"\n",
    "max_wei['Estimators']=\"Weighted\"\n",
    "max_bld['Estimators']=\"Pressure\"\n",
    "max_ask['Estimators']=\"Ask\"\n",
    "stats=stats.append(max_res)\n",
    "stats=stats.append(max_wei)\n",
    "stats=stats.append(max_bld)\n",
    "stats=stats.append(max_ask)\n",
    "\n",
    "plotResult(label+\" Random Forest With Feature Filtering and Without Smote\",max_res,max_wei,max_bld,max_ask,x1,x2,x3,x4)\n",
    "\n",
    "\n",
    "import os.path\n",
    "if not os.path.exists('Forrest_StatsSmotelessImportanceTotal'+'.xlsx'):\n",
    "    writer = pd.ExcelWriter('Forrest_StatsSmotelessImportanceTotal'+'.xlsx', engine = 'xlsxwriter')\n",
    "\n",
    "    writer.save()\n",
    "    writer.close()\n",
    "writer = pd.ExcelWriter('Forrest_StatsSmotelessImportanceTotal'+'.xlsx', engine='openpyxl')\n",
    "book = load_workbook('Forrest_StatsSmotelessImportanceTotal'+'.xlsx')\n",
    "writer.book = book\n",
    "writer.sheets = dict((ws.title, ws) for ws in book.worksheets)\n",
    "\n",
    "stats.to_excel(writer, sheet_name=label)\n",
    "writer.save()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier Function 10-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average(scores):\n",
    "    FScore=0\n",
    "    Recall=0\n",
    "    Precision=0\n",
    "\n",
    "    for i in scores:\n",
    "        Precision+=i[0]\n",
    "        Recall+=i[1]\n",
    "        FScore+=i[2]\n",
    "    return (Precision/10,Recall/10,FScore/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomForest10Fold(result,result_labels,estimators,DataSet):\n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn.metrics import f1_score\n",
    "    from collections import Counter\n",
    "    kf = KFold(n_splits=10)\n",
    "\n",
    "    accuracy=[]\n",
    "\n",
    "    scores_rf=[]\n",
    "    print(Counter(result_labels))\n",
    "    count = 1\n",
    "    for train_index, test_index in kf.split(result):\n",
    "        X_train, X_test, Y_train, Y_test = result[train_index], result[test_index], result_labels[train_index],result_labels[test_index]\n",
    "        clf = RandomForestClassifier(n_estimators=estimators, max_depth=2,random_state=0)\n",
    "        clf.fit(X_train, Y_train)\n",
    "        pred=clf.predict(X_test)\n",
    "        accuracy.append(accuracy_score(Y_test, pred))\n",
    "        scores_rf.append(precision_recall_fscore_support(Y_test,pred, average='macro'))\n",
    "        \n",
    "        #print(str(count)+DataSet)\n",
    "        #print(f1_score(Y_test, pred, average='micro'))\n",
    "        count+=1\n",
    "        #print (pred)\n",
    "        #print(classification_report(Y_test,pred,labels=[0,1]))\n",
    "    accuracy = np.mean(accuracy,axis=0)   \n",
    "    return accuracy,average(scores_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomForest10FoldNotSmote(result,result_labels,estimators,DataSet):\n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn.metrics import f1_score\n",
    "    from collections import Counter\n",
    "    kf = KFold(n_splits=10)\n",
    "\n",
    "    accuracy=[]\n",
    "\n",
    "    scores_rf=[]\n",
    "    print(Counter(result_labels))\n",
    "    count = 1\n",
    "    for train_index, test_index in kf.split(result):\n",
    "        X_train, X_test, Y_train, Y_test = result.iloc[train_index], result.iloc[test_index], result_labels[train_index],result_labels[test_index]\n",
    "        clf = RandomForestClassifier(n_estimators=estimators, max_depth=2,random_state=0)\n",
    "        clf.fit(X_train, Y_train)\n",
    "        pred=clf.predict(X_test)\n",
    "        accuracy.append(accuracy_score(Y_test, pred))\n",
    "        scores_rf.append(precision_recall_fscore_support(Y_test,pred, average='macro'))\n",
    "        \n",
    "        #print(str(count)+DataSet)\n",
    "        #print(f1_score(Y_test, pred, average='micro'))\n",
    "        count+=1\n",
    "        #print (pred)\n",
    "        #print(classification_report(Y_test,pred,labels=[0,1]))\n",
    "    accuracy = np.mean(accuracy,axis=0)   \n",
    "    return accuracy,average(scores_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with 10-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Atenolol': 620, 'Lisinopril': 428, 'Amlodipine': 161, 'Hydrochlorothiazide': 129, 'Nadolol': 119, 'Diltiazem': 100})\n",
      "Counter({'Lisinopril': 51, 'Atenolol': 45, 'Amlodipine': 14, 'Hydrochlorothiazide': 13})\n",
      "Counter({'Atenolol': 186, 'Lisinopril': 134, 'Amlodipine': 63, 'Hydrochlorothiazide': 51, 'Diltiazem': 26})\n",
      "Counter({'Lisinopril': 622, 'Atenolol': 134})\n",
      "Counter({0: 620, 2: 620, 3: 620, 1: 620, 4: 620, 5: 620})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 51, 2: 51, 1: 51, 3: 51})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 186, 2: 186, 3: 186, 1: 186, 4: 186})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 622, 0: 622})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Res: Accuracy: 0.040860215053763436 # Scores: (0.0577160843723052, 0.03433366000595907, 0.027965711503169705)\n",
      "Wei: Accuracy: 0.19166666666666665 # Scores: (0.27375000000000005, 0.12514515455304928, 0.13567045608712275)\n",
      "Bld: Accuracy: 0.0838709677419355 # Scores: (0.1151192093347266, 0.09026073968184188, 0.05673552273552272)\n",
      "Ask: Accuracy: 0.6203483870967742 # Scores: (0.5022222222222222, 0.35988995240613425, 0.3800583199425489)\n",
      "Counter({'Atenolol': 620, 'Lisinopril': 428, 'Amlodipine': 161, 'Hydrochlorothiazide': 129, 'Nadolol': 119, 'Diltiazem': 100})\n",
      "Counter({'Lisinopril': 51, 'Atenolol': 45, 'Amlodipine': 14, 'Hydrochlorothiazide': 13})\n",
      "Counter({'Atenolol': 186, 'Lisinopril': 134, 'Amlodipine': 63, 'Hydrochlorothiazide': 51, 'Diltiazem': 26})\n",
      "Counter({'Lisinopril': 622, 'Atenolol': 134})\n",
      "Counter({0: 620, 2: 620, 3: 620, 1: 620, 4: 620, 5: 620})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 51, 2: 51, 1: 51, 3: 51})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 186, 2: 186, 3: 186, 1: 186, 4: 186})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 622, 0: 622})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Res: Accuracy: 0.03870967741935484 # Scores: (0.058589794104641935, 0.03303424704951881, 0.027000651306221934)\n",
      "Wei: Accuracy: 0.18666666666666665 # Scores: (0.28208333333333335, 0.12472848788638262, 0.13852061827061823)\n",
      "Bld: Accuracy: 0.08387096774193549 # Scores: (0.1190058944886531, 0.08914740288889947, 0.05660295847576534)\n",
      "Ask: Accuracy: 0.6203483870967742 # Scores: (0.5022222222222222, 0.35988995240613425, 0.3800583199425489)\n",
      "Counter({'Atenolol': 620, 'Lisinopril': 428, 'Amlodipine': 161, 'Hydrochlorothiazide': 129, 'Nadolol': 119, 'Diltiazem': 100})\n",
      "Counter({'Lisinopril': 51, 'Atenolol': 45, 'Amlodipine': 14, 'Hydrochlorothiazide': 13})\n",
      "Counter({'Atenolol': 186, 'Lisinopril': 134, 'Amlodipine': 63, 'Hydrochlorothiazide': 51, 'Diltiazem': 26})\n",
      "Counter({'Lisinopril': 622, 'Atenolol': 134})\n",
      "Counter({0: 620, 2: 620, 3: 620, 1: 620, 4: 620, 5: 620})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 51, 2: 51, 1: 51, 3: 51})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 186, 2: 186, 3: 186, 1: 186, 4: 186})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 622, 0: 622})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Res: Accuracy: 0.034408602150537634 # Scores: (0.05583346339244706, 0.030510774566491226, 0.0246955079626585)\n",
      "Wei: Accuracy: 0.17190476190476192 # Scores: (0.25604166666666667, 0.11138027360066834, 0.11690708233227416)\n",
      "Bld: Accuracy: 0.08279569892473118 # Scores: (0.1199230399230399, 0.08509438061954636, 0.057156393309537076)\n",
      "Ask: Accuracy: 0.6203483870967742 # Scores: (0.5022222222222222, 0.35988995240613425, 0.3800583199425489)\n",
      "Counter({'Atenolol': 620, 'Lisinopril': 428, 'Amlodipine': 161, 'Hydrochlorothiazide': 129, 'Nadolol': 119, 'Diltiazem': 100})\n",
      "Counter({'Lisinopril': 51, 'Atenolol': 45, 'Amlodipine': 14, 'Hydrochlorothiazide': 13})\n",
      "Counter({'Atenolol': 186, 'Lisinopril': 134, 'Amlodipine': 63, 'Hydrochlorothiazide': 51, 'Diltiazem': 26})\n",
      "Counter({'Lisinopril': 622, 'Atenolol': 134})\n",
      "Counter({0: 620, 2: 620, 3: 620, 1: 620, 4: 620, 5: 620})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 51, 2: 51, 1: 51, 3: 51})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 186, 2: 186, 3: 186, 1: 186, 4: 186})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 622, 0: 622})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Res: Accuracy: 0.031451612903225803 # Scores: (0.05805597219800536, 0.028847666057225933, 0.023731659972265708)\n",
      "Wei: Accuracy: 0.16666666666666669 # Scores: (0.2348611111111111, 0.10659226190476193, 0.11400317766206511)\n",
      "Bld: Accuracy: 0.08494623655913978 # Scores: (0.11969755692329273, 0.09022882878008147, 0.057215588995930114)\n",
      "Ask: Accuracy: 0.6203483870967742 # Scores: (0.5022222222222222, 0.35988995240613425, 0.3800583199425489)\n",
      "Counter({'Atenolol': 620, 'Lisinopril': 428, 'Amlodipine': 161, 'Hydrochlorothiazide': 129, 'Nadolol': 119, 'Diltiazem': 100})\n",
      "Counter({'Lisinopril': 51, 'Atenolol': 45, 'Amlodipine': 14, 'Hydrochlorothiazide': 13})\n",
      "Counter({'Atenolol': 186, 'Lisinopril': 134, 'Amlodipine': 63, 'Hydrochlorothiazide': 51, 'Diltiazem': 26})\n",
      "Counter({'Lisinopril': 622, 'Atenolol': 134})\n",
      "Counter({0: 620, 2: 620, 3: 620, 1: 620, 4: 620, 5: 620})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 51, 2: 51, 1: 51, 3: 51})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 186, 2: 186, 3: 186, 1: 186, 4: 186})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 622, 0: 622})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Res: Accuracy: 0.03494623655913979 # Scores: (0.05667526617526617, 0.030822885534973216, 0.025327514244868198)\n",
      "Wei: Accuracy: 0.1869047619047619 # Scores: (0.25604166666666667, 0.115203373015873, 0.12197790882758577)\n",
      "Bld: Accuracy: 0.08279569892473118 # Scores: (0.11845343315184513, 0.08542882878008147, 0.055962265206394676)\n",
      "Ask: Accuracy: 0.6203483870967742 # Scores: (0.5022222222222222, 0.35988995240613425, 0.3800583199425489)\n",
      "Counter({'Atenolol': 620, 'Lisinopril': 428, 'Amlodipine': 161, 'Hydrochlorothiazide': 129, 'Nadolol': 119, 'Diltiazem': 100})\n",
      "Counter({'Lisinopril': 51, 'Atenolol': 45, 'Amlodipine': 14, 'Hydrochlorothiazide': 13})\n",
      "Counter({'Atenolol': 186, 'Lisinopril': 134, 'Amlodipine': 63, 'Hydrochlorothiazide': 51, 'Diltiazem': 26})\n",
      "Counter({'Lisinopril': 622, 'Atenolol': 134})\n",
      "Counter({0: 620, 2: 620, 3: 620, 1: 620, 4: 620, 5: 620})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 51, 2: 51, 1: 51, 3: 51})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 186, 2: 186, 3: 186, 1: 186, 4: 186})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 622, 0: 622})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Res: Accuracy: 0.03198924731182796 # Scores: (0.0578118202470127, 0.029241040798426758, 0.02398532060430983)\n",
      "Wei: Accuracy: 0.1869047619047619 # Scores: (0.2552380952380952, 0.115203373015873, 0.12248852974261845)\n",
      "Bld: Accuracy: 0.08064516129032259 # Scores: (0.11995257621031355, 0.0842340660959571, 0.05422967195747939)\n",
      "Ask: Accuracy: 0.6203483870967742 # Scores: (0.5022222222222222, 0.35988995240613425, 0.3800583199425489)\n",
      "Counter({'Atenolol': 620, 'Lisinopril': 428, 'Amlodipine': 161, 'Hydrochlorothiazide': 129, 'Nadolol': 119, 'Diltiazem': 100})\n",
      "Counter({'Lisinopril': 51, 'Atenolol': 45, 'Amlodipine': 14, 'Hydrochlorothiazide': 13})\n",
      "Counter({'Atenolol': 186, 'Lisinopril': 134, 'Amlodipine': 63, 'Hydrochlorothiazide': 51, 'Diltiazem': 26})\n",
      "Counter({'Lisinopril': 622, 'Atenolol': 134})\n",
      "Counter({0: 620, 2: 620, 3: 620, 1: 620, 4: 620, 5: 620})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 51, 2: 51, 1: 51, 3: 51})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 186, 2: 186, 3: 186, 1: 186, 4: 186})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 622, 0: 622})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Res: Accuracy: 0.031451612903225803 # Scores: (0.05882189239332096, 0.02903400146095264, 0.023773025232616714)\n",
      "Wei: Accuracy: 0.19190476190476188 # Scores: (0.2552380952380952, 0.11673115079365079, 0.12502352335312691)\n",
      "Bld: Accuracy: 0.08064516129032259 # Scores: (0.11910055469995502, 0.0842340660959571, 0.05416400976979725)\n",
      "Ask: Accuracy: 0.6203483870967742 # Scores: (0.5022222222222222, 0.35988995240613425, 0.3800583199425489)\n",
      "Counter({'Atenolol': 620, 'Lisinopril': 428, 'Amlodipine': 161, 'Hydrochlorothiazide': 129, 'Nadolol': 119, 'Diltiazem': 100})\n",
      "Counter({'Lisinopril': 51, 'Atenolol': 45, 'Amlodipine': 14, 'Hydrochlorothiazide': 13})\n",
      "Counter({'Atenolol': 186, 'Lisinopril': 134, 'Amlodipine': 63, 'Hydrochlorothiazide': 51, 'Diltiazem': 26})\n",
      "Counter({'Lisinopril': 622, 'Atenolol': 134})\n",
      "Counter({0: 620, 2: 620, 3: 620, 1: 620, 4: 620, 5: 620})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 51, 2: 51, 1: 51, 3: 51})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 186, 2: 186, 3: 186, 1: 186, 4: 186})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 622, 0: 622})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-013d75821925>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mwei_acc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwei_scores\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandomForest10Fold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweighted\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweighted_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mestimators\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Weighted\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mblood_acc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mblood_scores\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandomForest10Fold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblood\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mblood_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mestimators\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Blood\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mask_acc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mask_scores\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandomForest10Fold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mask_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Ask\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Res: Accuracy: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\" # \"\u001b[0m\u001b[1;33m+\u001b[0m \u001b[1;34m\"Scores: \"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres_scores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Wei: Accuracy: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwei_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\" # \"\u001b[0m\u001b[1;33m+\u001b[0m \u001b[1;34m\"Scores: \"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwei_scores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-7051873acdca>\u001b[0m in \u001b[0;36mrandomForest10Fold\u001b[1;34m(result, result_labels, estimators, DataSet)\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mresult_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mestimators\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mpred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0maccuracy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    317\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_more_estimators\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m                 tree = self._make_estimator(append=False,\n\u001b[1;32m--> 319\u001b[1;33m                                             random_state=random_state)\n\u001b[0m\u001b[0;32m    320\u001b[0m                 \u001b[0mtrees\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\base.py\u001b[0m in \u001b[0;36m_make_estimator\u001b[1;34m(self, append, random_state)\u001b[0m\n\u001b[0;32m    124\u001b[0m         \u001b[0msub\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mestimators\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \"\"\"\n\u001b[1;32m--> 126\u001b[1;33m         \u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_estimator_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m         estimator.set_params(**dict((p, getattr(self, p))\n\u001b[0;32m    128\u001b[0m                                     for p in self.estimator_params))\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mclone\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[0mnew_object_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[0mnew_object\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mnew_object_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m     \u001b[0mparams_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_object\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# quick sanity check of the parameters of the clone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mget_params\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    181\u001b[0m         \"\"\"\n\u001b[0;32m    182\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_param_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdeep\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'get_params'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_get_param_names\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m    153\u001b[0m         \u001b[0minit_signature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m         \u001b[1;31m# Consider the constructor parameters excluding 'self'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m         parameters = [p for p in init_signature.parameters.values()\n\u001b[0m\u001b[0;32m    156\u001b[0m                       if p.name != 'self' and p.kind != p.VAR_KEYWORD]\n\u001b[0;32m    157\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    154\u001b[0m         \u001b[1;31m# Consider the constructor parameters excluding 'self'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m         parameters = [p for p in init_signature.parameters.values()\n\u001b[1;32m--> 156\u001b[1;33m                       if p.name != 'self' and p.kind != p.VAR_KEYWORD]\n\u001b[0m\u001b[0;32m    157\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVAR_POSITIONAL\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "label='Drug'\n",
    "asklabel='Drug'\n",
    "\n",
    "res_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "wei_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "bld_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "ask_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "for estimators in range (100,1000,100):\n",
    "    result,result_labels,weighted,weighted_labels,blood,blood_labels,ask,ask_labels=prepareDataset(label,asklabel)\n",
    "    res_acc,res_scores=randomForest10Fold(result,result_labels,estimators,\"Result\")\n",
    "    wei_acc,wei_scores=randomForest10Fold(weighted,weighted_labels,estimators,\"Weighted\")\n",
    "    blood_acc,blood_scores=randomForest10Fold(blood,blood_labels,estimators,\"Blood\")\n",
    "    ask_acc,ask_scores=randomForest10Fold(ask,ask_labels,1000,\"Ask\")\n",
    "    print(\"Res: Accuracy: \" + str(res_acc)+\" # \"+ \"Scores: \"+str(res_scores))\n",
    "    print(\"Wei: Accuracy: \" + str(wei_acc)+\" # \"+ \"Scores: \"+str(wei_scores))\n",
    "    print(\"Bld: Accuracy: \" + str(blood_acc)+\" # \"+ \"Scores: \"+str(blood_scores))\n",
    "    print(\"Ask: Accuracy: \" + str(ask_acc)+\" # \"+ \"Scores: \"+str(ask_scores))\n",
    "    res_Stats=res_Stats.append({'Estimators':estimators,'Accuracy':res_acc,'Precision':res_scores[0],'Recall':res_scores[1],'FScore':res_scores[2]},ignore_index=True)\n",
    "    wei_Stats=wei_Stats.append({'Estimators':estimators,'Accuracy':wei_acc,'Precision':wei_scores[0],'Recall':wei_scores[1],'FScore':wei_scores[2]},ignore_index=True)\n",
    "    bld_Stats=bld_Stats.append({'Estimators':estimators,'Accuracy':blood_acc,'Precision':blood_scores[0],'Recall':blood_scores[1],'FScore':blood_scores[2]},ignore_index=True)\n",
    "    ask_Stats=ask_Stats.append({'Estimators':estimators,'Accuracy':ask_acc,'Precision':ask_scores[0],'Recall':ask_scores[1],'FScore':ask_scores[2]},ignore_index=True)\n",
    "writer = pd.ExcelWriter('ForrestFold_Stats'+label+'.xlsx', engine='xlsxwriter')\n",
    "res_Stats.to_excel(writer, sheet_name='Sheet1') \n",
    "wei_Stats.to_excel(writer, sheet_name='Sheet2') \n",
    "bld_Stats.to_excel(writer, sheet_name='Sheet3') \n",
    "ask_Stats.to_excel(writer, sheet_name='Sheet4')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Atenolol': 620, 'Lisinopril': 428, 'Amlodipine': 161, 'Hydrochlorothiazide': 129, 'Nadolol': 119, 'Diltiazem': 100})\n",
      "Counter({'Lisinopril': 51, 'Atenolol': 45, 'Amlodipine': 14, 'Hydrochlorothiazide': 13})\n",
      "Counter({'Atenolol': 186, 'Lisinopril': 134, 'Amlodipine': 63, 'Hydrochlorothiazide': 51, 'Diltiazem': 26})\n",
      "Counter({'Lisinopril': 622, 'Atenolol': 134})\n",
      "Counter({1: 620, 4: 428, 0: 161, 3: 129, 5: 119, 2: 100})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({3: 51, 1: 45, 0: 14, 2: 13})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 186, 4: 134, 0: 63, 3: 51, 2: 26})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 622, 0: 134})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Res: Accuracy: 0.29743589743589743 # Scores: (0.18992165242165243, 0.18247863247863247, 0.1732300670328386)\n",
      "Wei: Accuracy: 0.23205128205128203 # Scores: (0.3833333333333333, 0.14305555555555555, 0.1787129537129537)\n",
      "Bld: Accuracy: 0.2565217391304348 # Scores: (0.18609385783298826, 0.16732542819499344, 0.14974859287054412)\n",
      "Ask: Accuracy: 0.8213333333333332 # Scores: (0.8106666666666668, 0.85, 0.8175824175824176)\n",
      "Counter({'Atenolol': 620, 'Lisinopril': 428, 'Amlodipine': 161, 'Hydrochlorothiazide': 129, 'Nadolol': 119, 'Diltiazem': 100})\n",
      "Counter({'Lisinopril': 51, 'Atenolol': 45, 'Amlodipine': 14, 'Hydrochlorothiazide': 13})\n",
      "Counter({'Atenolol': 186, 'Lisinopril': 134, 'Amlodipine': 63, 'Hydrochlorothiazide': 51, 'Diltiazem': 26})\n",
      "Counter({'Lisinopril': 622, 'Atenolol': 134})\n",
      "Counter({1: 620, 4: 428, 0: 161, 3: 129, 5: 119, 2: 100})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({3: 51, 1: 45, 0: 14, 2: 13})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 186, 4: 134, 0: 63, 3: 51, 2: 26})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 622, 0: 134})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Res: Accuracy: 0.3038461538461538 # Scores: (0.19026806526806528, 0.1857905982905983, 0.17612605878432327)\n",
      "Wei: Accuracy: 0.24935897435897436 # Scores: (0.3833333333333333, 0.15277777777777776, 0.18757742257742255)\n",
      "Bld: Accuracy: 0.2434782608695652 # Scores: (0.18582930756843802, 0.16179183135704875, 0.14500614812456422)\n",
      "Ask: Accuracy: 0.8213333333333332 # Scores: (0.8106666666666668, 0.85, 0.8175824175824176)\n",
      "Counter({'Atenolol': 620, 'Lisinopril': 428, 'Amlodipine': 161, 'Hydrochlorothiazide': 129, 'Nadolol': 119, 'Diltiazem': 100})\n",
      "Counter({'Lisinopril': 51, 'Atenolol': 45, 'Amlodipine': 14, 'Hydrochlorothiazide': 13})\n",
      "Counter({'Atenolol': 186, 'Lisinopril': 134, 'Amlodipine': 63, 'Hydrochlorothiazide': 51, 'Diltiazem': 26})\n",
      "Counter({'Lisinopril': 622, 'Atenolol': 134})\n",
      "Counter({1: 620, 4: 428, 0: 161, 3: 129, 5: 119, 2: 100})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({3: 51, 1: 45, 0: 14, 2: 13})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 186, 4: 134, 0: 63, 3: 51, 2: 26})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 622, 0: 134})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Res: Accuracy: 0.3057692307692308 # Scores: (0.19038461538461537, 0.18707264957264957, 0.17659160287327247)\n",
      "Wei: Accuracy: 0.2653846153846154 # Scores: (0.3833333333333333, 0.1597222222222222, 0.19638479167890932)\n",
      "Bld: Accuracy: 0.25000000000000006 # Scores: (0.1860144927536232, 0.1643939393939394, 0.1473470737275866)\n",
      "Ask: Accuracy: 0.8213333333333332 # Scores: (0.8106666666666668, 0.85, 0.8175824175824176)\n",
      "Counter({'Atenolol': 620, 'Lisinopril': 428, 'Amlodipine': 161, 'Hydrochlorothiazide': 129, 'Nadolol': 119, 'Diltiazem': 100})\n",
      "Counter({'Lisinopril': 51, 'Atenolol': 45, 'Amlodipine': 14, 'Hydrochlorothiazide': 13})\n",
      "Counter({'Atenolol': 186, 'Lisinopril': 134, 'Amlodipine': 63, 'Hydrochlorothiazide': 51, 'Diltiazem': 26})\n",
      "Counter({'Lisinopril': 622, 'Atenolol': 134})\n",
      "Counter({1: 620, 4: 428, 0: 161, 3: 129, 5: 119, 2: 100})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({3: 51, 1: 45, 0: 14, 2: 13})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 186, 4: 134, 0: 63, 3: 51, 2: 26})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 622, 0: 134})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Res: Accuracy: 0.30256410256410254 # Scores: (0.19038461538461537, 0.18557692307692308, 0.17534728765648136)\n",
      "Wei: Accuracy: 0.241025641025641 # Scores: (0.3333333333333333, 0.1486111111111111, 0.17770347299759065)\n",
      "Bld: Accuracy: 0.24565217391304345 # Scores: (0.1859267734553776, 0.1625494071146245, 0.14577419727971014)\n",
      "Ask: Accuracy: 0.8213333333333332 # Scores: (0.8106666666666668, 0.85, 0.8175824175824176)\n",
      "Counter({'Atenolol': 620, 'Lisinopril': 428, 'Amlodipine': 161, 'Hydrochlorothiazide': 129, 'Nadolol': 119, 'Diltiazem': 100})\n",
      "Counter({'Lisinopril': 51, 'Atenolol': 45, 'Amlodipine': 14, 'Hydrochlorothiazide': 13})\n",
      "Counter({'Atenolol': 186, 'Lisinopril': 134, 'Amlodipine': 63, 'Hydrochlorothiazide': 51, 'Diltiazem': 26})\n",
      "Counter({'Lisinopril': 622, 'Atenolol': 134})\n",
      "Counter({1: 620, 4: 428, 0: 161, 3: 129, 5: 119, 2: 100})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({3: 51, 1: 45, 0: 14, 2: 13})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 186, 4: 134, 0: 63, 3: 51, 2: 26})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 622, 0: 134})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Res: Accuracy: 0.30128205128205127 # Scores: (0.19049955791335102, 0.18472222222222223, 0.1753320330181271)\n",
      "Wei: Accuracy: 0.2570512820512821 # Scores: (0.3833333333333333, 0.15555555555555556, 0.18979138508550275)\n",
      "Bld: Accuracy: 0.2456521739130435 # Scores: (0.1860144927536232, 0.16222002635046112, 0.14566670843078294)\n",
      "Ask: Accuracy: 0.8213333333333332 # Scores: (0.8106666666666668, 0.85, 0.8175824175824176)\n",
      "Counter({'Atenolol': 620, 'Lisinopril': 428, 'Amlodipine': 161, 'Hydrochlorothiazide': 129, 'Nadolol': 119, 'Diltiazem': 100})\n",
      "Counter({'Lisinopril': 51, 'Atenolol': 45, 'Amlodipine': 14, 'Hydrochlorothiazide': 13})\n",
      "Counter({'Atenolol': 186, 'Lisinopril': 134, 'Amlodipine': 63, 'Hydrochlorothiazide': 51, 'Diltiazem': 26})\n",
      "Counter({'Lisinopril': 622, 'Atenolol': 134})\n",
      "Counter({1: 620, 4: 428, 0: 161, 3: 129, 5: 119, 2: 100})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({3: 51, 1: 45, 0: 14, 2: 13})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 186, 4: 134, 0: 63, 3: 51, 2: 26})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 622, 0: 134})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Res: Accuracy: 0.3019230769230769 # Scores: (0.19038461538461537, 0.18493589743589745, 0.1755328566935753)\n",
      "Wei: Accuracy: 0.2730769230769231 # Scores: (0.3833333333333333, 0.1625, 0.20019431548843314)\n",
      "Bld: Accuracy: 0.24347826086956523 # Scores: (0.1859267734553776, 0.1614624505928854, 0.14492266081173533)\n",
      "Ask: Accuracy: 0.8213333333333332 # Scores: (0.8106666666666668, 0.85, 0.8175824175824176)\n",
      "Counter({'Atenolol': 620, 'Lisinopril': 428, 'Amlodipine': 161, 'Hydrochlorothiazide': 129, 'Nadolol': 119, 'Diltiazem': 100})\n",
      "Counter({'Lisinopril': 51, 'Atenolol': 45, 'Amlodipine': 14, 'Hydrochlorothiazide': 13})\n",
      "Counter({'Atenolol': 186, 'Lisinopril': 134, 'Amlodipine': 63, 'Hydrochlorothiazide': 51, 'Diltiazem': 26})\n",
      "Counter({'Lisinopril': 622, 'Atenolol': 134})\n",
      "Counter({1: 620, 4: 428, 0: 161, 3: 129, 5: 119, 2: 100})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({3: 51, 1: 45, 0: 14, 2: 13})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 186, 4: 134, 0: 63, 3: 51, 2: 26})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 622, 0: 134})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Res: Accuracy: 0.30256410256410254 # Scores: (0.19015939015939015, 0.18536324786324787, 0.1754451583757885)\n",
      "Wei: Accuracy: 0.2564102564102564 # Scores: (0.3833333333333333, 0.15416666666666665, 0.18918914418914418)\n",
      "Bld: Accuracy: 0.24347826086956523 # Scores: (0.1859267734553776, 0.1614624505928854, 0.14492266081173533)\n",
      "Ask: Accuracy: 0.8213333333333332 # Scores: (0.8106666666666668, 0.85, 0.8175824175824176)\n",
      "Counter({'Atenolol': 620, 'Lisinopril': 428, 'Amlodipine': 161, 'Hydrochlorothiazide': 129, 'Nadolol': 119, 'Diltiazem': 100})\n",
      "Counter({'Lisinopril': 51, 'Atenolol': 45, 'Amlodipine': 14, 'Hydrochlorothiazide': 13})\n",
      "Counter({'Atenolol': 186, 'Lisinopril': 134, 'Amlodipine': 63, 'Hydrochlorothiazide': 51, 'Diltiazem': 26})\n",
      "Counter({'Lisinopril': 622, 'Atenolol': 134})\n",
      "Counter({1: 620, 4: 428, 0: 161, 3: 129, 5: 119, 2: 100})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({3: 51, 1: 45, 0: 14, 2: 13})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 186, 4: 134, 0: 63, 3: 51, 2: 26})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 622, 0: 134})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Res: Accuracy: 0.3006410256410256 # Scores: (0.19027123669980814, 0.1844017094017094, 0.1748543573651819)\n",
      "Wei: Accuracy: 0.2564102564102564 # Scores: (0.3833333333333333, 0.15416666666666665, 0.18918914418914418)\n",
      "Bld: Accuracy: 0.2434782608695652 # Scores: (0.18582930756843802, 0.16179183135704875, 0.1448304858852112)\n",
      "Ask: Accuracy: 0.8213333333333332 # Scores: (0.8106666666666668, 0.85, 0.8175824175824176)\n",
      "Counter({'Atenolol': 620, 'Lisinopril': 428, 'Amlodipine': 161, 'Hydrochlorothiazide': 129, 'Nadolol': 119, 'Diltiazem': 100})\n",
      "Counter({'Lisinopril': 51, 'Atenolol': 45, 'Amlodipine': 14, 'Hydrochlorothiazide': 13})\n",
      "Counter({'Atenolol': 186, 'Lisinopril': 134, 'Amlodipine': 63, 'Hydrochlorothiazide': 51, 'Diltiazem': 26})\n",
      "Counter({'Lisinopril': 622, 'Atenolol': 134})\n",
      "Counter({1: 620, 4: 428, 0: 161, 3: 129, 5: 119, 2: 100})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({3: 51, 1: 45, 0: 14, 2: 13})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 186, 4: 134, 0: 63, 3: 51, 2: 26})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 622, 0: 134})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Res: Accuracy: 0.3006410256410256 # Scores: (0.19050116550116553, 0.1842948717948718, 0.17522787269238935)\n",
      "Wei: Accuracy: 0.25641025641025644 # Scores: (0.3833333333333333, 0.15416666666666667, 0.19262465604570866)\n",
      "Bld: Accuracy: 0.2434782608695652 # Scores: (0.18582930756843802, 0.16179183135704875, 0.1448304858852112)\n",
      "Ask: Accuracy: 0.8213333333333332 # Scores: (0.8106666666666668, 0.85, 0.8175824175824176)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "label='Drug'\n",
    "asklabel='Drug'\n",
    "\n",
    "res_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "wei_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "bld_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "ask_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "for estimators in range (100,1000,100):\n",
    "    result,result_labels,weighted,weighted_labels,blood,blood_labels,ask,ask_labels=prepareDatasetNoSmote(label,asklabel)\n",
    "    res_acc,res_scores=randomForest10FoldNotSmote(result,result_labels,estimators,\"Result\")\n",
    "    wei_acc,wei_scores=randomForest10FoldNotSmote(weighted,weighted_labels,estimators,\"Weighted\")\n",
    "    blood_acc,blood_scores=randomForest10FoldNotSmote(blood,blood_labels,estimators,\"Blood\")\n",
    "    ask_acc,ask_scores=randomForest10FoldNotSmote(ask,ask_labels,1000,\"Ask\")\n",
    "    print(\"Res: Accuracy: \" + str(res_acc)+\" # \"+ \"Scores: \"+str(res_scores))\n",
    "    print(\"Wei: Accuracy: \" + str(wei_acc)+\" # \"+ \"Scores: \"+str(wei_scores))\n",
    "    print(\"Bld: Accuracy: \" + str(blood_acc)+\" # \"+ \"Scores: \"+str(blood_scores))\n",
    "    print(\"Ask: Accuracy: \" + str(ask_acc)+\" # \"+ \"Scores: \"+str(ask_scores))\n",
    "    res_Stats=res_Stats.append({'Estimators':estimators,'Accuracy':res_acc,'Precision':res_scores[0],'Recall':res_scores[1],'FScore':res_scores[2]},ignore_index=True)\n",
    "    wei_Stats=wei_Stats.append({'Estimators':estimators,'Accuracy':wei_acc,'Precision':wei_scores[0],'Recall':wei_scores[1],'FScore':wei_scores[2]},ignore_index=True)\n",
    "    bld_Stats=bld_Stats.append({'Estimators':estimators,'Accuracy':blood_acc,'Precision':blood_scores[0],'Recall':blood_scores[1],'FScore':blood_scores[2]},ignore_index=True)\n",
    "    ask_Stats=ask_Stats.append({'Estimators':estimators,'Accuracy':ask_acc,'Precision':ask_scores[0],'Recall':ask_scores[1],'FScore':ask_scores[2]},ignore_index=True)\n",
    "\n",
    "writer = pd.ExcelWriter('ForrestFold_Stats'+label+'smoteless.xlsx', engine='xlsxwriter')\n",
    "res_Stats.to_excel(writer, sheet_name='Sheet1') \n",
    "wei_Stats.to_excel(writer, sheet_name='Sheet2') \n",
    "bld_Stats.to_excel(writer, sheet_name='Sheet3') \n",
    "ask_Stats.to_excel(writer, sheet_name='Sheet4')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Atenolol': 620, 'Lisinopril': 428, 'Amlodipine': 161, 'Hydrochlorothiazide': 129, 'Nadolol': 119, 'Diltiazem': 100})\n",
      "Counter({'Lisinopril': 51, 'Atenolol': 45, 'Amlodipine': 14, 'Hydrochlorothiazide': 13})\n",
      "Counter({'Atenolol': 186, 'Lisinopril': 134, 'Amlodipine': 63, 'Hydrochlorothiazide': 51, 'Diltiazem': 26})\n",
      "Counter({'Lisinopril': 622, 'Atenolol': 134})\n"
     ]
    }
   ],
   "source": [
    "result,result_labels,weighted,weighted_labels,blood,blood_labels,ask,ask_labels=prepareDataset(label,asklabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Classifier Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM(result,result_labels,DataSet):\n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn.metrics import f1_score\n",
    "    from collections import Counter\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(result, result_labels, test_size=0.30, random_state=42)\n",
    "    print(Counter(result_labels))\n",
    "    clf = SVC(gamma='auto')\n",
    "    clf.fit(X_train, Y_train)\n",
    "    pred=clf.predict(X_test)\n",
    "    accuracy=(accuracy_score(Y_test, pred))\n",
    "    #print (accuracy)\n",
    "    scores_rf=(precision_recall_fscore_support(Y_test,pred, average='macro'))\n",
    "    #print(DataSet)\n",
    "    #print (pred)\n",
    "    #print(classification_report(Y_test,pred,labels=[0,1,2]))\n",
    "        \n",
    "    return accuracy,scores_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Beta': 739, 'Angiotensin': 428, 'Calcium': 261, 'Diuretics': 129})\n",
      "Counter({'Angiotensin': 51, 'Beta': 45, 'Calcium': 14, 'Diuretics': 13})\n",
      "Counter({'Beta': 186, 'Angiotensin': 134, 'Calcium': 89, 'Diuretics': 51})\n",
      "Counter({'Angiotensin': 622, 'Beta': 134})\n",
      "Counter({2: 739, 3: 739, 1: 739, 0: 739})\n",
      "Counter({2: 51, 3: 51, 1: 51, 0: 51})\n",
      "Counter({2: 186, 3: 186, 1: 186, 0: 186})\n",
      "Counter({0: 622, 1: 622})\n",
      "Res: Accuracy: 0.455467869222097 # Scores: (0.4532571113265105, 0.45772812274777286, 0.4433001434403546, None)\n",
      "Wei: Accuracy: 0.45161290322580644 # Scores: (0.47159090909090906, 0.4527923669467787, 0.45470275614880734, None)\n",
      "Bld: Accuracy: 0.4330357142857143 # Scores: (0.4473443223443223, 0.44495805512754666, 0.4359724398150109, None)\n",
      "Ask: Accuracy: 0.7540106951871658 # Scores: (0.7614743308468627, 0.75572912196378, 0.7529935391241924, None)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "label='DrugFamily'\n",
    "asklabel='DrugFamily'\n",
    "Stats = pd.DataFrame(columns = ['Dataset','Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "\n",
    "\n",
    "result,result_labels,weighted,weighted_labels,blood,blood_labels,ask,ask_labels=prepareDataset(label,asklabel)\n",
    "res_acc,res_scores=SVM(result,result_labels,\"Result\")\n",
    "wei_acc,wei_scores=SVM(weighted,weighted_labels,\"Weighted\")\n",
    "blood_acc,blood_scores=SVM(blood,blood_labels,\"Blood\")\n",
    "ask_acc,ask_scores=SVM(ask,ask_labels,\"Ask\")\n",
    "print(\"Res: Accuracy: \" + str(res_acc)+\" # \"+ \"Scores: \"+str(res_scores))\n",
    "print(\"Wei: Accuracy: \" + str(wei_acc)+\" # \"+ \"Scores: \"+str(wei_scores))\n",
    "print(\"Bld: Accuracy: \" + str(blood_acc)+\" # \"+ \"Scores: \"+str(blood_scores))\n",
    "print(\"Ask: Accuracy: \" + str(ask_acc)+\" # \"+ \"Scores: \"+str(ask_scores))\n",
    "Stats=Stats.append({'Dataset':\"Complete\",'Accuracy':res_acc,'Precision':res_scores[0],'Recall':res_scores[1],'FScore':res_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Weighted\",'Accuracy':wei_acc,'Precision':wei_scores[0],'Recall':wei_scores[1],'FScore':wei_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Blood\",'Accuracy':blood_acc,'Precision':blood_scores[0],'Recall':blood_scores[1],'FScore':blood_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"AskAPatient\",'Accuracy':ask_acc,'Precision':ask_scores[0],'Recall':ask_scores[1],'FScore':ask_scores[2]},ignore_index=True)\n",
    "#Stats.to_excel('SVMresult_Stats'+label+'.xlsx') \n",
    "\n",
    "plotResult(label+\" SVM With Smote\",Stats,Stats,Stats,Stats,0,1,2,3)\n",
    "\n",
    "import os.path\n",
    "if not os.path.exists('SVM'+'.xlsx'):\n",
    "    writer = pd.ExcelWriter('SVM'+'.xlsx', engine = 'xlsxwriter')\n",
    "\n",
    "    writer.save()\n",
    "    writer.close()\n",
    "writer = pd.ExcelWriter('SVM'+'.xlsx', engine='openpyxl')\n",
    "book = load_workbook('SVM'+'.xlsx')\n",
    "writer.book = book\n",
    "writer.sheets = dict((ws.title, ws) for ws in book.worksheets)\n",
    "\n",
    "Stats.to_excel(writer, sheet_name=label)\n",
    "writer.save()\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Beta': 739, 'Angiotensin': 428, 'Calcium': 261, 'Diuretics': 129})\n",
      "Counter({'Angiotensin': 51, 'Beta': 45, 'Calcium': 14, 'Diuretics': 13})\n",
      "Counter({'Beta': 186, 'Angiotensin': 134, 'Calcium': 89, 'Diuretics': 51})\n",
      "Counter({'Angiotensin': 622, 'Beta': 134})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 4], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 2, 3, 5, 6, 15], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 1, 2, 3, 6, 15], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 6], dtype='int64')\n",
      "Counter({2: 739, 3: 739, 1: 739, 0: 739})\n",
      "Counter({2: 51, 3: 51, 1: 51, 0: 51})\n",
      "Counter({2: 186, 3: 186, 1: 186, 0: 186})\n",
      "Counter({0: 622, 1: 622})\n",
      "Res: Accuracy: 0.33032694475760993 # Scores: (0.34927977460854887, 0.33461241260429897, 0.32011749926249644, None)\n",
      "Wei: Accuracy: 0.4838709677419355 # Scores: (0.547979797979798, 0.47984943977591044, 0.4899377234459693, None)\n",
      "Bld: Accuracy: 0.4107142857142857 # Scores: (0.4417435551604696, 0.42537094104890716, 0.40668772863318925, None)\n",
      "Ask: Accuracy: 0.7165775401069518 # Scores: (0.7846464646464646, 0.7217120132749693, 0.7015208552928776, None)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "label='DrugFamily'\n",
    "asklabel='DrugFamily'\n",
    "Stats = pd.DataFrame(columns = ['Dataset','Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "\n",
    "\n",
    "result,result_labels,weighted,weighted_labels,blood,blood_labels,ask,ask_labels=prepareDataset(label,asklabel)\n",
    "res_feat=importance(result,result_labels)\n",
    "wei_feat=importance(weighted,weighted_labels)\n",
    "blood_feat=importance(blood,blood_labels)\n",
    "ask_feat=importance(ask,ask_labels)\n",
    "res_acc,res_scores=SVM(pd.DataFrame(result)[res_feat],result_labels,\"Result\")\n",
    "wei_acc,wei_scores=SVM(pd.DataFrame(weighted)[wei_feat],weighted_labels,\"Weighted\")\n",
    "blood_acc,blood_scores=SVM(pd.DataFrame(blood)[blood_feat],blood_labels,\"Blood\")\n",
    "ask_acc,ask_scores=SVM(pd.DataFrame(ask)[ask_feat],ask_labels,\"Ask\")\n",
    "print(\"Res: Accuracy: \" + str(res_acc)+\" # \"+ \"Scores: \"+str(res_scores))\n",
    "print(\"Wei: Accuracy: \" + str(wei_acc)+\" # \"+ \"Scores: \"+str(wei_scores))\n",
    "print(\"Bld: Accuracy: \" + str(blood_acc)+\" # \"+ \"Scores: \"+str(blood_scores))\n",
    "print(\"Ask: Accuracy: \" + str(ask_acc)+\" # \"+ \"Scores: \"+str(ask_scores))\n",
    "Stats=Stats.append({'Dataset':\"Complete\",'Accuracy':res_acc,'Precision':res_scores[0],'Recall':res_scores[1],'FScore':res_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Weighted\",'Accuracy':wei_acc,'Precision':wei_scores[0],'Recall':wei_scores[1],'FScore':wei_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Blood\",'Accuracy':blood_acc,'Precision':blood_scores[0],'Recall':blood_scores[1],'FScore':blood_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"AskAPatient\",'Accuracy':ask_acc,'Precision':ask_scores[0],'Recall':ask_scores[1],'FScore':ask_scores[2]},ignore_index=True)\n",
    "#Stats.to_excel('SVMresult_Stats'+label+'importance.xlsx')\n",
    "\n",
    "plotResult(label+\" SVM With Feature Filtering\",Stats,Stats,Stats,Stats,0,1,2,3)\n",
    "import os.path\n",
    "if not os.path.exists('SVMImportance'+'.xlsx'):\n",
    "    writer = pd.ExcelWriter('SVMImportance'+'.xlsx', engine = 'xlsxwriter')\n",
    "\n",
    "    writer.save()\n",
    "    writer.close()\n",
    "writer = pd.ExcelWriter('SVMImportance'+'.xlsx', engine='openpyxl')\n",
    "book = load_workbook('SVMImportance'+'.xlsx')\n",
    "writer.book = book\n",
    "writer.sheets = dict((ws.title, ws) for ws in book.worksheets)\n",
    "\n",
    "Stats.to_excel(writer, sheet_name=label)\n",
    "writer.save()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Atenolol': 620, 'Lisinopril': 428, 'Amlodipine': 161, 'Hydrochlorothiazide': 129, 'Nadolol': 119, 'Diltiazem': 100})\n",
      "Counter({'Lisinopril': 51, 'Atenolol': 45, 'Amlodipine': 14, 'Hydrochlorothiazide': 13})\n",
      "Counter({'Atenolol': 186, 'Lisinopril': 134, 'Amlodipine': 63, 'Hydrochlorothiazide': 51, 'Diltiazem': 26})\n",
      "Counter({'Lisinopril': 622, 'Atenolol': 134})\n",
      "Counter({1: 620, 4: 428, 0: 161, 3: 129, 5: 119, 2: 100})\n",
      "Counter({3: 51, 1: 45, 0: 14, 2: 13})\n",
      "Counter({1: 186, 4: 134, 0: 63, 3: 51, 2: 26})\n",
      "Counter({1: 622, 0: 134})\n",
      "Res: Accuracy: 0.4230769230769231 # Scores: (0.13579002500172935, 0.1892402338596564, 0.14871326725786818, None)\n",
      "Wei: Accuracy: 0.35135135135135137 # Scores: (0.18369565217391304, 0.22916666666666666, 0.1997607655502392, None)\n",
      "Bld: Accuracy: 0.32608695652173914 # Scores: (0.2604915514592934, 0.223291040682345, 0.2016501814989368, None)\n",
      "Ask: Accuracy: 0.8810572687224669 # Scores: (0.7752976190476191, 0.5332017229002154, 0.5326012354152367, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "label='Drug'\n",
    "asklabel='Drug'\n",
    "Stats = pd.DataFrame(columns = ['Dataset','Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "\n",
    "\n",
    "result,result_labels,weighted,weighted_labels,blood,blood_labels,ask,ask_labels=prepareDatasetNoSmote(label,asklabel)\n",
    "res_acc,res_scores=SVM(result,result_labels,\"Result\")\n",
    "wei_acc,wei_scores=SVM(weighted,weighted_labels,\"Weighted\")\n",
    "blood_acc,blood_scores=SVM(blood,blood_labels,\"Blood\")\n",
    "ask_acc,ask_scores=SVM(ask,ask_labels,\"Ask\")\n",
    "print(\"Res: Accuracy: \" + str(res_acc)+\" # \"+ \"Scores: \"+str(res_scores))\n",
    "print(\"Wei: Accuracy: \" + str(wei_acc)+\" # \"+ \"Scores: \"+str(wei_scores))\n",
    "print(\"Bld: Accuracy: \" + str(blood_acc)+\" # \"+ \"Scores: \"+str(blood_scores))\n",
    "print(\"Ask: Accuracy: \" + str(ask_acc)+\" # \"+ \"Scores: \"+str(ask_scores))\n",
    "Stats=Stats.append({'Dataset':\"Complete\",'Accuracy':res_acc,'Precision':res_scores[0],'Recall':res_scores[1],'FScore':res_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Weighted\",'Accuracy':wei_acc,'Precision':wei_scores[0],'Recall':wei_scores[1],'FScore':wei_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Blood\",'Accuracy':blood_acc,'Precision':blood_scores[0],'Recall':blood_scores[1],'FScore':blood_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"AskAPatient\",'Accuracy':ask_acc,'Precision':ask_scores[0],'Recall':ask_scores[1],'FScore':ask_scores[2]},ignore_index=True)\n",
    "Stats.to_excel('SVMresult_Stats'+label+'smoteless.xlsx') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Atenolol': 620, 'Lisinopril': 428, 'Amlodipine': 161, 'Hydrochlorothiazide': 129, 'Nadolol': 119, 'Diltiazem': 100})\n",
      "Counter({'Lisinopril': 51, 'Atenolol': 45, 'Amlodipine': 14, 'Hydrochlorothiazide': 13})\n",
      "Counter({'Atenolol': 186, 'Lisinopril': 134, 'Amlodipine': 63, 'Hydrochlorothiazide': 51, 'Diltiazem': 26})\n",
      "Counter({'Lisinopril': 622, 'Atenolol': 134})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 620, 4: 428, 0: 161, 3: 129, 5: 119, 2: 100})\n",
      "Counter({3: 51, 1: 45, 0: 14, 2: 13})\n",
      "Counter({1: 186, 4: 134, 0: 63, 3: 51, 2: 26})\n",
      "Counter({1: 622, 0: 134})\n",
      "Res: Accuracy: 0.37393162393162394 # Scores: (0.2882345808746261, 0.18438292060339304, 0.16067061928683019, None)\n",
      "Wei: Accuracy: 0.40540540540540543 # Scores: (0.23214285714285715, 0.2625, 0.22286821705426357, None)\n",
      "Bld: Accuracy: 0.3115942028985507 # Scores: (0.2079185520361991, 0.20991311426094034, 0.1697056277056277, None)\n",
      "Ask: Accuracy: 0.8502202643171806 # Scores: (0.5008561643835616, 0.5002692031586504, 0.4871079213184476, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "label='Drug'\n",
    "asklabel='Drug'\n",
    "Stats = pd.DataFrame(columns = ['Dataset','Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "\n",
    "\n",
    "result,result_labels,weighted,weighted_labels,blood,blood_labels,ask,ask_labels=prepareDatasetNoSmote(label,asklabel)\n",
    "res_feat=importance(result,result_labels)\n",
    "wei_feat=importance(weighted,weighted_labels)\n",
    "blood_feat=importance(blood,blood_labels)\n",
    "ask_feat=importance(ask,ask_labels)\n",
    "res_acc,res_scores=SVM(pd.DataFrame(result)[res_feat],result_labels,\"Result\")\n",
    "wei_acc,wei_scores=SVM(pd.DataFrame(weighted)[wei_feat],weighted_labels,\"Weighted\")\n",
    "blood_acc,blood_scores=SVM(pd.DataFrame(blood)[blood_feat],blood_labels,\"Blood\")\n",
    "ask_acc,ask_scores=SVM(pd.DataFrame(ask)[ask_feat],ask_labels,\"Ask\")\n",
    "print(\"Res: Accuracy: \" + str(res_acc)+\" # \"+ \"Scores: \"+str(res_scores))\n",
    "print(\"Wei: Accuracy: \" + str(wei_acc)+\" # \"+ \"Scores: \"+str(wei_scores))\n",
    "print(\"Bld: Accuracy: \" + str(blood_acc)+\" # \"+ \"Scores: \"+str(blood_scores))\n",
    "print(\"Ask: Accuracy: \" + str(ask_acc)+\" # \"+ \"Scores: \"+str(ask_scores))\n",
    "Stats=Stats.append({'Dataset':\"Complete\",'Accuracy':res_acc,'Precision':res_scores[0],'Recall':res_scores[1],'FScore':res_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Weighted\",'Accuracy':wei_acc,'Precision':wei_scores[0],'Recall':wei_scores[1],'FScore':wei_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Blood\",'Accuracy':blood_acc,'Precision':blood_scores[0],'Recall':blood_scores[1],'FScore':blood_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"AskAPatient\",'Accuracy':ask_acc,'Precision':ask_scores[0],'Recall':ask_scores[1],'FScore':ask_scores[2]},ignore_index=True)\n",
    "Stats.to_excel('SVMresult_Stats'+label+'importancesmoteless.xlsx') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM 10-Fold Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM10Fold(result,result_labels,DataSet):\n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn.metrics import f1_score\n",
    "    from collections import Counter\n",
    "    kf = KFold(n_splits=10)\n",
    "\n",
    "    accuracy=[]\n",
    "\n",
    "    scores_rf=[]\n",
    "    print(Counter(result_labels))\n",
    "    count = 1\n",
    "    for train_index, test_index in kf.split(result):\n",
    "        X_train, X_test, Y_train, Y_test = result[train_index], result[test_index], result_labels[train_index],result_labels[test_index]\n",
    "        clf = SVC(gamma='auto')\n",
    "        clf.fit(X_train, Y_train)\n",
    "        pred=clf.predict(X_test)\n",
    "        accuracy.append(accuracy_score(Y_test, pred))\n",
    "        scores_rf.append(precision_recall_fscore_support(Y_test,pred, average='macro'))\n",
    "        \n",
    "        #print(str(count)+DataSet)\n",
    "        #print(f1_score(Y_test, pred, average='micro'))\n",
    "        count+=1\n",
    "        #print (pred)\n",
    "        #print(classification_report(Y_test,pred,labels=[0,1]))\n",
    "    accuracy = np.mean(accuracy,axis=0)   \n",
    "    return accuracy,average(scores_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM10FoldNoSmote(result,result_labels,DataSet):\n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn.metrics import f1_score\n",
    "    from collections import Counter\n",
    "    kf = KFold(n_splits=10)\n",
    "    accuracy=[]\n",
    "\n",
    "    scores_rf=[]\n",
    "    print(Counter(result_labels))\n",
    "    count = 1\n",
    "    for train_index, test_index in kf.split(result):\n",
    "        X_train, X_test, Y_train, Y_test = result.iloc[train_index], result.iloc[test_index], result_labels[train_index],result_labels[test_index]\n",
    "        clf = SVC(gamma='auto')\n",
    "        clf.fit(X_train, Y_train)\n",
    "        pred=clf.predict(X_test)\n",
    "        accuracy.append(accuracy_score(Y_test, pred))\n",
    "        scores_rf.append(precision_recall_fscore_support(Y_test,pred, average='macro'))\n",
    "        \n",
    "        #print(str(count)+DataSet)\n",
    "        #print(f1_score(Y_test, pred, average='micro'))\n",
    "        count+=1\n",
    "        #print (pred)\n",
    "        #print(classification_report(Y_test,pred,labels=[0,1]))\n",
    "    accuracy = np.mean(accuracy,axis=0)   \n",
    "    return accuracy,average(scores_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM 10-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Beta': 739, 'Angiotensin': 428, 'Calcium': 261, 'Diuretics': 129})\n",
      "Counter({'Angiotensin': 51, 'Beta': 45, 'Calcium': 14, 'Diuretics': 13})\n",
      "Counter({'Beta': 186, 'Angiotensin': 134, 'Calcium': 89, 'Diuretics': 51})\n",
      "Counter({'Angiotensin': 622, 'Beta': 134})\n",
      "Counter({2: 739, 3: 739, 1: 739, 0: 739})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({2: 51, 3: 51, 1: 51, 0: 51})\n",
      "Counter({2: 186, 3: 186, 1: 186, 0: 186})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 622, 1: 622})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Res: Accuracy: 0.20168117269812186 # Scores: (0.28083773341812057, 0.10982860057253067, 0.12451004657680309)\n",
      "Wei: Accuracy: 0.2647619047619047 # Scores: (0.27130952380952383, 0.12747284878863824, 0.13682150202115878)\n",
      "Bld: Accuracy: 0.3081981981981982 # Scores: (0.2870208394976197, 0.13634607286112532, 0.1565449975482354)\n",
      "Ask: Accuracy: 0.6933806451612903 # Scores: (0.5035714285714286, 0.396518455843469, 0.4118479277382098)\n"
     ]
    }
   ],
   "source": [
    "Stats = pd.DataFrame(columns = ['Dataset','Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "\n",
    "label='DrugFamily'\n",
    "asklabel='DrugFamily'\n",
    "result,result_labels,weighted,weighted_labels,blood,blood_labels,ask,ask_labels=prepareDataset(label,asklabel)\n",
    "res_acc,res_scores=SVM10Fold(result,result_labels,\"Result\")\n",
    "wei_acc,wei_scores=SVM10Fold(weighted,weighted_labels,\"Weighted\")\n",
    "blood_acc,blood_scores=SVM10Fold(blood,blood_labels,\"Blood\")\n",
    "ask_acc,ask_scores=SVM10Fold(ask,ask_labels,\"Ask\")\n",
    "print(\"Res: Accuracy: \" + str(res_acc)+\" # \"+ \"Scores: \"+str(res_scores))\n",
    "print(\"Wei: Accuracy: \" + str(wei_acc)+\" # \"+ \"Scores: \"+str(wei_scores))\n",
    "print(\"Bld: Accuracy: \" + str(blood_acc)+\" # \"+ \"Scores: \"+str(blood_scores))\n",
    "print(\"Ask: Accuracy: \" + str(ask_acc)+\" # \"+ \"Scores: \"+str(ask_scores))\n",
    "Stats=Stats.append({'Dataset':\"Complete\",'Accuracy':res_acc,'Precision':res_scores[0],'Recall':res_scores[1],'FScore':res_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Weighted\",'Accuracy':wei_acc,'Precision':wei_scores[0],'Recall':wei_scores[1],'FScore':wei_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Blood\",'Accuracy':blood_acc,'Precision':blood_scores[0],'Recall':blood_scores[1],'FScore':blood_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"AskAPatient\",'Accuracy':ask_acc,'Precision':ask_scores[0],'Recall':ask_scores[1],'FScore':ask_scores[2]},ignore_index=True)\n",
    "Stats.to_excel('SVMresult_Stats10Fold'+label+'.xlsx') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Beta': 739, 'Angiotensin': 428, 'Calcium': 261, 'Diuretics': 129})\n",
      "Counter({'Angiotensin': 51, 'Beta': 45, 'Calcium': 14, 'Diuretics': 13})\n",
      "Counter({'Beta': 186, 'Angiotensin': 134, 'Calcium': 89, 'Diuretics': 51})\n",
      "Counter({'Angiotensin': 622, 'Beta': 134})\n",
      "Counter({1: 739, 0: 428, 2: 261, 3: 129})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 51, 1: 45, 2: 14, 3: 13})\n",
      "Counter({1: 186, 0: 134, 2: 89, 3: 51})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 622, 1: 134})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Res: Accuracy: 0.4222415219189413 # Scores: (0.25204316051386305, 0.23149066380773697, 0.21973955960348884)\n",
      "Wei: Accuracy: 0.22435897435897437 # Scores: (0.26666666666666666, 0.12916666666666668, 0.13827731092436973)\n",
      "Bld: Accuracy: 0.17608695652173917 # Scores: (0.19981617647058822, 0.06714834499844612, 0.06724216651438637)\n",
      "Ask: Accuracy: 0.8173859649122808 # Scores: (0.6606666666666666, 0.6980263157894736, 0.6665890400989739)\n"
     ]
    }
   ],
   "source": [
    "Stats = pd.DataFrame(columns = ['Dataset','Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "\n",
    "label='DrugFamily'\n",
    "asklabel='DrugFamily'\n",
    "result,result_labels,weighted,weighted_labels,blood,blood_labels,ask,ask_labels=prepareDatasetNoSmote(label,asklabel)\n",
    "res_acc,res_scores=SVM10FoldNoSmote(result,result_labels,\"Result\")\n",
    "wei_acc,wei_scores=SVM10FoldNoSmote(weighted,weighted_labels,\"Weighted\")\n",
    "blood_acc,blood_scores=SVM10FoldNoSmote(blood,blood_labels,\"Blood\")\n",
    "ask_acc,ask_scores=SVM10FoldNoSmote(ask,ask_labels,\"Ask\")\n",
    "print(\"Res: Accuracy: \" + str(res_acc)+\" # \"+ \"Scores: \"+str(res_scores))\n",
    "print(\"Wei: Accuracy: \" + str(wei_acc)+\" # \"+ \"Scores: \"+str(wei_scores))\n",
    "print(\"Bld: Accuracy: \" + str(blood_acc)+\" # \"+ \"Scores: \"+str(blood_scores))\n",
    "print(\"Ask: Accuracy: \" + str(ask_acc)+\" # \"+ \"Scores: \"+str(ask_scores))\n",
    "Stats=Stats.append({'Dataset':\"Complete\",'Accuracy':res_acc,'Precision':res_scores[0],'Recall':res_scores[1],'FScore':res_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Weighted\",'Accuracy':wei_acc,'Precision':wei_scores[0],'Recall':wei_scores[1],'FScore':wei_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Blood\",'Accuracy':blood_acc,'Precision':blood_scores[0],'Recall':blood_scores[1],'FScore':blood_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"AskAPatient\",'Accuracy':ask_acc,'Precision':ask_scores[0],'Recall':ask_scores[1],'FScore':ask_scores[2]},ignore_index=True)\n",
    "Stats.to_excel('SVMresult_Stats10Fold'+label+'smoteless.xlsx') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Beta': 739, 'Angiotensin': 428, 'Calcium': 261, 'Diuretics': 129})\n",
      "Counter({'Angiotensin': 51, 'Beta': 45, 'Calcium': 14, 'Diuretics': 13})\n",
      "Counter({'Beta': 186, 'Angiotensin': 134, 'Calcium': 89, 'Diuretics': 51})\n",
      "Counter({'Angiotensin': 622, 'Beta': 134})\n"
     ]
    }
   ],
   "source": [
    "result,result_labels,weighted,weighted_labels,blood,blood_labels,ask,ask_labels=prepareDatasetNoSmote(label,asklabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NB(result,result_labels,DataSet):\n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn.metrics import f1_score\n",
    "    from collections import Counter\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(result, result_labels, test_size=0.30, random_state=42)\n",
    "    print(Counter(result_labels))\n",
    "    clf = GaussianNB()\n",
    "    clf.fit(X_train, Y_train)\n",
    "    pred=clf.predict(X_test)\n",
    "    accuracy=(accuracy_score(Y_test, pred))\n",
    "    #print (accuracy)\n",
    "    scores_rf=(precision_recall_fscore_support(Y_test,pred, average='macro'))\n",
    "    #print(DataSet)\n",
    "    #print (pred)\n",
    "    #print(classification_report(Y_test,pred,labels=[0,1,2]))\n",
    "        \n",
    "    return accuracy,scores_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Atenolol': 620, 'Lisinopril': 428, 'Amlodipine': 161, 'Hydrochlorothiazide': 129, 'Nadolol': 119, 'Diltiazem': 100})\n",
      "Counter({'Lisinopril': 51, 'Atenolol': 45, 'Amlodipine': 14, 'Hydrochlorothiazide': 13})\n",
      "Counter({'Atenolol': 186, 'Lisinopril': 134, 'Amlodipine': 63, 'Hydrochlorothiazide': 51, 'Diltiazem': 26})\n",
      "Counter({'Lisinopril': 622, 'Atenolol': 134})\n",
      "Counter({0: 620, 2: 620, 3: 620, 1: 620, 4: 620, 5: 620})\n",
      "Counter({0: 51, 2: 51, 1: 51, 3: 51})\n",
      "Counter({0: 186, 2: 186, 3: 186, 1: 186, 4: 186})\n",
      "Counter({1: 622, 0: 622})\n",
      "Res: Accuracy: 0.3055555555555556 # Scores: (0.36439119053754726, 0.3101047653946964, 0.27366199498300997, None)\n",
      "Wei: Accuracy: 0.45161290322580644 # Scores: (0.4540229885057471, 0.454578081232493, 0.4142292490118577, None)\n",
      "Bld: Accuracy: 0.3655913978494624 # Scores: (0.38933929707611514, 0.35494639376218323, 0.33331805217284177, None)\n",
      "Ask: Accuracy: 0.7219251336898396 # Scores: (0.7578153072224219, 0.7258032214688296, 0.7140672782874619, None)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "label='Drug'\n",
    "asklabel='Drug'\n",
    "Stats = pd.DataFrame(columns = ['Dataset','Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "\n",
    "\n",
    "result,result_labels,weighted,weighted_labels,blood,blood_labels,ask,ask_labels=prepareDataset(label,asklabel)\n",
    "res_acc,res_scores=NB(result,result_labels,\"Result\")\n",
    "wei_acc,wei_scores=NB(weighted,weighted_labels,\"Weighted\")\n",
    "blood_acc,blood_scores=NB(blood,blood_labels,\"Blood\")\n",
    "ask_acc,ask_scores=NB(ask,ask_labels,\"Ask\")\n",
    "print(\"Res: Accuracy: \" + str(res_acc)+\" # \"+ \"Scores: \"+str(res_scores))\n",
    "print(\"Wei: Accuracy: \" + str(wei_acc)+\" # \"+ \"Scores: \"+str(wei_scores))\n",
    "print(\"Bld: Accuracy: \" + str(blood_acc)+\" # \"+ \"Scores: \"+str(blood_scores))\n",
    "print(\"Ask: Accuracy: \" + str(ask_acc)+\" # \"+ \"Scores: \"+str(ask_scores))\n",
    "Stats=Stats.append({'Dataset':\"Complete\",'Accuracy':res_acc,'Precision':res_scores[0],'Recall':res_scores[1],'FScore':res_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Weighted\",'Accuracy':wei_acc,'Precision':wei_scores[0],'Recall':wei_scores[1],'FScore':wei_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Blood\",'Accuracy':blood_acc,'Precision':blood_scores[0],'Recall':blood_scores[1],'FScore':blood_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"AskAPatient\",'Accuracy':ask_acc,'Precision':ask_scores[0],'Recall':ask_scores[1],'FScore':ask_scores[2]},ignore_index=True)\n",
    "#Stats.to_excel('NBresult_Stats'+label+'.xlsx')\n",
    "\n",
    "plotResult(label+\" Naive Bayes With Smote\",Stats,Stats,Stats,Stats,0,1,2,3)\n",
    "\n",
    "import os.path\n",
    "if not os.path.exists('NBStats'+'.xlsx'):\n",
    "    writer = pd.ExcelWriter('NBStats'+'.xlsx', engine = 'xlsxwriter')\n",
    "    writer.save()\n",
    "    writer.close()\n",
    "writer = pd.ExcelWriter('NBStats'+'.xlsx', engine='openpyxl')\n",
    "book = load_workbook('NBStats'+'.xlsx')\n",
    "writer.book = book\n",
    "writer.sheets = dict((ws.title, ws) for ws in book.worksheets)\n",
    "\n",
    "Stats.to_excel(writer, sheet_name=label)\n",
    "writer.save()\n",
    "writer.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Atenolol': 620, 'Lisinopril': 428, 'Amlodipine': 161, 'Hydrochlorothiazide': 129, 'Nadolol': 119, 'Diltiazem': 100})\n",
      "Counter({'Lisinopril': 51, 'Atenolol': 45, 'Amlodipine': 14, 'Hydrochlorothiazide': 13})\n",
      "Counter({'Atenolol': 186, 'Lisinopril': 134, 'Amlodipine': 63, 'Hydrochlorothiazide': 51, 'Diltiazem': 26})\n",
      "Counter({'Lisinopril': 622, 'Atenolol': 134})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 3, 4], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 2, 3, 5, 6, 15, 17], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 1, 2, 3, 5, 6, 15], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 6], dtype='int64')\n",
      "Counter({0: 620, 2: 620, 3: 620, 1: 620, 4: 620, 5: 620})\n",
      "Counter({0: 51, 2: 51, 1: 51, 3: 51})\n",
      "Counter({0: 186, 2: 186, 3: 186, 1: 186, 4: 186})\n",
      "Counter({1: 622, 0: 622})\n",
      "Res: Accuracy: 0.2517921146953405 # Scores: (0.2508154971899532, 0.25090672397319363, 0.23690136449703847, None)\n",
      "Wei: Accuracy: 0.4032258064516129 # Scores: (0.44052419354838707, 0.40653886554621854, 0.3813438735177866, None)\n",
      "Bld: Accuracy: 0.3906810035842294 # Scores: (0.3686728274787062, 0.3921637426900585, 0.3453329065510116, None)\n",
      "Ask: Accuracy: 0.6925133689839572 # Scores: (0.8010221760221761, 0.6988384401911137, 0.6662035995064066, None)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "label='Drug'\n",
    "asklabel='Drug'\n",
    "Stats = pd.DataFrame(columns = ['Dataset','Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "\n",
    "result,result_labels,weighted,weighted_labels,blood,blood_labels,ask,ask_labels=prepareDataset(label,asklabel)\n",
    "res_feat=importance(result,result_labels)\n",
    "wei_feat=importance(weighted,weighted_labels)\n",
    "blood_feat=importance(blood,blood_labels)\n",
    "ask_feat=importance(ask,ask_labels)\n",
    "res_acc,res_scores=NB(pd.DataFrame(result)[res_feat],result_labels,\"Result\")\n",
    "wei_acc,wei_scores=NB(pd.DataFrame(weighted)[wei_feat],weighted_labels,\"Weighted\")\n",
    "blood_acc,blood_scores=NB(pd.DataFrame(blood)[blood_feat],blood_labels,\"Blood\")\n",
    "ask_acc,ask_scores=NB(pd.DataFrame(ask)[ask_feat],ask_labels,\"Ask\")\n",
    "print(\"Res: Accuracy: \" + str(res_acc)+\" # \"+ \"Scores: \"+str(res_scores))\n",
    "print(\"Wei: Accuracy: \" + str(wei_acc)+\" # \"+ \"Scores: \"+str(wei_scores))\n",
    "print(\"Bld: Accuracy: \" + str(blood_acc)+\" # \"+ \"Scores: \"+str(blood_scores))\n",
    "print(\"Ask: Accuracy: \" + str(ask_acc)+\" # \"+ \"Scores: \"+str(ask_scores))\n",
    "Stats=Stats.append({'Dataset':\"Complete\",'Accuracy':res_acc,'Precision':res_scores[0],'Recall':res_scores[1],'FScore':res_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Weighted\",'Accuracy':wei_acc,'Precision':wei_scores[0],'Recall':wei_scores[1],'FScore':wei_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Blood\",'Accuracy':blood_acc,'Precision':blood_scores[0],'Recall':blood_scores[1],'FScore':blood_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"AskAPatient\",'Accuracy':ask_acc,'Precision':ask_scores[0],'Recall':ask_scores[1],'FScore':ask_scores[2]},ignore_index=True)\n",
    "#Stats.to_excel('NBresult_Stats'+label+'importance.xlsx') \n",
    "\n",
    "plotResult(label+\" Naive Bayes With Feature Filtering\",Stats,Stats,Stats,Stats,0,1,2,3)\n",
    "\n",
    "import os.path\n",
    "if not os.path.exists('NBStatsImportance'+'.xlsx'):\n",
    "    writer = pd.ExcelWriter('NBStatsImportance'+'.xlsx', engine = 'xlsxwriter')\n",
    "    writer.save()\n",
    "    writer.close()\n",
    "writer = pd.ExcelWriter('NBStatsImportance'+'.xlsx', engine='openpyxl')\n",
    "book = load_workbook('NBStatsImportance'+'.xlsx')\n",
    "writer.book = book\n",
    "writer.sheets = dict((ws.title, ws) for ws in book.worksheets)\n",
    "\n",
    "Stats.to_excel(writer, sheet_name=label)\n",
    "writer.save()\n",
    "writer.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Atenolol': 620, 'Lisinopril': 428, 'Amlodipine': 161, 'Hydrochlorothiazide': 129, 'Nadolol': 119, 'Diltiazem': 100})\n",
      "Counter({'Lisinopril': 51, 'Atenolol': 45, 'Amlodipine': 14, 'Hydrochlorothiazide': 13})\n",
      "Counter({'Atenolol': 186, 'Lisinopril': 134, 'Amlodipine': 63, 'Hydrochlorothiazide': 51, 'Diltiazem': 26})\n",
      "Counter({'Lisinopril': 622, 'Atenolol': 134})\n",
      "Counter({1: 620, 4: 428, 0: 161, 3: 129, 5: 119, 2: 100})\n",
      "Counter({3: 51, 1: 45, 0: 14, 2: 13})\n",
      "Counter({1: 186, 4: 134, 0: 63, 3: 51, 2: 26})\n",
      "Counter({1: 622, 0: 134})\n",
      "Res: Accuracy: 0.27136752136752135 # Scores: (0.22805096506589043, 0.25728075248252413, 0.21574051320280485, None)\n",
      "Wei: Accuracy: 0.24324324324324326 # Scores: (0.2579365079365079, 0.31666666666666665, 0.22435897435897434, None)\n",
      "Bld: Accuracy: 0.18840579710144928 # Scores: (0.27184684684684685, 0.21605439648917907, 0.19481042421777603, None)\n",
      "Ask: Accuracy: 0.6960352422907489 # Scores: (0.5898477591515566, 0.6885319454414932, 0.5781464623340247, None)\n"
     ]
    }
   ],
   "source": [
    "label='Drug'\n",
    "asklabel='Drug'\n",
    "Stats = pd.DataFrame(columns = ['Dataset','Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "\n",
    "\n",
    "result,result_labels,weighted,weighted_labels,blood,blood_labels,ask,ask_labels=prepareDatasetNoSmote(label,asklabel)\n",
    "res_acc,res_scores=NB(result,result_labels,\"Result\")\n",
    "wei_acc,wei_scores=NB(weighted,weighted_labels,\"Weighted\")\n",
    "blood_acc,blood_scores=NB(blood,blood_labels,\"Blood\")\n",
    "ask_acc,ask_scores=NB(ask,ask_labels,\"Ask\")\n",
    "print(\"Res: Accuracy: \" + str(res_acc)+\" # \"+ \"Scores: \"+str(res_scores))\n",
    "print(\"Wei: Accuracy: \" + str(wei_acc)+\" # \"+ \"Scores: \"+str(wei_scores))\n",
    "print(\"Bld: Accuracy: \" + str(blood_acc)+\" # \"+ \"Scores: \"+str(blood_scores))\n",
    "print(\"Ask: Accuracy: \" + str(ask_acc)+\" # \"+ \"Scores: \"+str(ask_scores))\n",
    "Stats=Stats.append({'Dataset':\"Complete\",'Accuracy':res_acc,'Precision':res_scores[0],'Recall':res_scores[1],'FScore':res_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Weighted\",'Accuracy':wei_acc,'Precision':wei_scores[0],'Recall':wei_scores[1],'FScore':wei_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Blood\",'Accuracy':blood_acc,'Precision':blood_scores[0],'Recall':blood_scores[1],'FScore':blood_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"AskAPatient\",'Accuracy':ask_acc,'Precision':ask_scores[0],'Recall':ask_scores[1],'FScore':ask_scores[2]},ignore_index=True)\n",
    "Stats.to_excel('NBresult_Stats'+label+'smoteless.xlsx') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Atenolol': 620, 'Lisinopril': 428, 'Amlodipine': 161, 'Hydrochlorothiazide': 129, 'Nadolol': 119, 'Diltiazem': 100})\n",
      "Counter({'Lisinopril': 51, 'Atenolol': 45, 'Amlodipine': 14, 'Hydrochlorothiazide': 13})\n",
      "Counter({'Atenolol': 186, 'Lisinopril': 134, 'Amlodipine': 63, 'Hydrochlorothiazide': 51, 'Diltiazem': 26})\n",
      "Counter({'Lisinopril': 622, 'Atenolol': 134})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 620, 4: 428, 0: 161, 3: 129, 5: 119, 2: 100})\n",
      "Counter({3: 51, 1: 45, 0: 14, 2: 13})\n",
      "Counter({1: 186, 4: 134, 0: 63, 3: 51, 2: 26})\n",
      "Counter({1: 622, 0: 134})\n",
      "Res: Accuracy: 0.41239316239316237 # Scores: (0.12607833933135137, 0.18181755058395477, 0.1392566782810685, None)\n",
      "Wei: Accuracy: 0.40540540540540543 # Scores: (0.2272727272727273, 0.275, 0.24662162162162163, None)\n",
      "Bld: Accuracy: 0.32608695652173914 # Scores: (0.2858749021561232, 0.23889862150731717, 0.21709442688847722, None)\n",
      "Ask: Accuracy: 0.5066079295154186 # Scores: (0.5922081094284318, 0.7032483847810481, 0.46820615796519416, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "label='Drug'\n",
    "asklabel='Drug'\n",
    "Stats = pd.DataFrame(columns = ['Dataset','Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "\n",
    "\n",
    "result,result_labels,weighted,weighted_labels,blood,blood_labels,ask,ask_labels=prepareDatasetNoSmote(label,asklabel)\n",
    "res_feat=importance(result,result_labels)\n",
    "wei_feat=importance(weighted,weighted_labels)\n",
    "blood_feat=importance(blood,blood_labels)\n",
    "ask_feat=importance(ask,ask_labels)\n",
    "res_acc,res_scores=NB(pd.DataFrame(result)[res_feat],result_labels,\"Result\")\n",
    "wei_acc,wei_scores=NB(pd.DataFrame(weighted)[wei_feat],weighted_labels,\"Weighted\")\n",
    "blood_acc,blood_scores=NB(pd.DataFrame(blood)[blood_feat],blood_labels,\"Blood\")\n",
    "ask_acc,ask_scores=NB(pd.DataFrame(ask)[ask_feat],ask_labels,\"Ask\")\n",
    "print(\"Res: Accuracy: \" + str(res_acc)+\" # \"+ \"Scores: \"+str(res_scores))\n",
    "print(\"Wei: Accuracy: \" + str(wei_acc)+\" # \"+ \"Scores: \"+str(wei_scores))\n",
    "print(\"Bld: Accuracy: \" + str(blood_acc)+\" # \"+ \"Scores: \"+str(blood_scores))\n",
    "print(\"Ask: Accuracy: \" + str(ask_acc)+\" # \"+ \"Scores: \"+str(ask_scores))\n",
    "Stats=Stats.append({'Dataset':\"Complete\",'Accuracy':res_acc,'Precision':res_scores[0],'Recall':res_scores[1],'FScore':res_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Weighted\",'Accuracy':wei_acc,'Precision':wei_scores[0],'Recall':wei_scores[1],'FScore':wei_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Blood\",'Accuracy':blood_acc,'Precision':blood_scores[0],'Recall':blood_scores[1],'FScore':blood_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"AskAPatient\",'Accuracy':ask_acc,'Precision':ask_scores[0],'Recall':ask_scores[1],'FScore':ask_scores[2]},ignore_index=True)\n",
    "Stats.to_excel('NBresult_Stats'+label+'importancesmoteless.xlsx') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes 10-Fold Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NB10Fold(result,result_labels,DataSet):\n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn.metrics import f1_score\n",
    "    from collections import Counter\n",
    "    kf = KFold(n_splits=10)\n",
    "\n",
    "    accuracy=[]\n",
    "\n",
    "    scores_rf=[]\n",
    "    print(Counter(result_labels))\n",
    "    count = 1\n",
    "    for train_index, test_index in kf.split(result):\n",
    "        X_train, X_test, Y_train, Y_test = result[train_index], result[test_index], result_labels[train_index],result_labels[test_index]\n",
    "        clf = GaussianNB()\n",
    "        clf.fit(X_train, Y_train)\n",
    "        pred=clf.predict(X_test)\n",
    "        accuracy.append(accuracy_score(Y_test, pred))\n",
    "        scores_rf.append(precision_recall_fscore_support(Y_test,pred, average='macro'))\n",
    "        \n",
    "        #print(str(count)+DataSet)\n",
    "        #print(f1_score(Y_test, pred, average='micro'))\n",
    "        count+=1\n",
    "        #print (pred)\n",
    "        #print(classification_report(Y_test,pred,labels=[0,1]))\n",
    "    accuracy = np.mean(accuracy,axis=0)   \n",
    "    return accuracy,average(scores_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NB10FoldNoSmote(result,result_labels,DataSet):\n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn.metrics import f1_score\n",
    "    from collections import Counter\n",
    "    kf = KFold(n_splits=10)\n",
    "\n",
    "    accuracy=[]\n",
    "\n",
    "    scores_rf=[]\n",
    "    print(Counter(result_labels))\n",
    "    count = 1\n",
    "    for train_index, test_index in kf.split(result):\n",
    "        X_train, X_test, Y_train, Y_test = result.iloc[train_index], result.iloc[test_index], result_labels[train_index],result_labels[test_index]\n",
    "        clf = GaussianNB()\n",
    "        clf.fit(X_train, Y_train)\n",
    "        pred=clf.predict(X_test)\n",
    "        accuracy.append(accuracy_score(Y_test, pred))\n",
    "        scores_rf.append(precision_recall_fscore_support(Y_test,pred, average='macro'))\n",
    "        \n",
    "        #print(str(count)+DataSet)\n",
    "        #print(f1_score(Y_test, pred, average='micro'))\n",
    "        count+=1\n",
    "        #print (pred)\n",
    "        #print(classification_report(Y_test,pred,labels=[0,1]))\n",
    "    accuracy = np.mean(accuracy,axis=0)   \n",
    "    return accuracy,average(scores_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes 10-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Beta': 739, 'Angiotensin': 428, 'Calcium': 261, 'Diuretics': 129})\n",
      "Counter({'Angiotensin': 51, 'Beta': 45, 'Calcium': 14, 'Diuretics': 13})\n",
      "Counter({'Beta': 186, 'Angiotensin': 134, 'Calcium': 89, 'Diuretics': 51})\n",
      "Counter({'Angiotensin': 622, 'Beta': 134})\n",
      "Counter({2: 739, 3: 739, 1: 739, 0: 739})\n",
      "Counter({2: 51, 3: 51, 1: 51, 0: 51})\n",
      "Counter({2: 186, 3: 186, 1: 186, 0: 186})\n",
      "Counter({0: 622, 1: 622})\n",
      "Res: Accuracy: 0.39831195602382047 # Scores: (0.3085599129502049, 0.1733916566191306, 0.1786742092069412)\n",
      "Wei: Accuracy: 0.43547619047619046 # Scores: (0.387844304388422, 0.2976629072681704, 0.29369561991452675)\n",
      "Bld: Accuracy: 0.45228828828828826 # Scores: (0.31875046908715643, 0.19632877903491758, 0.2213011835791415)\n",
      "Ask: Accuracy: 0.7602129032258065 # Scores: (0.5027777777777778, 0.4298817028027499, 0.431806107854796)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "Stats = pd.DataFrame(columns = ['Dataset','Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "\n",
    "label='DrugFamily'\n",
    "asklabel='DrugFamily'\n",
    "result,result_labels,weighted,weighted_labels,blood,blood_labels,ask,ask_labels=prepareDataset(label,asklabel)\n",
    "res_acc,res_scores=NB10Fold(result,result_labels,\"Result\")\n",
    "wei_acc,wei_scores=NB10Fold(weighted,weighted_labels,\"Weighted\")\n",
    "blood_acc,blood_scores=NB10Fold(blood,blood_labels,\"Blood\")\n",
    "ask_acc,ask_scores=NB10Fold(ask,ask_labels,\"Ask\")\n",
    "print(\"Res: Accuracy: \" + str(res_acc)+\" # \"+ \"Scores: \"+str(res_scores))\n",
    "print(\"Wei: Accuracy: \" + str(wei_acc)+\" # \"+ \"Scores: \"+str(wei_scores))\n",
    "print(\"Bld: Accuracy: \" + str(blood_acc)+\" # \"+ \"Scores: \"+str(blood_scores))\n",
    "print(\"Ask: Accuracy: \" + str(ask_acc)+\" # \"+ \"Scores: \"+str(ask_scores))\n",
    "Stats=Stats.append({'Dataset':\"Complete\",'Accuracy':res_acc,'Precision':res_scores[0],'Recall':res_scores[1],'FScore':res_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Weighted\",'Accuracy':wei_acc,'Precision':wei_scores[0],'Recall':wei_scores[1],'FScore':wei_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Blood\",'Accuracy':blood_acc,'Precision':blood_scores[0],'Recall':blood_scores[1],'FScore':blood_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"AskAPatient\",'Accuracy':ask_acc,'Precision':ask_scores[0],'Recall':ask_scores[1],'FScore':ask_scores[2]},ignore_index=True)\n",
    "Stats.to_excel('NBresult_Stats10Fold'+label+'.xlsx') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Beta': 739, 'Angiotensin': 428, 'Calcium': 261, 'Diuretics': 129})\n",
      "Counter({'Angiotensin': 51, 'Beta': 45, 'Calcium': 14, 'Diuretics': 13})\n",
      "Counter({'Beta': 186, 'Angiotensin': 134, 'Calcium': 89, 'Diuretics': 51})\n",
      "Counter({'Angiotensin': 622, 'Beta': 134})\n",
      "Counter({1: 739, 0: 428, 2: 261, 3: 129})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 51, 1: 45, 2: 14, 3: 13})\n",
      "Counter({1: 186, 0: 134, 2: 89, 3: 51})\n",
      "Counter({0: 622, 1: 134})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Res: Accuracy: 0.31732009925558313 # Scores: (0.2537050077543929, 0.10473894197866754, 0.13470876641368232)\n",
      "Wei: Accuracy: 0.10769230769230768 # Scores: (0.16333333333333333, 0.052083333333333336, 0.05348901098901099)\n",
      "Bld: Accuracy: 0.35 # Scores: (0.2672463768115942, 0.10546315203165557, 0.1381595457994706)\n",
      "Ask: Accuracy: 0.650701754385965 # Scores: (0.5319444444444444, 0.3576001709782932, 0.41652369567419384)\n"
     ]
    }
   ],
   "source": [
    "Stats = pd.DataFrame(columns = ['Dataset','Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "\n",
    "label='DrugFamily'\n",
    "asklabel='DrugFamily'\n",
    "result,result_labels,weighted,weighted_labels,blood,blood_labels,ask,ask_labels=prepareDatasetNoSmote(label,asklabel)\n",
    "res_acc,res_scores=NB10FoldNoSmote(result,result_labels,\"Result\")\n",
    "wei_acc,wei_scores=NB10FoldNoSmote(weighted,weighted_labels,\"Weighted\")\n",
    "blood_acc,blood_scores=NB10FoldNoSmote(blood,blood_labels,\"Blood\")\n",
    "ask_acc,ask_scores=NB10FoldNoSmote(ask,ask_labels,\"Ask\")\n",
    "print(\"Res: Accuracy: \" + str(res_acc)+\" # \"+ \"Scores: \"+str(res_scores))\n",
    "print(\"Wei: Accuracy: \" + str(wei_acc)+\" # \"+ \"Scores: \"+str(wei_scores))\n",
    "print(\"Bld: Accuracy: \" + str(blood_acc)+\" # \"+ \"Scores: \"+str(blood_scores))\n",
    "print(\"Ask: Accuracy: \" + str(ask_acc)+\" # \"+ \"Scores: \"+str(ask_scores))\n",
    "Stats=Stats.append({'Dataset':\"Complete\",'Accuracy':res_acc,'Precision':res_scores[0],'Recall':res_scores[1],'FScore':res_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Weighted\",'Accuracy':wei_acc,'Precision':wei_scores[0],'Recall':wei_scores[1],'FScore':wei_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Blood\",'Accuracy':blood_acc,'Precision':blood_scores[0],'Recall':blood_scores[1],'FScore':blood_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"AskAPatient\",'Accuracy':ask_acc,'Precision':ask_scores[0],'Recall':ask_scores[1],'FScore':ask_scores[2]},ignore_index=True)\n",
    "Stats.to_excel('NBresult_Stats10Fold'+label+'smoteless.xlsx') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from collections import Counter\\nfrom imblearn.over_sampling import SMOTENC\\nsm = SMOTENC(random_state=42, categorical_features=[0, 1,3])\\nX_res, y_res = sm.fit_resample(result, result_labels)\\nprint(Counter(result_labels))\\nprint(Counter(y_res))\\nprint(X_res)\\nprint(y_res)\\nprint(result_labels)'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from collections import Counter\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "sm = SMOTENC(random_state=42, categorical_features=[0, 1,3])\n",
    "X_res, y_res = sm.fit_resample(result, result_labels)\n",
    "print(Counter(result_labels))\n",
    "print(Counter(y_res))\n",
    "print(X_res)\n",
    "print(y_res)\n",
    "print(result_labels)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#average(wei_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_scores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wei_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wei_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 287,
   "position": {
    "height": "309px",
    "left": "263px",
    "right": "20px",
    "top": "125px",
    "width": "649px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
