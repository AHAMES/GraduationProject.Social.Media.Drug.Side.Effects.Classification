{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports necessary for running the program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'df = pd.read_excel(\"MLDataSet.xlsx\")\\ndf2 = pd.read_excel(\"ADRs.xlsx\")\\ndf3 = pd.read_excel(\"DS.xlsx\")\\ndf4 = pd.read_excel(\"Mental.xlsx\")\\n\\ndf5=[df, df2,  df3, df4]\\n\\nresult = pd.concat([df,df2,df3, df4], axis=1, join_axes=[df.index])'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sun May  5 23:01:42 2019\n",
    "\n",
    "@author: Ahmed\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "'''df = pd.read_excel(\"MLDataSet.xlsx\")\n",
    "df2 = pd.read_excel(\"ADRs.xlsx\")\n",
    "df3 = pd.read_excel(\"DS.xlsx\")\n",
    "df4 = pd.read_excel(\"Mental.xlsx\")\n",
    "\n",
    "df5=[df, df2,  df3, df4]\n",
    "\n",
    "result = pd.concat([df,df2,df3, df4], axis=1, join_axes=[df.index])'''\n",
    "#result.to_excel('result.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeColumns(result):\n",
    "    del result['Pain']\n",
    "    del result['Content']\n",
    "    del result['Filtered']\n",
    "    del result['Stemmed']\n",
    "    del result['big1']\n",
    "    del result['big2']\n",
    "    del result['small1']\n",
    "    del result['small2']\n",
    "    del result['Height']\n",
    "    del result['Joined']\n",
    "    del result['Posted']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorizeCount(result):\n",
    "    for i in range(len(result)):\n",
    "        if result[i]==0:\n",
    "            result[i]=0\n",
    "        if result[i]>0 and result[i]<=3:\n",
    "            result[i]=1\n",
    "        if result[i]>3:\n",
    "            result[i]=2\n",
    "    return result\n",
    "    '''if result.at[i,'MentalCount']==0:\n",
    "        result.at[i,'MentalCount']=0\n",
    "    if result.at[i,'MentalCount']>0 and result.at[i,'MentalCount']<=3:\n",
    "        result.at[i,'MentalCount']=1\n",
    "    if result.at[i,'MentalCount']>3:\n",
    "        result.at[i,'MentalCount']=2\n",
    "\n",
    "\n",
    "    if result.at[i,'DieaseCount']==0:\n",
    "        result.at[i,'DieaseCount']=0\n",
    "    if result.at[i,'DieaseCount']>0 and result.at[i,'DieaseCount']<=3:\n",
    "        result.at[i,'DieaseCount']=1\n",
    "    if result.at[i,'DieaseCount']>3:\n",
    "        result.at[i,'DieaseCount']=2'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### manipulating data to prepare for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manipulate(result,labelfile,label):\n",
    "    imp_mean = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "    result['Gender']=imp_mean.fit_transform(result['Gender'].values.reshape(-1, 1))\n",
    "    for i in range(len(result)):\n",
    "        if result.at[i,'Gender']=='Male':\n",
    "            result.at[i,'Gender']=0\n",
    "        if result.at[i,'Gender']=='Female':\n",
    "            result.at[i,'Gender']=1\n",
    "    result['Drug']=LabelEncoder().fit_transform(result['Drug'])\n",
    "    if 'Unnamed: 0' in result:\n",
    "        del result['Unnamed: 0'] \n",
    "    result['DrugFamily']=LabelEncoder().fit_transform(result['DrugFamily'])\n",
    "    labels=labelfile.iloc[:][label]\n",
    "    \n",
    "    #removeColumns(result)\n",
    "    imp_mean = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "    result['Age']=imp_mean.fit_transform(result['Age'].values.reshape(-1, 1))\n",
    "    if 'Height' in result:\n",
    "        result['Height']=imp_mean.fit_transform(result['Height'].values.reshape(-1, 1))\n",
    "    return result,labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label='Hypertensive disease '\n",
    "asklabel='Hypertensive disease '\n",
    "def prepareDataset(label,asklab):\n",
    "    result=pd.read_excel('result_reduced.xlsx')\n",
    "    weighted=pd.read_excel('Weighted_reduced.xlsx')\n",
    "    blood=pd.read_excel('blood_reduced.xlsx')\n",
    "    ask=pd.read_excel('askapatient_reduced.xlsx')\n",
    "\n",
    "    resultlabel=pd.read_excel('resultlabels.xlsx')\n",
    "    weightedlabel=pd.read_excel('Weightedlabels.xlsx')\n",
    "    bloodlabel=pd.read_excel('bloodlabels.xlsx')\n",
    "    asklabel=pd.read_excel('asklabels.xlsx')\n",
    "\n",
    "    result,result_labels=manipulate(result,resultlabel,label)\n",
    "    weighted,weighted_labels=manipulate(weighted,weightedlabel,label)\n",
    "    blood,blood_labels=manipulate(blood,bloodlabel,label)\n",
    "    ask,ask_labels=manipulate(ask,asklabel,asklab)\n",
    "    if 'Count' in label:\n",
    "        result_labels = vectorizeCount(result_labels)\n",
    "        weighted_labels = vectorizeCount(weighted_labels)\n",
    "        blood_labels=vectorizeCount(blood_labels)\n",
    "    if 'Count' in asklab:\n",
    "        ask_labels = vectorizeCount(ask_labels)\n",
    "    del result['weights2']\n",
    "    del result['Height']\n",
    "    return result,result_labels,weighted,weighted_labels,blood,blood_labels,ask,ask_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"for i in weighted:\\n    if i not in result:\\n        if i != 'weights2':\\n            del weighted[i]\\nweighted.to_excel('Weighted.xlsx')\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''for i in weighted:\n",
    "    if i not in result:\n",
    "        if i != 'weights2':\n",
    "            del weighted[i]\n",
    "weighted.to_excel('Weighted.xlsx')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ask_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for i in weighted:\\n    print (weighted[i])'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''for i in weighted:\n",
    "    print (weighted[i])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(model, X_train,X_test,Y_train,Y_test):\n",
    "    model.fit(X_train,Y_train)\n",
    "    return model.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10-Fold Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#cross_val_score(RandomForestClassifier(n_estimators=1000),result,result_labels,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This was used for some other no longer existing purposes\n",
    "def getMissingPercentage(feature):\n",
    "    #nancount = int(result[result[feature].isnull()][feature].shape[0])\n",
    "    nancount = int(result[result[feature]==1][feature].shape[0])\n",
    "    size=int(result.shape[0])\n",
    "    print (nancount)\n",
    "    print ((nancount*100)/size)\n",
    "#getMissingPercentage('Pvc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from sklearn.model_selection import KFold\\nfrom sklearn.ensemble import RandomForestClassifier\\nkf = KFold(n_splits=10)\\n\\nscores_rf=[]\\n\\nfor train_index, test_index in kf.split(result):\\n    X_train, X_test, Y_train, Y_test = result.iloc[train_index], result.iloc[test_index], result_labels.iloc[train_index],result_labels.iloc[test_index]\\n    scores_rf.append(get_score(RandomForestClassifier(n_estimators=400),X_train, X_test, Y_train, Y_test))'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "kf = KFold(n_splits=10)\n",
    "\n",
    "scores_rf=[]\n",
    "\n",
    "for train_index, test_index in kf.split(result):\n",
    "    X_train, X_test, Y_train, Y_test = result.iloc[train_index], result.iloc[test_index], result_labels.iloc[train_index],result_labels.iloc[test_index]\n",
    "    scores_rf.append(get_score(RandomForestClassifier(n_estimators=400),X_train, X_test, Y_train, Y_test))'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomForest(result,result_labels,estimators,DataSet):\n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn.metrics import f1_score\n",
    "    \n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(result, result_labels, test_size=0.45, random_state=42)\n",
    "    clf = RandomForestClassifier(n_estimators=estimators, max_depth=2,random_state=0)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    pred=clf.predict(X_test)\n",
    "    accuracy=(accuracy_score(Y_test, pred))\n",
    "    print (accuracy)\n",
    "    scores_rf=(precision_recall_fscore_support(Y_test,pred, average='macro'))\n",
    "    print(DataSet)\n",
    "    #print (pred)\n",
    "    print(classification_report(Y_test,pred,labels=[0,1,2]))\n",
    "        \n",
    "    return accuracy,scores_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier Function 10-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomForest10Fold(result,result_labels,estimators,DataSet):\n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn.metrics import f1_score\n",
    "    kf = KFold(n_splits=10)\n",
    "\n",
    "    accuracy=[]\n",
    "\n",
    "    scores_rf=[]\n",
    "    \n",
    "    count = 1\n",
    "    for train_index, test_index in kf.split(result):\n",
    "        X_train, X_test, Y_train, Y_test = result.iloc[train_index], result.iloc[test_index], result_labels.iloc[train_index],result_labels.iloc[test_index]\n",
    "        clf = RandomForestClassifier(n_estimators=estimators, max_depth=2,random_state=0)\n",
    "        clf.fit(X_train, Y_train)\n",
    "        pred=clf.predict(X_test)\n",
    "        accuracy.append(accuracy_score(Y_test, pred))\n",
    "        scores_rf.append(precision_recall_fscore_support(Y_test,pred, average='macro'))\n",
    "        print(str(count)+DataSet)\n",
    "        print(f1_score(Y_test, pred, average='macro'))\n",
    "        count+=1\n",
    "        #print (pred)\n",
    "        print(classification_report(Y_test,pred,labels=[0,1]))\n",
    "    accuracy = np.mean(accuracy,axis=0)   \n",
    "    return accuracy,scores_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with 10-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1Result\n",
      "0.26066350710900477\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      1.00      0.52        55\n",
      "           1       0.00      0.00      0.00       101\n",
      "\n",
      "   micro avg       0.35      0.35      0.35       156\n",
      "   macro avg       0.18      0.50      0.26       156\n",
      "weighted avg       0.12      0.35      0.18       156\n",
      "\n",
      "2Result\n",
      "0.44173419439759776\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.42      0.46        89\n",
      "           1       0.38      0.48      0.42        67\n",
      "\n",
      "   micro avg       0.44      0.44      0.44       156\n",
      "   macro avg       0.45      0.45      0.44       156\n",
      "weighted avg       0.46      0.44      0.44       156\n",
      "\n",
      "3Result\n",
      "0.4835577135290223\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.84      0.62        73\n",
      "           1       0.62      0.24      0.35        83\n",
      "\n",
      "   micro avg       0.52      0.52      0.52       156\n",
      "   macro avg       0.56      0.54      0.48       156\n",
      "weighted avg       0.56      0.52      0.47       156\n",
      "\n",
      "4Result\n",
      "0.34541293152775127\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.94      0.59        67\n",
      "           1       0.56      0.06      0.10        89\n",
      "\n",
      "   micro avg       0.44      0.44      0.44       156\n",
      "   macro avg       0.49      0.50      0.35       156\n",
      "weighted avg       0.50      0.44      0.31       156\n",
      "\n",
      "5Result\n",
      "0.3226053639846743\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.99      0.62        71\n",
      "           1       0.50      0.01      0.02        85\n",
      "\n",
      "   micro avg       0.46      0.46      0.46       156\n",
      "   macro avg       0.48      0.50      0.32       156\n",
      "weighted avg       0.48      0.46      0.30       156\n",
      "\n",
      "6Result\n",
      "0.5432363849307047\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.79      0.72       100\n",
      "           1       0.45      0.30      0.36        56\n",
      "\n",
      "   micro avg       0.62      0.62      0.62       156\n",
      "   macro avg       0.56      0.55      0.54       156\n",
      "weighted avg       0.59      0.62      0.59       156\n",
      "\n",
      "7Result\n",
      "0.4700854700854701\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.89      0.74        97\n",
      "           1       0.42      0.14      0.21        59\n",
      "\n",
      "   micro avg       0.60      0.60      0.60       156\n",
      "   macro avg       0.52      0.51      0.47       156\n",
      "weighted avg       0.55      0.60      0.53       156\n",
      "\n",
      "8Result\n",
      "0.3580808080808081\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.97      0.63        71\n",
      "           1       0.67      0.05      0.09        84\n",
      "\n",
      "   micro avg       0.47      0.47      0.47       155\n",
      "   macro avg       0.56      0.51      0.36       155\n",
      "weighted avg       0.57      0.47      0.34       155\n",
      "\n",
      "9Result\n",
      "0.483355132694823\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.59      0.54        80\n",
      "           1       0.47      0.39      0.42        75\n",
      "\n",
      "   micro avg       0.49      0.49      0.49       155\n",
      "   macro avg       0.49      0.49      0.48       155\n",
      "weighted avg       0.49      0.49      0.49       155\n",
      "\n",
      "10Result\n",
      "0.4902736748230311\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.66      0.75       131\n",
      "           1       0.17      0.38      0.23        24\n",
      "\n",
      "   micro avg       0.62      0.62      0.62       155\n",
      "   macro avg       0.51      0.52      0.49       155\n",
      "weighted avg       0.75      0.62      0.67       155\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1Weighted\n",
      "0.48000000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.92      0.96        13\n",
      "\n",
      "   micro avg       0.92      0.92      0.92        13\n",
      "   macro avg       0.50      0.46      0.48        13\n",
      "weighted avg       1.00      0.92      0.96        13\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2Weighted\n",
      "0.35000000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         6\n",
      "           1       0.54      1.00      0.70         7\n",
      "\n",
      "   micro avg       0.54      0.54      0.54        13\n",
      "   macro avg       0.27      0.50      0.35        13\n",
      "weighted avg       0.29      0.54      0.38        13\n",
      "\n",
      "3Weighted\n",
      "0.5666666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.25      0.33         4\n",
      "           1       0.73      0.89      0.80         9\n",
      "\n",
      "   micro avg       0.69      0.69      0.69        13\n",
      "   macro avg       0.61      0.57      0.57        13\n",
      "weighted avg       0.66      0.69      0.66        13\n",
      "\n",
      "4Weighted\n",
      "0.380952380952381\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         4\n",
      "           1       0.67      0.89      0.76         9\n",
      "\n",
      "   micro avg       0.62      0.62      0.62        13\n",
      "   macro avg       0.33      0.44      0.38        13\n",
      "weighted avg       0.46      0.62      0.53        13\n",
      "\n",
      "5Weighted\n",
      "0.35000000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         5\n",
      "           1       0.58      0.88      0.70         8\n",
      "\n",
      "   micro avg       0.54      0.54      0.54        13\n",
      "   macro avg       0.29      0.44      0.35        13\n",
      "weighted avg       0.36      0.54      0.43        13\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6Weighted\n",
      "0.23529411764705882\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         9\n",
      "           1       0.31      1.00      0.47         4\n",
      "\n",
      "   micro avg       0.31      0.31      0.31        13\n",
      "   macro avg       0.15      0.50      0.24        13\n",
      "weighted avg       0.09      0.31      0.14        13\n",
      "\n",
      "7Weighted\n",
      "0.7045454545454546\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.33      0.50         3\n",
      "           1       0.83      1.00      0.91        10\n",
      "\n",
      "   micro avg       0.85      0.85      0.85        13\n",
      "   macro avg       0.92      0.67      0.70        13\n",
      "weighted avg       0.87      0.85      0.81        13\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8Weighted\n",
      "0.35000000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         6\n",
      "           1       0.54      1.00      0.70         7\n",
      "\n",
      "   micro avg       0.54      0.54      0.54        13\n",
      "   macro avg       0.27      0.50      0.35        13\n",
      "weighted avg       0.29      0.54      0.38        13\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9Weighted\n",
      "0.35000000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         6\n",
      "           1       0.54      1.00      0.70         7\n",
      "\n",
      "   micro avg       0.54      0.54      0.54        13\n",
      "   macro avg       0.27      0.50      0.35        13\n",
      "weighted avg       0.29      0.54      0.38        13\n",
      "\n",
      "10Weighted\n",
      "0.4583333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.14      0.25         7\n",
      "           1       0.50      1.00      0.67         6\n",
      "\n",
      "   micro avg       0.54      0.54      0.54        13\n",
      "   macro avg       0.75      0.57      0.46        13\n",
      "weighted avg       0.77      0.54      0.44        13\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1Blood\n",
      "0.44705882352941173\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         9\n",
      "           1       0.81      1.00      0.89        38\n",
      "\n",
      "   micro avg       0.81      0.81      0.81        47\n",
      "   macro avg       0.40      0.50      0.45        47\n",
      "weighted avg       0.65      0.81      0.72        47\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2Blood\n",
      "0.3648648648648649\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        20\n",
      "           1       0.57      1.00      0.73        27\n",
      "\n",
      "   micro avg       0.57      0.57      0.57        47\n",
      "   macro avg       0.29      0.50      0.36        47\n",
      "weighted avg       0.33      0.57      0.42        47\n",
      "\n",
      "3Blood\n",
      "0.3918561607615018\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.15      0.19        20\n",
      "           1       0.51      0.69      0.59        26\n",
      "\n",
      "   micro avg       0.46      0.46      0.46        46\n",
      "   macro avg       0.39      0.42      0.39        46\n",
      "weighted avg       0.41      0.46      0.42        46\n",
      "\n",
      "4Blood\n",
      "0.46233766233766227\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.13      0.18        15\n",
      "           1       0.67      0.84      0.74        31\n",
      "\n",
      "   micro avg       0.61      0.61      0.61        46\n",
      "   macro avg       0.48      0.49      0.46        46\n",
      "weighted avg       0.54      0.61      0.56        46\n",
      "\n",
      "5Blood\n",
      "0.5892857142857143\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.40      0.43        15\n",
      "           1       0.73      0.77      0.75        31\n",
      "\n",
      "   micro avg       0.65      0.65      0.65        46\n",
      "   macro avg       0.59      0.59      0.59        46\n",
      "weighted avg       0.64      0.65      0.65        46\n",
      "\n",
      "6Blood\n",
      "0.3918561607615018\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.15      0.19        20\n",
      "           1       0.51      0.69      0.59        26\n",
      "\n",
      "   micro avg       0.46      0.46      0.46        46\n",
      "   macro avg       0.39      0.42      0.39        46\n",
      "weighted avg       0.41      0.46      0.42        46\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7Blood\n",
      "0.30303030303030304\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        26\n",
      "           1       0.43      1.00      0.61        20\n",
      "\n",
      "   micro avg       0.43      0.43      0.43        46\n",
      "   macro avg       0.22      0.50      0.30        46\n",
      "weighted avg       0.19      0.43      0.26        46\n",
      "\n",
      "8Blood\n",
      "0.5710955710955711\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.29      0.38        17\n",
      "           1       0.68      0.86      0.76        29\n",
      "\n",
      "   micro avg       0.65      0.65      0.65        46\n",
      "   macro avg       0.62      0.58      0.57        46\n",
      "weighted avg       0.63      0.65      0.62        46\n",
      "\n",
      "9Blood\n",
      "0.35664335664335667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.04      0.08        24\n",
      "           1       0.48      0.95      0.64        22\n",
      "\n",
      "   micro avg       0.48      0.48      0.48        46\n",
      "   macro avg       0.49      0.50      0.36        46\n",
      "weighted avg       0.49      0.48      0.34        46\n",
      "\n",
      "10Blood\n",
      "0.5892857142857142\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.27      0.43        22\n",
      "           1       0.60      1.00      0.75        24\n",
      "\n",
      "   micro avg       0.65      0.65      0.65        46\n",
      "   macro avg       0.80      0.64      0.59        46\n",
      "weighted avg       0.79      0.65      0.60        46\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1Ask\n",
      "0.45714285714285713\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91        64\n",
      "           1       0.00      0.00      0.00        12\n",
      "\n",
      "   micro avg       0.84      0.84      0.84        76\n",
      "   macro avg       0.42      0.50      0.46        76\n",
      "weighted avg       0.71      0.84      0.77        76\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2Ask\n",
      "0.45714285714285713\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91        64\n",
      "           1       0.00      0.00      0.00        12\n",
      "\n",
      "   micro avg       0.84      0.84      0.84        76\n",
      "   macro avg       0.42      0.50      0.46        76\n",
      "weighted avg       0.71      0.84      0.77        76\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3Ask\n",
      "0.4722222222222222\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94        68\n",
      "           1       0.00      0.00      0.00         8\n",
      "\n",
      "   micro avg       0.89      0.89      0.89        76\n",
      "   macro avg       0.45      0.50      0.47        76\n",
      "weighted avg       0.80      0.89      0.85        76\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4Ask\n",
      "0.46099290780141844\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92        65\n",
      "           1       0.00      0.00      0.00        11\n",
      "\n",
      "   micro avg       0.86      0.86      0.86        76\n",
      "   macro avg       0.43      0.50      0.46        76\n",
      "weighted avg       0.73      0.86      0.79        76\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5Ask\n",
      "0.4492753623188405\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90        62\n",
      "           1       0.00      0.00      0.00        14\n",
      "\n",
      "   micro avg       0.82      0.82      0.82        76\n",
      "   macro avg       0.41      0.50      0.45        76\n",
      "weighted avg       0.67      0.82      0.73        76\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6Ask\n",
      "0.44525547445255476\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89        61\n",
      "           1       0.00      0.00      0.00        15\n",
      "\n",
      "   micro avg       0.80      0.80      0.80        76\n",
      "   macro avg       0.40      0.50      0.45        76\n",
      "weighted avg       0.64      0.80      0.71        76\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7Ask\n",
      "0.423076923076923\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        55\n",
      "           1       0.00      0.00      0.00        20\n",
      "\n",
      "   micro avg       0.73      0.73      0.73        75\n",
      "   macro avg       0.37      0.50      0.42        75\n",
      "weighted avg       0.54      0.73      0.62        75\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8Ask\n",
      "0.4094488188976378\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      1.00      0.82        52\n",
      "           1       0.00      0.00      0.00        23\n",
      "\n",
      "   micro avg       0.69      0.69      0.69        75\n",
      "   macro avg       0.35      0.50      0.41        75\n",
      "weighted avg       0.48      0.69      0.57        75\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9Ask\n",
      "0.41860465116279066\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      1.00      0.84        54\n",
      "           1       0.00      0.00      0.00        21\n",
      "\n",
      "   micro avg       0.72      0.72      0.72        75\n",
      "   macro avg       0.36      0.50      0.42        75\n",
      "weighted avg       0.52      0.72      0.60        75\n",
      "\n",
      "10Ask\n",
      "0.4565217391304348\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91        63\n",
      "           1       0.00      0.00      0.00        12\n",
      "\n",
      "   micro avg       0.84      0.84      0.84        75\n",
      "   macro avg       0.42      0.50      0.46        75\n",
      "weighted avg       0.71      0.84      0.77        75\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "label='Hypertensive disease '\n",
    "asklabel='Hypertensive disease '\n",
    "result,result_labels,weighted,weighted_labels,blood,blood_labels,ask,ask_labels=prepareDataset(label,asklabel)\n",
    "res_acc,res_scores=randomForest10Fold(result,result_labels,500,\"Result\")\n",
    "wei_acc,wei_scores=randomForest10Fold(weighted,weighted_labels,500,\"Weighted\")\n",
    "blood_acc,blood_scores=randomForest10Fold(blood,blood_labels,500,\"Blood\")\n",
    "ask_acc,ask_scores=randomForest10Fold(ask,ask_labels,500,\"Ask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "3\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "3\n",
      "2\n",
      "0\n",
      "6\n",
      "0\n",
      "1\n",
      "0\n",
      "3\n",
      "3\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "1\n",
      "1\n",
      "0\n",
      "3\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "2\n",
      "4\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "0\n",
      "0\n",
      "3\n",
      "0\n",
      "2\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "4\n",
      "4\n",
      "0\n",
      "3\n",
      "5\n",
      "3\n",
      "4\n",
      "0\n",
      "1\n",
      "6\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "3\n",
      "4\n",
      "2\n",
      "1\n",
      "6\n",
      "6\n",
      "0\n",
      "2\n",
      "3\n",
      "5\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "1\n",
      "4\n",
      "4\n",
      "4\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "3\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "4\n",
      "3\n",
      "3\n",
      "5\n",
      "0\n",
      "0\n",
      "0\n",
      "3\n",
      "7\n",
      "2\n",
      "0\n",
      "4\n",
      "3\n",
      "3\n",
      "0\n",
      "4\n",
      "0\n",
      "5\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "3\n",
      "1\n",
      "1\n",
      "4\n",
      "2\n",
      "2\n",
      "1\n",
      "3\n",
      "2\n",
      "7\n",
      "3\n",
      "2\n",
      "5\n",
      "3\n",
      "1\n",
      "2\n",
      "2\n",
      "3\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "5\n",
      "3\n",
      "0\n",
      "0\n",
      "3\n",
      "4\n",
      "0\n",
      "9\n",
      "0\n",
      "3\n",
      "3\n",
      "0\n",
      "2\n",
      "2\n",
      "1\n",
      "3\n",
      "1\n",
      "6\n",
      "0\n",
      "2\n",
      "3\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "3\n",
      "2\n",
      "0\n",
      "4\n",
      "0\n",
      "1\n",
      "4\n",
      "2\n",
      "0\n",
      "0\n",
      "5\n",
      "1\n",
      "3\n",
      "1\n",
      "0\n",
      "2\n",
      "2\n",
      "9\n",
      "0\n",
      "0\n",
      "4\n",
      "4\n",
      "3\n",
      "6\n",
      "3\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "3\n",
      "6\n",
      "3\n",
      "0\n",
      "0\n",
      "2\n",
      "4\n",
      "0\n",
      "3\n",
      "1\n",
      "2\n",
      "0\n",
      "7\n",
      "3\n",
      "5\n",
      "0\n",
      "5\n",
      "0\n",
      "0\n",
      "6\n",
      "0\n",
      "7\n",
      "0\n",
      "0\n",
      "3\n",
      "0\n",
      "3\n",
      "1\n",
      "4\n",
      "2\n",
      "0\n",
      "6\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "3\n",
      "5\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "4\n",
      "0\n",
      "3\n",
      "1\n",
      "3\n",
      "0\n",
      "0\n",
      "1\n",
      "9\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "4\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "4\n",
      "3\n",
      "2\n",
      "6\n",
      "3\n",
      "0\n",
      "4\n",
      "0\n",
      "0\n",
      "5\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "4\n",
      "0\n",
      "1\n",
      "5\n",
      "1\n",
      "0\n",
      "0\n",
      "4\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "4\n",
      "7\n",
      "6\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "0\n",
      "5\n",
      "0\n",
      "3\n",
      "0\n",
      "3\n",
      "0\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "4\n",
      "4\n",
      "0\n",
      "4\n",
      "2\n",
      "5\n",
      "3\n",
      "0\n",
      "0\n",
      "6\n",
      "1\n",
      "2\n",
      "5\n",
      "1\n",
      "2\n",
      "0\n",
      "2\n",
      "1\n",
      "0\n",
      "0\n",
      "3\n",
      "2\n",
      "1\n",
      "0\n",
      "0\n",
      "7\n",
      "7\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "6\n",
      "2\n",
      "4\n",
      "0\n",
      "0\n",
      "0\n",
      "4\n",
      "1\n",
      "3\n",
      "4\n",
      "3\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "3\n",
      "3\n",
      "6\n",
      "6\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "0\n",
      "1\n",
      "0\n",
      "3\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "4\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "3\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "1\n",
      "3\n",
      "0\n",
      "1\n",
      "1\n",
      "5\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "5\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "3\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "3\n",
      "0\n",
      "2\n",
      "1\n",
      "3\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "3\n",
      "0\n",
      "2\n",
      "1\n",
      "0\n",
      "2\n",
      "3\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "3\n",
      "0\n",
      "3\n",
      "0\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "2\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "4\n",
      "0\n",
      "5\n",
      "3\n",
      "4\n",
      "4\n",
      "1\n",
      "6\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "4\n",
      "3\n",
      "2\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "3\n",
      "4\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "4\n",
      "5\n",
      "2\n",
      "4\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "6\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "4\n",
      "3\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "4\n",
      "5\n",
      "0\n",
      "5\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "4\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "4\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "3\n",
      "7\n",
      "3\n",
      "4\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "4\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "4\n",
      "7\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "4\n",
      "10\n",
      "6\n",
      "5\n",
      "3\n",
      "4\n",
      "0\n",
      "5\n",
      "1\n",
      "13\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "3\n",
      "2\n",
      "2\n",
      "0\n",
      "4\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "2\n",
      "2\n",
      "6\n",
      "0\n",
      "1\n",
      "4\n",
      "0\n",
      "7\n",
      "0\n",
      "0\n",
      "10\n",
      "3\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "5\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "3\n",
      "1\n",
      "0\n",
      "5\n",
      "0\n",
      "0\n",
      "2\n",
      "3\n",
      "6\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "5\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "5\n",
      "0\n",
      "2\n",
      "0\n",
      "5\n",
      "2\n",
      "0\n",
      "2\n",
      "3\n",
      "5\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "4\n",
      "2\n",
      "5\n",
      "1\n",
      "0\n",
      "4\n",
      "0\n",
      "0\n",
      "7\n",
      "0\n",
      "8\n",
      "0\n",
      "6\n",
      "4\n",
      "2\n",
      "0\n",
      "1\n",
      "3\n",
      "5\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "7\n",
      "1\n",
      "0\n",
      "1\n",
      "5\n",
      "5\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "3\n",
      "9\n",
      "2\n",
      "6\n",
      "2\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "5\n",
      "0\n",
      "6\n",
      "11\n",
      "2\n",
      "1\n",
      "5\n",
      "1\n",
      "0\n",
      "8\n",
      "8\n",
      "3\n",
      "0\n",
      "2\n",
      "6\n",
      "0\n",
      "0\n",
      "0\n",
      "6\n",
      "0\n",
      "1\n",
      "10\n",
      "5\n",
      "8\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "3\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "4\n",
      "6\n",
      "3\n",
      "0\n",
      "9\n",
      "6\n",
      "7\n",
      "5\n",
      "4\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "8\n",
      "2\n",
      "5\n",
      "1\n",
      "5\n",
      "0\n",
      "2\n",
      "3\n",
      "0\n",
      "0\n",
      "2\n",
      "3\n",
      "1\n",
      "0\n",
      "0\n",
      "2\n",
      "1\n",
      "3\n",
      "3\n",
      "5\n",
      "1\n",
      "3\n",
      "6\n",
      "0\n",
      "5\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "1\n",
      "3\n",
      "3\n",
      "5\n",
      "0\n",
      "6\n",
      "1\n",
      "0\n",
      "7\n",
      "7\n",
      "5\n",
      "10\n",
      "3\n",
      "0\n",
      "7\n",
      "2\n",
      "0\n",
      "1\n",
      "3\n",
      "3\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "5\n",
      "2\n",
      "2\n",
      "0\n",
      "8\n",
      "0\n",
      "7\n",
      "1\n",
      "6\n",
      "0\n",
      "6\n",
      "1\n",
      "9\n",
      "8\n",
      "10\n",
      "0\n",
      "0\n",
      "3\n",
      "9\n",
      "0\n",
      "0\n",
      "6\n",
      "4\n",
      "3\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "3\n",
      "0\n",
      "0\n",
      "2\n",
      "5\n",
      "0\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "5\n",
      "1\n",
      "2\n",
      "2\n",
      "5\n",
      "3\n",
      "5\n",
      "0\n",
      "3\n",
      "1\n",
      "0\n",
      "5\n",
      "1\n",
      "1\n",
      "2\n",
      "3\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "3\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "3\n",
      "1\n",
      "0\n",
      "0\n",
      "2\n",
      "5\n",
      "5\n",
      "1\n",
      "2\n",
      "2\n",
      "0\n",
      "4\n",
      "7\n",
      "4\n",
      "9\n",
      "4\n",
      "0\n",
      "0\n",
      "4\n",
      "1\n",
      "0\n",
      "2\n",
      "3\n",
      "2\n",
      "1\n",
      "0\n",
      "4\n",
      "3\n",
      "1\n",
      "1\n",
      "3\n",
      "2\n",
      "2\n",
      "1\n",
      "3\n",
      "0\n",
      "0\n",
      "6\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "5\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "4\n",
      "0\n",
      "3\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "5\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "4\n",
      "0\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "3\n",
      "2\n",
      "0\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "2\n",
      "5\n",
      "4\n",
      "2\n",
      "7\n",
      "3\n",
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "0\n",
      "2\n",
      "3\n",
      "0\n",
      "3\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "3\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "4\n",
      "1\n",
      "4\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "2\n",
      "5\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "3\n",
      "3\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "3\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "5\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "6\n",
      "7\n",
      "0\n",
      "2\n",
      "1\n",
      "0\n",
      "9\n",
      "0\n",
      "0\n",
      "6\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "3\n",
      "3\n",
      "8\n",
      "5\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "4\n",
      "7\n",
      "4\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "6\n",
      "1\n",
      "3\n",
      "1\n",
      "7\n",
      "5\n",
      "5\n",
      "2\n",
      "0\n",
      "2\n",
      "7\n",
      "10\n",
      "3\n",
      "4\n",
      "2\n",
      "1\n",
      "5\n",
      "3\n",
      "4\n",
      "1\n",
      "3\n",
      "1\n",
      "2\n",
      "4\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "9\n",
      "5\n",
      "7\n",
      "2\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "4\n",
      "0\n",
      "5\n",
      "1\n",
      "2\n",
      "0\n",
      "3\n",
      "0\n",
      "4\n",
      "13\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "10\n",
      "1\n",
      "2\n",
      "1\n",
      "6\n",
      "0\n",
      "2\n",
      "6\n",
      "0\n",
      "11\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "3\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "5\n",
      "2\n",
      "0\n",
      "2\n",
      "4\n",
      "0\n",
      "0\n",
      "9\n",
      "3\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "0\n",
      "4\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "5\n",
      "1\n",
      "4\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "13\n",
      "0\n",
      "5\n",
      "13\n",
      "4\n",
      "2\n",
      "7\n",
      "3\n",
      "9\n",
      "4\n",
      "3\n",
      "1\n",
      "8\n",
      "0\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "5\n",
      "3\n",
      "1\n",
      "0\n",
      "5\n",
      "9\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "6\n",
      "0\n",
      "3\n",
      "0\n",
      "0\n",
      "1\n",
      "4\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "3\n",
      "5\n",
      "4\n",
      "2\n",
      "0\n",
      "2\n",
      "1\n",
      "1\n",
      "5\n",
      "1\n",
      "3\n",
      "5\n",
      "3\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "0\n",
      "2\n",
      "3\n",
      "0\n",
      "10\n",
      "2\n",
      "5\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "1\n",
      "0\n",
      "5\n",
      "1\n",
      "0\n",
      "3\n",
      "12\n",
      "2\n",
      "5\n",
      "0\n",
      "6\n",
      "5\n",
      "9\n",
      "7\n",
      "9\n",
      "0\n",
      "4\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "7\n",
      "2\n",
      "5\n",
      "2\n",
      "0\n",
      "3\n",
      "2\n",
      "0\n",
      "0\n",
      "9\n",
      "0\n",
      "0\n",
      "3\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "5\n",
      "0\n",
      "3\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "3\n",
      "2\n",
      "4\n",
      "2\n",
      "1\n",
      "3\n",
      "3\n",
      "1\n",
      "9\n",
      "3\n",
      "0\n",
      "2\n",
      "6\n",
      "0\n",
      "3\n",
      "0\n",
      "3\n",
      "0\n",
      "3\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "4\n",
      "6\n",
      "4\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "7\n",
      "0\n",
      "5\n",
      "5\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "1\n",
      "0\n",
      "3\n",
      "6\n",
      "2\n",
      "5\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "5\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "8\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "4\n",
      "0\n",
      "2\n",
      "1\n",
      "1\n",
      "4\n",
      "0\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "4\n",
      "8\n",
      "0\n",
      "1\n",
      "4\n",
      "0\n",
      "0\n",
      "1\n",
      "7\n",
      "4\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "5\n",
      "2\n",
      "0\n",
      "0\n",
      "3\n",
      "2\n",
      "1\n",
      "1\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(result_labels)):\n",
    "    print (result_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    834\n",
      "1    723\n",
      "Name: Hypertensive disease , dtype: int64\n",
      "1    80\n",
      "0    50\n",
      "Name: Hypertensive disease , dtype: int64\n",
      "0    608\n",
      "1    148\n",
      "Name: Hypertensive disease , dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(result_labels.value_counts())\n",
    "print(weighted_labels.value_counts())\n",
    "print(ask_labels.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-667677621759>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ADRCount'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0masklabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ADRCount'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mresult_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweighted\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweighted_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mask_labels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprepareDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0masklabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mres_acc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mres_scores\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandomForest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mresult_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Result\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mwei_acc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwei_scores\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandomForest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweighted\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweighted_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Weighted\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 6)"
     ]
    }
   ],
   "source": [
    "label='ADRCount'\n",
    "asklabel='ADRCount'\n",
    "result,result_labels,weighted,weighted_labels,blood,blood_labels,ask,ask_labels=prepareDataset(label,asklabel)\n",
    "res_acc,res_scores=randomForest(result,result_labels,1000,\"Result\")\n",
    "wei_acc,wei_scores=randomForest(weighted,weighted_labels,1000,\"Weighted\")\n",
    "blood_acc,blood_scores=randomForest(blood,blood_labels,1000,\"Blood\")\n",
    "ask_acc,ask_scores=randomForest(ask,ask_labels,1000,\"Ask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7631954350927247"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6949152542372882"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6275659824046921"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.1762820512820513, 0.5, 0.26066350710900477, None),\n",
       " (0.4474206349206349, 0.44667113868857955, 0.44173419439759776, None),\n",
       " (0.5584677419354839, 0.5382901468889256, 0.4835577135290223, None),\n",
       " (0.4920634920634921, 0.49823914137179276, 0.34541293152775127, None),\n",
       " (0.4772727272727273, 0.4988400994200497, 0.3226053639846743, None),\n",
       " (0.5584299732381802, 0.5467857142857143, 0.5432363849307047, None),\n",
       " (0.5243949289281598, 0.5110955792416565, 0.4700854700854701, None),\n",
       " (0.5648769574944071, 0.5097250167672703, 0.3580808080808081, None),\n",
       " (0.48655913978494625, 0.4870833333333333, 0.483355132694823, None),\n",
       " (0.5113762486126526, 0.51956106870229, 0.4902736748230311, None)]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.5, 0.46153846153846156, 0.48000000000000004, None),\n",
       " (0.2692307692307692, 0.5, 0.35000000000000003, None),\n",
       " (0.6136363636363636, 0.5694444444444444, 0.5666666666666667, None),\n",
       " (0.3333333333333333, 0.4444444444444444, 0.380952380952381, None),\n",
       " (0.2916666666666667, 0.4375, 0.35000000000000003, None),\n",
       " (0.15384615384615385, 0.5, 0.23529411764705882, None),\n",
       " (0.9166666666666667, 0.6666666666666666, 0.7045454545454546, None),\n",
       " (0.2692307692307692, 0.5, 0.35000000000000003, None),\n",
       " (0.2692307692307692, 0.5, 0.35000000000000003, None),\n",
       " (0.75, 0.5714285714285714, 0.4583333333333333, None)]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.42105263157894735, 0.5, 0.45714285714285713, None),\n",
       " (0.42105263157894735, 0.5, 0.45714285714285713, None),\n",
       " (0.4473684210526316, 0.5, 0.4722222222222222, None),\n",
       " (0.4276315789473684, 0.5, 0.46099290780141844, None),\n",
       " (0.40789473684210525, 0.5, 0.4492753623188405, None),\n",
       " (0.40131578947368424, 0.5, 0.44525547445255476, None),\n",
       " (0.36666666666666664, 0.5, 0.423076923076923, None),\n",
       " (0.3466666666666667, 0.5, 0.4094488188976378, None),\n",
       " (0.36, 0.5, 0.41860465116279066, None),\n",
       " (0.42, 0.5, 0.4565217391304348, None)]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 357,
   "position": {
    "height": "309px",
    "left": "1199px",
    "right": "20px",
    "top": "-27px",
    "width": "649px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
