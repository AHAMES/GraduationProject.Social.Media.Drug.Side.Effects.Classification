{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports necessary for running the program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'df = pd.read_excel(\"MLDataSet.xlsx\")\\ndf2 = pd.read_excel(\"ADRs.xlsx\")\\ndf3 = pd.read_excel(\"DS.xlsx\")\\ndf4 = pd.read_excel(\"Mental.xlsx\")\\n\\ndf5=[df, df2,  df3, df4]\\n\\nresult = pd.concat([df,df2,df3, df4], axis=1, join_axes=[df.index])'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sun May  5 23:01:42 2019\n",
    "\n",
    "@author: Ahmed\n",
    "\"\"\"\n",
    "\n",
    "from openpyxl import load_workbook\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "'''df = pd.read_excel(\"MLDataSet.xlsx\")\n",
    "df2 = pd.read_excel(\"ADRs.xlsx\")\n",
    "df3 = pd.read_excel(\"DS.xlsx\")\n",
    "df4 = pd.read_excel(\"Mental.xlsx\")\n",
    "\n",
    "df5=[df, df2,  df3, df4]\n",
    "\n",
    "result = pd.concat([df,df2,df3, df4], axis=1, join_axes=[df.index])'''\n",
    "#result.to_excel('result.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeColumns(result):\n",
    "    del result['Pain']\n",
    "    del result['Content']\n",
    "    del result['Filtered']\n",
    "    del result['Stemmed']\n",
    "    del result['big1']\n",
    "    del result['big2']\n",
    "    del result['small1']\n",
    "    del result['small2']\n",
    "    del result['Height']\n",
    "    del result['Joined']\n",
    "    del result['Posted']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorizeCount(result):\n",
    "    '''for i in range(len(result)):\n",
    "        if result[i]==0:\n",
    "            result[i]=0\n",
    "        if result[i]>0 and result[i]<=3:\n",
    "            result[i]=1\n",
    "        if result[i]>3:\n",
    "            result[i]=2'''\n",
    "    for i in range(len(result)):\n",
    "        if result.at[i,'MentalCount']==0:\n",
    "            result.at[i,'MentalCount']=0\n",
    "        if result.at[i,'MentalCount']>0 and result.at[i,'MentalCount']<=3:\n",
    "            result.at[i,'MentalCount']=1\n",
    "        if result.at[i,'MentalCount']>3:\n",
    "            result.at[i,'MentalCount']=2\n",
    "            \n",
    "        if result.at[i,'ADRCount']==0:\n",
    "            result.at[i,'ADRCount']=0\n",
    "        if result.at[i,'ADRCount']>0 and result.at[i,'MentalCount']<=3:\n",
    "            result.at[i,'ADRCount']=1\n",
    "        if result.at[i,'ADRCount']>3:\n",
    "            result.at[i,'ADRCount']=2\n",
    "\n",
    "        if result.at[i,'DieaseCount']==0:\n",
    "            result.at[i,'DieaseCount']=0\n",
    "        if result.at[i,'DieaseCount']>0 and result.at[i,'DieaseCount']<=3:\n",
    "            result.at[i,'DieaseCount']=1\n",
    "        if result.at[i,'DieaseCount']>3:\n",
    "            result.at[i,'DieaseCount']=2\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### manipulating data to prepare for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manipulate(result,label):\n",
    "    imp_mean = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "    result['Gender']=imp_mean.fit_transform(result['Gender'].values.reshape(-1, 1))\n",
    "    result = vectorizeCount(result)\n",
    "    for i in range(len(result)):\n",
    "        if result.at[i,'Gender']=='Male':\n",
    "            result.at[i,'Gender']=0\n",
    "        if result.at[i,'Gender']=='Female':\n",
    "            result.at[i,'Gender']=1\n",
    "    result['Drug']=LabelEncoder().fit_transform(result['Drug'])\n",
    "    if 'Unnamed: 0' in result:\n",
    "        del result['Unnamed: 0'] \n",
    "    result['DrugFamily']=LabelEncoder().fit_transform(result['DrugFamily'])\n",
    "    labels=result.iloc[:][label]\n",
    "    del result[label]\n",
    "    #removeColumns(result)\n",
    "    imp_mean = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "    result['Age']=imp_mean.fit_transform(result['Age'].values.reshape(-1, 1))\n",
    "    if 'Height' in result:\n",
    "        result['Height']=imp_mean.fit_transform(result['Height'].values.reshape(-1, 1))\n",
    "    return result,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#asklabel=pd.read_excel('asklabels.xlsx')\n",
    "#labels=asklabel.iloc[:]['MICROCEPHALY , EPILEPSY , AND DIABETES SYNDROME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def SMOTE(begin,columns):\n",
    "    from imblearn.over_sampling import SMOTENC\n",
    "    x=[1]\n",
    "    x.extend(list(range(begin,len(columns))))\n",
    "    sm=SMOTENC(random_state=42, categorical_features=x)\n",
    "    return sm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label='ADRCount'\n",
    "asklabel='ADRCount'\n",
    "\n",
    "#from collections import Counter\n",
    "#X_res, y_res = sm.fit_resample(result, result_labels)\n",
    "#print(Counter(result_labels))\n",
    "#print(Counter(y_res))\n",
    "def prepareDataset(label,asklab):\n",
    "    from imblearn.over_sampling import SMOTENC\n",
    "    \n",
    "    \n",
    "    result=pd.read_excel('result_reduced.xlsx')\n",
    "    weighted=pd.read_excel('Weighted_reduced.xlsx')\n",
    "    blood=pd.read_excel('blood_reduced.xlsx')\n",
    "    ask=pd.read_excel('askapatient_reduced.xlsx')\n",
    "\n",
    "    result,result_labels=manipulate(result,label)\n",
    "    weighted,weighted_labels=manipulate(weighted,label)\n",
    "    blood,blood_labels=manipulate(blood,label)\n",
    "    ask,ask_labels=manipulate(ask,asklab)\n",
    "    \n",
    " \n",
    "\n",
    "    sm1 = SMOTE(2,result.columns)\n",
    "    sm2 = SMOTE(4,weighted.columns)\n",
    "    sm3 = SMOTE(4,blood.columns)\n",
    "    sm4 = SMOTE(2,ask.columns)\n",
    "    #Applying SMOTENC\n",
    "    result,result_labels=sm1.fit_resample(result,result_labels)\n",
    "    weighted,weighted_labels=sm2.fit_resample(weighted,weighted_labels)\n",
    "    blood,blood_labels=sm3.fit_resample(blood,blood_labels)\n",
    "    ask,ask_labels=sm4.fit_resample(ask,ask_labels)\n",
    "    return result,result_labels,weighted,weighted_labels,blood,blood_labels,ask,ask_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label='ADRCount'\n",
    "asklabel='ADRCount'\n",
    "\n",
    "#from collections import Counter\n",
    "#X_res, y_res = sm.fit_resample(result, result_labels)\n",
    "#print(Counter(result_labels))\n",
    "#print(Counter(y_res))\n",
    "def prepareDatasetNoSmote(label,asklab):\n",
    "    from imblearn.over_sampling import SMOTENC\n",
    "    \n",
    "    sm = SMOTENC(random_state=42, categorical_features=[0, 1,3])\n",
    "    \n",
    "    result=pd.read_excel('result_reduced.xlsx')\n",
    "    weighted=pd.read_excel('Weighted_reduced.xlsx')\n",
    "    blood=pd.read_excel('blood_reduced.xlsx')\n",
    "    ask=pd.read_excel('askapatient_reduced.xlsx')\n",
    "\n",
    "\n",
    "    result,result_labels=manipulate(result,label)\n",
    "    weighted,weighted_labels=manipulate(weighted,label)\n",
    "    blood,blood_labels=manipulate(blood,label)\n",
    "    ask,ask_labels=manipulate(ask,asklab)\n",
    "    \n",
    "    \n",
    "    #Applying SMOTENC\n",
    "    #result,result_labels=sm.fit_resample(result,result_labels)\n",
    "    #weighted,weighted_labels=sm.fit_resample(weighted,weighted_labels)\n",
    "    #blood,blood_labels=sm.fit_resample(blood,blood_labels)\n",
    "    #ask,ask_labels=sm.fit_resample(ask,ask_labels)\n",
    "    return result,result_labels,weighted,weighted_labels,blood,blood_labels,ask,ask_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"for i in weighted:\\n    if i not in result:\\n        if i != 'weights2':\\n            del weighted[i]\\nweighted.to_excel('Weighted.xlsx')\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''for i in weighted:\n",
    "    if i not in result:\n",
    "        if i != 'weights2':\n",
    "            del weighted[i]\n",
    "weighted.to_excel('Weighted.xlsx')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ask_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for i in weighted:\\n    print (weighted[i])'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''for i in weighted:\n",
    "    print (weighted[i])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(model, X_train,X_test,Y_train,Y_test):\n",
    "    model.fit(X_train,Y_train)\n",
    "    return model.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10-Fold Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#cross_val_score(RandomForestClassifier(n_estimators=1000),result,result_labels,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This was used for some other no longer existing purposes\n",
    "def getMissingPercentage(feature):\n",
    "    #nancount = int(result[result[feature].isnull()][feature].shape[0])\n",
    "    nancount = int(result[result[feature]==1][feature].shape[0])\n",
    "    size=int(result.shape[0])\n",
    "    print (nancount)\n",
    "    print ((nancount*100)/size)\n",
    "#getMissingPercentage('Pvc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importance(result,result_labels):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.feature_selection import SelectFromModel\n",
    "    from collections import Counter\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(result, result_labels, test_size=0.30, random_state=42)\n",
    "    X_train, X_test, Y_train, Y_test = pd.DataFrame(X_train),pd.DataFrame(X_test),pd.DataFrame(Y_train),pd.DataFrame(Y_test),\n",
    "    #print(Counter(result_labels))\n",
    "    sel = SelectFromModel(RandomForestClassifier(n_estimators = 500))\n",
    "    sel.fit(X_train, Y_train)\n",
    "    #print(sel.get_support())\n",
    "    selected_feat= X_train.columns[(sel.get_support())]\n",
    "    \n",
    "    #print(len(selected_feat))\n",
    "    print(selected_feat)\n",
    "\n",
    "\n",
    "    return selected_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotResult(name,max_res,max_wei,max_bld,max_ask,x1,x2,x3,x4):\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    fig, ax = plt.subplots()\n",
    "    width = 0.2\n",
    "\n",
    "    acc_m = (max_res['Accuracy'][x1],max_wei['Accuracy'][x2],max_bld['Accuracy'][x3],max_ask['Accuracy'][x4])\n",
    "    pre_m = (max_res['Precision'][x1],max_wei['Precision'][x2],max_bld['Precision'][x3],max_ask['Precision'][x4])\n",
    "    rec_m = (max_res['Recall'][x1],max_wei['Recall'][x2],max_bld['Recall'][x3],max_ask['Recall'][x4])\n",
    "    fse_m = (max_res['FScore'][x1],max_wei['FScore'][x2],max_bld['FScore'][x3],max_ask['FScore'][x4])\n",
    "\n",
    "    ind = np.arange(len(acc_m)) \n",
    "    old_ind =  ind\n",
    "    rects1 = ax.bar(ind,acc_m, width=width ,label='accuracy')\n",
    "    ind = ind + width\n",
    "    rects2 = ax.bar(ind,pre_m, width=width,label='Precision')\n",
    "    ind = ind + width\n",
    "    rects3 = ax.bar(ind,rec_m, width=width,label='recall')\n",
    "    ind = ind + width\n",
    "    rects4 = ax.bar(ind,fse_m, width=width ,label='fscore')\n",
    "\n",
    "\n",
    "    # Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "    ax.set_ylabel('Scores')\n",
    "    ax.set_title(name)\n",
    "    ax.set_xticks(old_ind+ width *2)\n",
    "    ax.set_xticklabels(('complete', 'weighted', 'pressure', 'ask'))\n",
    "    box = ax.get_position()\n",
    "    ax.set_position([box.x0, box.y0,box.width, box.height * 0.6])\n",
    "    ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05), fancybox=True,shadow=True, ncol=4)\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from sklearn.model_selection import KFold\\nfrom sklearn.ensemble import RandomForestClassifier\\nkf = KFold(n_splits=10)\\n\\nscores_rf=[]\\n\\nfor train_index, test_index in kf.split(result):\\n    X_train, X_test, Y_train, Y_test = result.iloc[train_index], result.iloc[test_index], result_labels.iloc[train_index],result_labels.iloc[test_index]\\n    scores_rf.append(get_score(RandomForestClassifier(n_estimators=400),X_train, X_test, Y_train, Y_test))'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "kf = KFold(n_splits=10)\n",
    "\n",
    "scores_rf=[]\n",
    "\n",
    "for train_index, test_index in kf.split(result):\n",
    "    X_train, X_test, Y_train, Y_test = result.iloc[train_index], result.iloc[test_index], result_labels.iloc[train_index],result_labels.iloc[test_index]\n",
    "    scores_rf.append(get_score(RandomForestClassifier(n_estimators=400),X_train, X_test, Y_train, Y_test))'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomForest(result,result_labels,estimators,DataSet):\n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn.metrics import f1_score\n",
    "    from collections import Counter\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(result, result_labels, test_size=0.30, random_state=42)\n",
    "    print(Counter(result_labels))\n",
    "    clf = RandomForestClassifier(n_estimators=estimators,random_state=0)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    pred=clf.predict(X_test)\n",
    "    accuracy=(accuracy_score(Y_test, pred))\n",
    "    #print (accuracy)\n",
    "    scores_rf=(precision_recall_fscore_support(Y_test,pred, average='macro'))\n",
    "    #print(DataSet)\n",
    "    #print (pred)\n",
    "    #print(classification_report(Y_test,pred,labels=[0,1,2]))\n",
    "        \n",
    "    return accuracy,scores_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "Counter({1: 834, 0: 834})\n",
      "Counter({1: 80, 0: 80})\n",
      "Counter({1: 274, 0: 274})\n",
      "Counter({0: 608, 1: 608})\n",
      "Res: Accuracy: 0.7305389221556886 # Scores: (0.7307158579768398, 0.7305099601593625, 0.730470197699024, None)\n",
      "Wei: Accuracy: 0.75 # Scores: (0.75, 0.75, 0.75, None)\n",
      "Bld: Accuracy: 0.7636363636363637 # Scores: (0.771505376344086, 0.7679045092838197, 0.7633234028467395, None)\n",
      "Ask: Accuracy: 0.821917808219178 # Scores: (0.8229560881840572, 0.8258333333333334, 0.8216554285155868, None)\n",
      "200\n",
      "Counter({1: 834, 0: 834})\n",
      "Counter({1: 80, 0: 80})\n",
      "Counter({1: 274, 0: 274})\n",
      "Counter({0: 608, 1: 608})\n",
      "Res: Accuracy: 0.7305389221556886 # Scores: (0.730979909930052, 0.7304940239043825, 0.730384242815628, None)\n",
      "Wei: Accuracy: 0.7291666666666666 # Scores: (0.7328042328042328, 0.7291666666666666, 0.7281045751633988, None)\n",
      "Bld: Accuracy: 0.7636363636363637 # Scores: (0.7740601503759399, 0.7685676392572944, 0.7630794153381686, None)\n",
      "Ask: Accuracy: 0.8136986301369863 # Scores: (0.8158068783068784, 0.8183333333333334, 0.8135292703449934, None)\n",
      "300\n",
      "Counter({1: 834, 0: 834})\n",
      "Counter({1: 80, 0: 80})\n",
      "Counter({1: 274, 0: 274})\n",
      "Counter({0: 608, 1: 608})\n",
      "Res: Accuracy: 0.7305389221556886 # Scores: (0.7308330673475902, 0.7305019920318725, 0.730431524784676, None)\n",
      "Wei: Accuracy: 0.7291666666666666 # Scores: (0.7328042328042328, 0.7291666666666666, 0.7281045751633988, None)\n",
      "Bld: Accuracy: 0.7636363636363637 # Scores: (0.7740601503759399, 0.7685676392572944, 0.7630794153381686, None)\n",
      "Ask: Accuracy: 0.810958904109589 # Scores: (0.8134586466165414, 0.8158333333333334, 0.8108169014084508, None)\n",
      "400\n",
      "Counter({1: 834, 0: 834})\n",
      "Counter({1: 80, 0: 80})\n",
      "Counter({1: 274, 0: 274})\n",
      "Counter({0: 608, 1: 608})\n",
      "Res: Accuracy: 0.7245508982035929 # Scores: (0.7247758384122021, 0.7245179282868526, 0.7244619799139167, None)\n",
      "Wei: Accuracy: 0.7291666666666666 # Scores: (0.7328042328042328, 0.7291666666666666, 0.7281045751633988, None)\n",
      "Bld: Accuracy: 0.7818181818181819 # Scores: (0.788787969029184, 0.7858090185676392, 0.7816176470588234, None)\n",
      "Ask: Accuracy: 0.810958904109589 # Scores: (0.8134586466165414, 0.8158333333333334, 0.8108169014084508, None)\n",
      "500\n",
      "Counter({1: 834, 0: 834})\n",
      "Counter({1: 80, 0: 80})\n",
      "Counter({1: 274, 0: 274})\n",
      "Counter({0: 608, 1: 608})\n",
      "Res: Accuracy: 0.7245508982035929 # Scores: (0.7246762773489825, 0.7245258964143426, 0.7244971149861329, None)\n",
      "Wei: Accuracy: 0.7291666666666666 # Scores: (0.7328042328042328, 0.7291666666666666, 0.7281045751633988, None)\n",
      "Bld: Accuracy: 0.7757575757575758 # Scores: (0.7815562815562815, 0.7793987621573828, 0.7756257120805615, None)\n",
      "Ask: Accuracy: 0.810958904109589 # Scores: (0.8134586466165414, 0.8158333333333334, 0.8108169014084508, None)\n",
      "600\n",
      "Counter({1: 834, 0: 834})\n",
      "Counter({1: 80, 0: 80})\n",
      "Counter({1: 274, 0: 274})\n",
      "Counter({0: 608, 1: 608})\n",
      "Res: Accuracy: 0.7285429141716567 # Scores: (0.728598756575801, 0.7285258964143426, 0.7285158740277955, None)\n",
      "Wei: Accuracy: 0.7291666666666666 # Scores: (0.7328042328042328, 0.7291666666666666, 0.7281045751633988, None)\n",
      "Bld: Accuracy: 0.7757575757575758 # Scores: (0.779642223536369, 0.7787356321839081, 0.7757246243708902, None)\n",
      "Ask: Accuracy: 0.810958904109589 # Scores: (0.8134586466165414, 0.8158333333333334, 0.8108169014084508, None)\n",
      "700\n",
      "Counter({1: 834, 0: 834})\n",
      "Counter({1: 80, 0: 80})\n",
      "Counter({1: 274, 0: 274})\n",
      "Counter({0: 608, 1: 608})\n",
      "Res: Accuracy: 0.7325349301397206 # Scores: (0.7325920612147298, 0.7325179282868526, 0.7325082876450338, None)\n",
      "Wei: Accuracy: 0.7291666666666666 # Scores: (0.7328042328042328, 0.7291666666666666, 0.7281045751633988, None)\n",
      "Bld: Accuracy: 0.7696969696969697 # Scores: (0.7744444444444445, 0.7729885057471264, 0.769620811287478, None)\n",
      "Ask: Accuracy: 0.810958904109589 # Scores: (0.8134586466165414, 0.8158333333333334, 0.8108169014084508, None)\n",
      "800\n",
      "Counter({1: 834, 0: 834})\n",
      "Counter({1: 80, 0: 80})\n",
      "Counter({1: 274, 0: 274})\n",
      "Counter({0: 608, 1: 608})\n",
      "Res: Accuracy: 0.7325349301397206 # Scores: (0.7325920612147298, 0.7325179282868526, 0.7325082876450338, None)\n",
      "Wei: Accuracy: 0.7291666666666666 # Scores: (0.7328042328042328, 0.7291666666666666, 0.7281045751633988, None)\n",
      "Bld: Accuracy: 0.7818181818181819 # Scores: (0.7849025974025974, 0.7844827586206897, 0.7818101674992655, None)\n",
      "Ask: Accuracy: 0.810958904109589 # Scores: (0.8134586466165414, 0.8158333333333334, 0.8108169014084508, None)\n",
      "900\n",
      "Counter({1: 834, 0: 834})\n",
      "Counter({1: 80, 0: 80})\n",
      "Counter({1: 274, 0: 274})\n",
      "Counter({0: 608, 1: 608})\n",
      "Res: Accuracy: 0.7365269461077845 # Scores: (0.7365853658536585, 0.7365099601593625, 0.736500701262272, None)\n",
      "Wei: Accuracy: 0.7291666666666666 # Scores: (0.7328042328042328, 0.7291666666666666, 0.7281045751633988, None)\n",
      "Bld: Accuracy: 0.7696969696969697 # Scores: (0.7727272727272727, 0.7723253757736517, 0.7696885101381135, None)\n",
      "Ask: Accuracy: 0.810958904109589 # Scores: (0.8134586466165414, 0.8158333333333334, 0.8108169014084508, None)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "label='Hypertensive disease '\n",
    "asklabel='Hypertensive disease '\n",
    "res_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "wei_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "bld_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "ask_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "for estimators in range (100,1000,100):\n",
    "    print (estimators)\n",
    "    result,result_labels,weighted,weighted_labels,blood,blood_labels,ask,ask_labels=prepareDataset(label,asklabel)\n",
    "    res_acc,res_scores=randomForest(result,result_labels,estimators,\"Result\")\n",
    "    wei_acc,wei_scores=randomForest(weighted,weighted_labels,estimators,\"Weighted\")\n",
    "    blood_acc,blood_scores=randomForest(blood,blood_labels,estimators,\"Blood\")\n",
    "    ask_acc,ask_scores=randomForest(ask,ask_labels,estimators,\"Ask\")\n",
    "    print(\"Res: Accuracy: \" + str(res_acc)+\" # \"+ \"Scores: \"+str(res_scores))\n",
    "    print(\"Wei: Accuracy: \" + str(wei_acc)+\" # \"+ \"Scores: \"+str(wei_scores))\n",
    "    print(\"Bld: Accuracy: \" + str(blood_acc)+\" # \"+ \"Scores: \"+str(blood_scores))\n",
    "    print(\"Ask: Accuracy: \" + str(ask_acc)+\" # \"+ \"Scores: \"+str(ask_scores))\n",
    "    res_Stats=res_Stats.append({'Estimators':estimators,'Accuracy':res_acc,'Precision':res_scores[0],'Recall':res_scores[1],'FScore':res_scores[2]},ignore_index=True)\n",
    "    wei_Stats=wei_Stats.append({'Estimators':estimators,'Accuracy':wei_acc,'Precision':wei_scores[0],'Recall':wei_scores[1],'FScore':wei_scores[2]},ignore_index=True)\n",
    "    bld_Stats=bld_Stats.append({'Estimators':estimators,'Accuracy':blood_acc,'Precision':blood_scores[0],'Recall':blood_scores[1],'FScore':blood_scores[2]},ignore_index=True)\n",
    "    ask_Stats=ask_Stats.append({'Estimators':estimators,'Accuracy':ask_acc,'Precision':ask_scores[0],'Recall':ask_scores[1],'FScore':ask_scores[2]},ignore_index=True)\n",
    "'''writer = pd.ExcelWriter('Forrest_Stats'+label+'.xlsx', engine='xlsxwriter')\n",
    "res_Stats.to_excel(writer, sheet_name='Sheet1') \n",
    "wei_Stats.to_excel(writer, sheet_name='Sheet2') \n",
    "bld_Stats.to_excel(writer, sheet_name='Sheet3') \n",
    "ask_Stats.to_excel(writer, sheet_name='Sheet4')\n",
    "writer.save()'''\n",
    "x1=res_Stats['FScore'].tolist().index(max(res_Stats['FScore'].tolist()))\n",
    "x2=wei_Stats['FScore'].tolist().index(max(wei_Stats['FScore'].tolist()))\n",
    "x3=bld_Stats['FScore'].tolist().index(max(bld_Stats['FScore'].tolist()))\n",
    "x4=ask_Stats['FScore'].tolist().index(max(ask_Stats['FScore'].tolist()))\n",
    "max_res=res_Stats.iloc[x1].to_frame().transpose()\n",
    "max_wei=wei_Stats.iloc[x2].to_frame().transpose()\n",
    "max_bld=bld_Stats.iloc[x3].to_frame().transpose()\n",
    "max_ask=ask_Stats.iloc[x4].to_frame().transpose()\n",
    "stats=pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "max_res['Estimators']=\"Complete\"\n",
    "max_wei['Estimators']=\"Weighted\"\n",
    "max_bld['Estimators']=\"Pressure\"\n",
    "max_ask['Estimators']=\"Ask\"\n",
    "stats=stats.append(max_res)\n",
    "stats=stats.append(max_wei)\n",
    "stats=stats.append(max_bld)\n",
    "stats=stats.append(max_ask)\n",
    "\n",
    "plotResult(label+\" Random Forest With Smote\",max_res,max_wei,max_bld,max_ask,x1,x2,x3,x4)\n",
    "\n",
    "import os.path\n",
    "if not os.path.exists('Forrest_StatsTotal'+'.xlsx'):\n",
    "    writer = pd.ExcelWriter('Forrest_StatsTotal'+'.xlsx', engine = 'xlsxwriter')\n",
    "\n",
    "    writer.save()\n",
    "    writer.close()\n",
    "writer = pd.ExcelWriter('Forrest_StatsTotal'+'.xlsx', engine='openpyxl')\n",
    "book = load_workbook('Forrest_StatsTotal'+'.xlsx')\n",
    "writer.book = book\n",
    "writer.sheets = dict((ws.title, ws) for ws in book.worksheets)\n",
    "\n",
    "stats.to_excel(writer, sheet_name=label)\n",
    "writer.save()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests with importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 834, 0: 834})\n",
      "Counter({1: 80, 0: 80})\n",
      "Counter({1: 274, 0: 274})\n",
      "Counter({0: 608, 1: 608})\n",
      "Res: Accuracy: 0.6906187624750499 # Scores: (0.69087239541785, 0.6906533864541833, 0.6905398566173979, None)\n",
      "Wei: Accuracy: 0.7708333333333334 # Scores: (0.771304347826087, 0.7708333333333333, 0.7707338254450717, None)\n",
      "Bld: Accuracy: 0.7575757575757576 # Scores: (0.7569852941176471, 0.7575154730327144, 0.7571386517515455, None)\n",
      "Ask: Accuracy: 0.8383561643835616 # Scores: (0.8367742326088272, 0.8371212121212122, 0.8369412958377818, None)\n",
      "200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 834, 0: 834})\n",
      "Counter({1: 80, 0: 80})\n",
      "Counter({1: 274, 0: 274})\n",
      "Counter({0: 608, 1: 608})\n",
      "Res: Accuracy: 0.6926147704590818 # Scores: (0.6928174944970811, 0.6926454183266932, 0.6925547515062642, None)\n",
      "Wei: Accuracy: 0.7708333333333334 # Scores: (0.771304347826087, 0.7708333333333333, 0.7707338254450717, None)\n",
      "Bld: Accuracy: 0.7515151515151515 # Scores: (0.7511022927689595, 0.7517683465959328, 0.7511861414542647, None)\n",
      "Ask: Accuracy: 0.8383561643835616 # Scores: (0.8367742326088272, 0.8371212121212122, 0.8369412958377818, None)\n",
      "300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 834, 0: 834})\n",
      "Counter({1: 80, 0: 80})\n",
      "Counter({1: 274, 0: 274})\n",
      "Counter({0: 608, 1: 608})\n",
      "Res: Accuracy: 0.6906187624750499 # Scores: (0.6907731070995726, 0.6906454183266932, 0.6905743828820752, None)\n",
      "Wei: Accuracy: 0.75 # Scores: (0.7517482517482517, 0.75, 0.7495652173913043, None)\n",
      "Bld: Accuracy: 0.7575757575757576 # Scores: (0.7574199235968263, 0.7581786030061892, 0.7573529411764706, None)\n",
      "Ask: Accuracy: 0.8328767123287671 # Scores: (0.8312496216019858, 0.831590909090909, 0.8314138821373676, None)\n",
      "400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 834, 0: 834})\n",
      "Counter({1: 80, 0: 80})\n",
      "Counter({1: 274, 0: 274})\n",
      "Counter({0: 608, 1: 608})\n",
      "Res: Accuracy: 0.6906187624750499 # Scores: (0.6907731070995726, 0.6906454183266932, 0.6905743828820752, None)\n",
      "Wei: Accuracy: 0.75 # Scores: (0.7517482517482517, 0.75, 0.7495652173913043, None)\n",
      "Bld: Accuracy: 0.7515151515151515 # Scores: (0.7511022927689595, 0.7517683465959328, 0.7511861414542647, None)\n",
      "Ask: Accuracy: 0.8328767123287671 # Scores: (0.8311578438481992, 0.832121212121212, 0.8315822119348568, None)\n",
      "500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 834, 0: 834})\n",
      "Counter({1: 80, 0: 80})\n",
      "Counter({1: 274, 0: 274})\n",
      "Counter({0: 608, 1: 608})\n",
      "Res: Accuracy: 0.6906187624750499 # Scores: (0.6907731070995726, 0.6906454183266932, 0.6905743828820752, None)\n",
      "Wei: Accuracy: 0.7708333333333334 # Scores: (0.771304347826087, 0.7708333333333333, 0.7707338254450717, None)\n",
      "Bld: Accuracy: 0.7515151515151515 # Scores: (0.7511022927689595, 0.7517683465959328, 0.7511861414542647, None)\n",
      "Ask: Accuracy: 0.8383561643835616 # Scores: (0.8367742326088272, 0.8371212121212122, 0.8369412958377818, None)\n",
      "600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 834, 0: 834})\n",
      "Counter({1: 80, 0: 80})\n",
      "Counter({1: 274, 0: 274})\n",
      "Counter({0: 608, 1: 608})\n",
      "Res: Accuracy: 0.6906187624750499 # Scores: (0.6907731070995726, 0.6906454183266932, 0.6905743828820752, None)\n",
      "Wei: Accuracy: 0.75 # Scores: (0.7517482517482517, 0.75, 0.7495652173913043, None)\n",
      "Bld: Accuracy: 0.7515151515151515 # Scores: (0.7511022927689595, 0.7517683465959328, 0.7511861414542647, None)\n",
      "Ask: Accuracy: 0.8328767123287671 # Scores: (0.8311578438481992, 0.832121212121212, 0.8315822119348568, None)\n",
      "700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 834, 0: 834})\n",
      "Counter({1: 80, 0: 80})\n",
      "Counter({1: 274, 0: 274})\n",
      "Counter({0: 608, 1: 608})\n",
      "Res: Accuracy: 0.6906187624750499 # Scores: (0.6907731070995726, 0.6906454183266932, 0.6905743828820752, None)\n",
      "Wei: Accuracy: 0.75 # Scores: (0.7517482517482517, 0.75, 0.7495652173913043, None)\n",
      "Bld: Accuracy: 0.7515151515151515 # Scores: (0.7511022927689595, 0.7517683465959328, 0.7511861414542647, None)\n",
      "Ask: Accuracy: 0.8383561643835616 # Scores: (0.8367742326088272, 0.8371212121212122, 0.8369412958377818, None)\n",
      "800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 834, 0: 834})\n",
      "Counter({1: 80, 0: 80})\n",
      "Counter({1: 274, 0: 274})\n",
      "Counter({0: 608, 1: 608})\n",
      "Res: Accuracy: 0.6906187624750499 # Scores: (0.6907731070995726, 0.6906454183266932, 0.6905743828820752, None)\n",
      "Wei: Accuracy: 0.75 # Scores: (0.7517482517482517, 0.75, 0.7495652173913043, None)\n",
      "Bld: Accuracy: 0.7515151515151515 # Scores: (0.7511022927689595, 0.7517683465959328, 0.7511861414542647, None)\n",
      "Ask: Accuracy: 0.8328767123287671 # Scores: (0.8311578438481992, 0.832121212121212, 0.8315822119348568, None)\n",
      "900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 834, 0: 834})\n",
      "Counter({1: 80, 0: 80})\n",
      "Counter({1: 274, 0: 274})\n",
      "Counter({0: 608, 1: 608})\n",
      "Res: Accuracy: 0.7025948103792415 # Scores: (0.7029932950191571, 0.7026374501992032, 0.7024762755030869, None)\n",
      "Wei: Accuracy: 0.7708333333333334 # Scores: (0.771304347826087, 0.7708333333333333, 0.7707338254450717, None)\n",
      "Bld: Accuracy: 0.7515151515151515 # Scores: (0.7511022927689595, 0.7517683465959328, 0.7511861414542647, None)\n",
      "Ask: Accuracy: 0.8328767123287671 # Scores: (0.8311578438481992, 0.832121212121212, 0.8315822119348568, None)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "label='Hypertensive disease '\n",
    "asklabel='Hypertensive disease '\n",
    "res_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "wei_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "bld_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "ask_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "for estimators in range (100,1000,100):\n",
    "    print (estimators)\n",
    "    result,result_labels,weighted,weighted_labels,blood,blood_labels,ask,ask_labels=prepareDataset(label,asklabel)\n",
    "    res_feat=importance(result,result_labels)\n",
    "    wei_feat=importance(weighted,weighted_labels)\n",
    "    blood_feat=importance(blood,blood_labels)\n",
    "    ask_feat=importance(ask,ask_labels)\n",
    "    res_acc,res_scores=randomForest(pd.DataFrame(result)[res_feat],result_labels,estimators,\"Result\")\n",
    "    wei_acc,wei_scores=randomForest(pd.DataFrame(weighted)[wei_feat],weighted_labels,estimators,\"Weighted\")\n",
    "    blood_acc,blood_scores=randomForest(pd.DataFrame(blood)[blood_feat],blood_labels,estimators,\"Blood\")\n",
    "    ask_acc,ask_scores=randomForest(pd.DataFrame(ask)[ask_feat],ask_labels,estimators,\"Ask\")\n",
    "    print(\"Res: Accuracy: \" + str(res_acc)+\" # \"+ \"Scores: \"+str(res_scores))\n",
    "    print(\"Wei: Accuracy: \" + str(wei_acc)+\" # \"+ \"Scores: \"+str(wei_scores))\n",
    "    print(\"Bld: Accuracy: \" + str(blood_acc)+\" # \"+ \"Scores: \"+str(blood_scores))\n",
    "    print(\"Ask: Accuracy: \" + str(ask_acc)+\" # \"+ \"Scores: \"+str(ask_scores))\n",
    "    res_Stats=res_Stats.append({'Estimators':estimators,'Accuracy':res_acc,'Precision':res_scores[0],'Recall':res_scores[1],'FScore':res_scores[2]},ignore_index=True)\n",
    "    wei_Stats=wei_Stats.append({'Estimators':estimators,'Accuracy':wei_acc,'Precision':wei_scores[0],'Recall':wei_scores[1],'FScore':wei_scores[2]},ignore_index=True)\n",
    "    bld_Stats=bld_Stats.append({'Estimators':estimators,'Accuracy':blood_acc,'Precision':blood_scores[0],'Recall':blood_scores[1],'FScore':blood_scores[2]},ignore_index=True)\n",
    "    ask_Stats=ask_Stats.append({'Estimators':estimators,'Accuracy':ask_acc,'Precision':ask_scores[0],'Recall':ask_scores[1],'FScore':ask_scores[2]},ignore_index=True)\n",
    "x1=res_Stats['FScore'].tolist().index(max(res_Stats['FScore'].tolist()))\n",
    "x2=wei_Stats['FScore'].tolist().index(max(wei_Stats['FScore'].tolist()))\n",
    "x3=bld_Stats['FScore'].tolist().index(max(bld_Stats['FScore'].tolist()))\n",
    "x4=ask_Stats['FScore'].tolist().index(max(ask_Stats['FScore'].tolist()))\n",
    "max_res=res_Stats.iloc[x1].to_frame().transpose()\n",
    "max_wei=wei_Stats.iloc[x2].to_frame().transpose()\n",
    "max_bld=bld_Stats.iloc[x3].to_frame().transpose()\n",
    "max_ask=ask_Stats.iloc[x4].to_frame().transpose()\n",
    "stats=pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "max_res['Estimators']=\"Complete\"\n",
    "max_wei['Estimators']=\"Weighted\"\n",
    "max_bld['Estimators']=\"Pressure\"\n",
    "max_ask['Estimators']=\"Ask\"\n",
    "stats=stats.append(max_res)\n",
    "stats=stats.append(max_wei)\n",
    "stats=stats.append(max_bld)\n",
    "stats=stats.append(max_ask)\n",
    "\n",
    "plotResult(label+\" Random Forest With Feature Filtering\",max_res,max_wei,max_bld,max_ask,x1,x2,x3,x4)\n",
    "\n",
    "import os.path\n",
    "if not os.path.exists('Forrest_StatsImportanceTotal'+'.xlsx'):\n",
    "    writer = pd.ExcelWriter('Forrest_StatsImportanceTotal'+'.xlsx', engine = 'xlsxwriter')\n",
    "\n",
    "    writer.save()\n",
    "    writer.close()\n",
    "writer = pd.ExcelWriter('Forrest_StatsImportanceTotal'+'.xlsx', engine='openpyxl')\n",
    "book = load_workbook('Forrest_StatsImportanceTotal'+'.xlsx')\n",
    "writer.book = book\n",
    "writer.sheets = dict((ws.title, ws) for ws in book.worksheets)\n",
    "\n",
    "stats.to_excel(writer, sheet_name=label)\n",
    "writer.save()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "Counter({0: 834, 1: 723})\n",
      "Counter({1: 80, 0: 50})\n",
      "Counter({1: 274, 0: 188})\n",
      "Counter({0: 608, 1: 148})\n",
      "Res: Accuracy: 0.7008547008547008 # Scores: (0.7007251153592617, 0.7003289473684211, 0.7004115226337448, None)\n",
      "Wei: Accuracy: 0.717948717948718 # Scores: (0.6370967741935484, 0.6103896103896104, 0.6173059768064229, None)\n",
      "Bld: Accuracy: 0.8273381294964028 # Scores: (0.8401511203751955, 0.7885720601237842, 0.8028368794326242, None)\n",
      "Ask: Accuracy: 0.7444933920704846 # Scores: (0.5572548028311426, 0.5644381223328592, 0.5599598930481284, None)\n",
      "200\n",
      "Counter({0: 834, 1: 723})\n",
      "Counter({1: 80, 0: 50})\n",
      "Counter({1: 274, 0: 188})\n",
      "Counter({0: 608, 1: 148})\n",
      "Res: Accuracy: 0.7029914529914529 # Scores: (0.7027983539094651, 0.7026315789473685, 0.7026860269014027, None)\n",
      "Wei: Accuracy: 0.6923076923076923 # Scores: (0.6201298701298701, 0.6201298701298701, 0.6201298701298701, None)\n",
      "Bld: Accuracy: 0.8057553956834532 # Scores: (0.8159777424483307, 0.7635941644562334, 0.7768860353130016, None)\n",
      "Ask: Accuracy: 0.748898678414097 # Scores: (0.5680576254346745, 0.5779516358463728, 0.5717406414457352, None)\n",
      "300\n",
      "Counter({0: 834, 1: 723})\n",
      "Counter({1: 80, 0: 50})\n",
      "Counter({1: 274, 0: 188})\n",
      "Counter({0: 608, 1: 148})\n",
      "Res: Accuracy: 0.7029914529914529 # Scores: (0.7027983539094651, 0.7026315789473685, 0.7026860269014027, None)\n",
      "Wei: Accuracy: 0.6923076923076923 # Scores: (0.6201298701298701, 0.6201298701298701, 0.6201298701298701, None)\n",
      "Bld: Accuracy: 0.8201438848920863 # Scores: (0.834393216746158, 0.7789566755083996, 0.7934129956601866, None)\n",
      "Ask: Accuracy: 0.7577092511013216 # Scores: (0.5752895752895753, 0.5832147937411095, 0.5785654008438819, None)\n",
      "400\n",
      "Counter({0: 834, 1: 723})\n",
      "Counter({1: 80, 0: 50})\n",
      "Counter({1: 274, 0: 188})\n",
      "Counter({0: 608, 1: 148})\n",
      "Res: Accuracy: 0.7008547008547008 # Scores: (0.7006509178673297, 0.7005482456140351, 0.7005867622059334, None)\n",
      "Wei: Accuracy: 0.717948717948718 # Scores: (0.6574074074074074, 0.6655844155844155, 0.6608695652173913, None)\n",
      "Bld: Accuracy: 0.8201438848920863 # Scores: (0.834393216746158, 0.7789566755083996, 0.7934129956601866, None)\n",
      "Ask: Accuracy: 0.7444933920704846 # Scores: (0.5572548028311426, 0.5644381223328592, 0.5599598930481284, None)\n",
      "500\n",
      "Counter({0: 834, 1: 723})\n",
      "Counter({1: 80, 0: 50})\n",
      "Counter({1: 274, 0: 188})\n",
      "Counter({0: 608, 1: 148})\n",
      "Res: Accuracy: 0.7158119658119658 # Scores: (0.7156378600823046, 0.7154605263157894, 0.7155197235819175, None)\n",
      "Wei: Accuracy: 0.717948717948718 # Scores: (0.6574074074074074, 0.6655844155844155, 0.6608695652173913, None)\n",
      "Bld: Accuracy: 0.8201438848920863 # Scores: (0.834393216746158, 0.7789566755083996, 0.7934129956601866, None)\n",
      "Ask: Accuracy: 0.748898678414097 # Scores: (0.5680576254346745, 0.5779516358463728, 0.5717406414457352, None)\n",
      "600\n",
      "Counter({0: 834, 1: 723})\n",
      "Counter({1: 80, 0: 50})\n",
      "Counter({1: 274, 0: 188})\n",
      "Counter({0: 608, 1: 148})\n",
      "Res: Accuracy: 0.7115384615384616 # Scores: (0.711358024691358, 0.7111842105263158, 0.7112418246884127, None)\n",
      "Wei: Accuracy: 0.6923076923076923 # Scores: (0.6201298701298701, 0.6201298701298701, 0.6201298701298701, None)\n",
      "Bld: Accuracy: 0.8201438848920863 # Scores: (0.8418956043956044, 0.7750884173297966, 0.7908768129024493, None)\n",
      "Ask: Accuracy: 0.7533039647577092 # Scores: (0.5785103785103785, 0.5914651493598863, 0.5832677681615526, None)\n",
      "700\n",
      "Counter({0: 834, 1: 723})\n",
      "Counter({1: 80, 0: 50})\n",
      "Counter({1: 274, 0: 188})\n",
      "Counter({0: 608, 1: 148})\n",
      "Res: Accuracy: 0.7115384615384616 # Scores: (0.711344069314713, 0.7112938596491227, 0.7113157113157114, None)\n",
      "Wei: Accuracy: 0.6923076923076923 # Scores: (0.6346153846153846, 0.6477272727272727, 0.6388888888888888, None)\n",
      "Bld: Accuracy: 0.8273381294964028 # Scores: (0.8473570658036678, 0.7847038019451813, 0.8004784688995217, None)\n",
      "Ask: Accuracy: 0.7533039647577092 # Scores: (0.5785103785103785, 0.5914651493598863, 0.5832677681615526, None)\n",
      "800\n",
      "Counter({0: 834, 1: 723})\n",
      "Counter({1: 80, 0: 50})\n",
      "Counter({1: 274, 0: 188})\n",
      "Counter({0: 608, 1: 148})\n",
      "Res: Accuracy: 0.7115384615384616 # Scores: (0.711358024691358, 0.7111842105263158, 0.7112418246884127, None)\n",
      "Wei: Accuracy: 0.6923076923076923 # Scores: (0.6346153846153846, 0.6477272727272727, 0.6388888888888888, None)\n",
      "Bld: Accuracy: 0.8345323741007195 # Scores: (0.8528086910439852, 0.7943191865605659, 0.8099399560073718, None)\n",
      "Ask: Accuracy: 0.7533039647577092 # Scores: (0.5785103785103785, 0.5914651493598863, 0.5832677681615526, None)\n",
      "900\n",
      "Counter({0: 834, 1: 723})\n",
      "Counter({1: 80, 0: 50})\n",
      "Counter({1: 274, 0: 188})\n",
      "Counter({0: 608, 1: 148})\n",
      "Res: Accuracy: 0.7072649572649573 # Scores: (0.7070781893004114, 0.7069078947368421, 0.7069639257949076, None)\n",
      "Wei: Accuracy: 0.6923076923076923 # Scores: (0.6346153846153846, 0.6477272727272727, 0.6388888888888888, None)\n",
      "Bld: Accuracy: 0.8345323741007195 # Scores: (0.8528086910439852, 0.7943191865605659, 0.8099399560073718, None)\n",
      "Ask: Accuracy: 0.7533039647577092 # Scores: (0.5785103785103785, 0.5914651493598863, 0.5832677681615526, None)\n"
     ]
    }
   ],
   "source": [
    "label='Hypertensive disease '\n",
    "asklabel='Hypertensive disease '\n",
    "res_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "wei_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "bld_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "ask_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "for estimators in range (100,1000,100):\n",
    "    print (estimators)\n",
    "    result,result_labels,weighted,weighted_labels,blood,blood_labels,ask,ask_labels=prepareDatasetNoSmote(label,asklabel)\n",
    "    res_acc,res_scores=randomForest(result,result_labels,estimators,\"Result\")\n",
    "    wei_acc,wei_scores=randomForest(weighted,weighted_labels,estimators,\"Weighted\")\n",
    "    blood_acc,blood_scores=randomForest(blood,blood_labels,estimators,\"Blood\")\n",
    "    ask_acc,ask_scores=randomForest(ask,ask_labels,estimators,\"Ask\")\n",
    "    print(\"Res: Accuracy: \" + str(res_acc)+\" # \"+ \"Scores: \"+str(res_scores))\n",
    "    print(\"Wei: Accuracy: \" + str(wei_acc)+\" # \"+ \"Scores: \"+str(wei_scores))\n",
    "    print(\"Bld: Accuracy: \" + str(blood_acc)+\" # \"+ \"Scores: \"+str(blood_scores))\n",
    "    print(\"Ask: Accuracy: \" + str(ask_acc)+\" # \"+ \"Scores: \"+str(ask_scores))\n",
    "    res_Stats=res_Stats.append({'Estimators':estimators,'Accuracy':res_acc,'Precision':res_scores[0],'Recall':res_scores[1],'FScore':res_scores[2]},ignore_index=True)\n",
    "    wei_Stats=wei_Stats.append({'Estimators':estimators,'Accuracy':wei_acc,'Precision':wei_scores[0],'Recall':wei_scores[1],'FScore':wei_scores[2]},ignore_index=True)\n",
    "    bld_Stats=bld_Stats.append({'Estimators':estimators,'Accuracy':blood_acc,'Precision':blood_scores[0],'Recall':blood_scores[1],'FScore':blood_scores[2]},ignore_index=True)\n",
    "    ask_Stats=ask_Stats.append({'Estimators':estimators,'Accuracy':ask_acc,'Precision':ask_scores[0],'Recall':ask_scores[1],'FScore':ask_scores[2]},ignore_index=True)\n",
    "writer = pd.ExcelWriter('Forrest_Stats'+label+'smoteless.xlsx', engine='xlsxwriter')\n",
    "res_Stats.to_excel(writer, sheet_name='Sheet1') \n",
    "wei_Stats.to_excel(writer, sheet_name='Sheet2') \n",
    "bld_Stats.to_excel(writer, sheet_name='Sheet3') \n",
    "ask_Stats.to_excel(writer, sheet_name='Sheet4')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 834, 1: 723})\n",
      "Counter({1: 80, 0: 50})\n",
      "Counter({1: 274, 0: 188})\n",
      "Counter({0: 608, 1: 148})\n",
      "Res: Accuracy: 0.6837606837606838 # Scores: (0.6870343893445707, 0.681688596491228, 0.6806756781677024, None)\n",
      "Wei: Accuracy: 0.7435897435897436 # Scores: (0.6834415584415584, 0.6834415584415584, 0.6834415584415584, None)\n",
      "Bld: Accuracy: 0.7841726618705036 # Scores: (0.7778595974472262, 0.7502210433244916, 0.7589037927844589, None)\n",
      "Ask: Accuracy: 0.7929515418502202 # Scores: (0.6177283304246655, 0.615149359886202, 0.6164024017545752, None)\n",
      "200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 834, 1: 723})\n",
      "Counter({1: 80, 0: 50})\n",
      "Counter({1: 274, 0: 188})\n",
      "Counter({0: 608, 1: 148})\n",
      "Res: Accuracy: 0.6794871794871795 # Scores: (0.6826322522386936, 0.6774122807017544, 0.6763604846294282, None)\n",
      "Wei: Accuracy: 0.7435897435897436 # Scores: (0.7041666666666666, 0.7386363636363636, 0.7115384615384615, None)\n",
      "Bld: Accuracy: 0.7841726618705036 # Scores: (0.7778595974472262, 0.7502210433244916, 0.7589037927844589, None)\n",
      "Ask: Accuracy: 0.7797356828193832 # Scores: (0.6089037503278258, 0.6181365576102418, 0.6129978177850519, None)\n",
      "300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 834, 1: 723})\n",
      "Counter({1: 80, 0: 50})\n",
      "Counter({1: 274, 0: 188})\n",
      "Counter({0: 608, 1: 148})\n",
      "Res: Accuracy: 0.6773504273504274 # Scores: (0.680650023551578, 0.675219298245614, 0.6740631413878191, None)\n",
      "Wei: Accuracy: 0.6666666666666666 # Scores: (0.5972222222222222, 0.6022727272727273, 0.599209486166008, None)\n",
      "Bld: Accuracy: 0.7769784172661871 # Scores: (0.7709059233449478, 0.740605658709107, 0.7495495495495496, None)\n",
      "Ask: Accuracy: 0.7797356828193832 # Scores: (0.6089037503278258, 0.6181365576102418, 0.6129978177850519, None)\n",
      "400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 834, 1: 723})\n",
      "Counter({1: 80, 0: 50})\n",
      "Counter({1: 274, 0: 188})\n",
      "Counter({0: 608, 1: 148})\n",
      "Res: Accuracy: 0.6773504273504274 # Scores: (0.6816009557945042, 0.675, 0.6734727824676676, None)\n",
      "Wei: Accuracy: 0.6923076923076923 # Scores: (0.6346153846153846, 0.6477272727272727, 0.6388888888888888, None)\n",
      "Bld: Accuracy: 0.7697841726618705 # Scores: (0.7638888888888888, 0.7309902740937224, 0.740065451145395, None)\n",
      "Ask: Accuracy: 0.7797356828193832 # Scores: (0.6089037503278258, 0.6181365576102418, 0.6129978177850519, None)\n",
      "500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 834, 1: 723})\n",
      "Counter({1: 80, 0: 50})\n",
      "Counter({1: 274, 0: 188})\n",
      "Counter({0: 608, 1: 148})\n",
      "Res: Accuracy: 0.6773504273504274 # Scores: (0.6816009557945042, 0.675, 0.6734727824676676, None)\n",
      "Wei: Accuracy: 0.6923076923076923 # Scores: (0.6346153846153846, 0.6477272727272727, 0.6388888888888888, None)\n",
      "Bld: Accuracy: 0.7769784172661871 # Scores: (0.7709059233449478, 0.740605658709107, 0.7495495495495496, None)\n",
      "Ask: Accuracy: 0.7797356828193832 # Scores: (0.6089037503278258, 0.6181365576102418, 0.6129978177850519, None)\n",
      "600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 834, 1: 723})\n",
      "Counter({1: 80, 0: 50})\n",
      "Counter({1: 274, 0: 188})\n",
      "Counter({0: 608, 1: 148})\n",
      "Res: Accuracy: 0.6752136752136753 # Scores: (0.6786684782608696, 0.6730263157894737, 0.6717607973421926, None)\n",
      "Wei: Accuracy: 0.717948717948718 # Scores: (0.6574074074074074, 0.6655844155844155, 0.6608695652173913, None)\n",
      "Bld: Accuracy: 0.7769784172661871 # Scores: (0.7746153846153847, 0.736737400530504, 0.7467826291355704, None)\n",
      "Ask: Accuracy: 0.7797356828193832 # Scores: (0.6089037503278258, 0.6181365576102418, 0.6129978177850519, None)\n",
      "700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 834, 1: 723})\n",
      "Counter({1: 80, 0: 50})\n",
      "Counter({1: 274, 0: 188})\n",
      "Counter({0: 608, 1: 148})\n",
      "Res: Accuracy: 0.6773504273504274 # Scores: (0.6816009557945042, 0.675, 0.6734727824676676, None)\n",
      "Wei: Accuracy: 0.7435897435897436 # Scores: (0.6923076923076923, 0.711038961038961, 0.6990740740740741, None)\n",
      "Bld: Accuracy: 0.7841726618705036 # Scores: (0.7858259510161543, 0.7424845269672855, 0.7535460992907801, None)\n",
      "Ask: Accuracy: 0.7797356828193832 # Scores: (0.6089037503278258, 0.6181365576102418, 0.6129978177850519, None)\n",
      "800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 834, 1: 723})\n",
      "Counter({1: 80, 0: 50})\n",
      "Counter({1: 274, 0: 188})\n",
      "Counter({0: 608, 1: 148})\n",
      "Res: Accuracy: 0.6752136752136753 # Scores: (0.6796352583586627, 0.6728070175438596, 0.6711538461538462, None)\n",
      "Wei: Accuracy: 0.6666666666666666 # Scores: (0.5972222222222222, 0.6022727272727273, 0.599209486166008, None)\n",
      "Bld: Accuracy: 0.7841726618705036 # Scores: (0.7858259510161543, 0.7424845269672855, 0.7535460992907801, None)\n",
      "Ask: Accuracy: 0.7797356828193832 # Scores: (0.6089037503278258, 0.6181365576102418, 0.6129978177850519, None)\n",
      "900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 834, 1: 723})\n",
      "Counter({1: 80, 0: 50})\n",
      "Counter({1: 274, 0: 188})\n",
      "Counter({0: 608, 1: 148})\n",
      "Res: Accuracy: 0.6773504273504274 # Scores: (0.6816009557945042, 0.675, 0.6734727824676676, None)\n",
      "Wei: Accuracy: 0.6923076923076923 # Scores: (0.6346153846153846, 0.6477272727272727, 0.6388888888888888, None)\n",
      "Bld: Accuracy: 0.7841726618705036 # Scores: (0.7858259510161543, 0.7424845269672855, 0.7535460992907801, None)\n",
      "Ask: Accuracy: 0.7797356828193832 # Scores: (0.6089037503278258, 0.6181365576102418, 0.6129978177850519, None)\n"
     ]
    }
   ],
   "source": [
    "label='Hypertensive disease '\n",
    "asklabel='Hypertensive disease '\n",
    "res_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "wei_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "bld_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "ask_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "for estimators in range (100,1000,100):\n",
    "    print (estimators)\n",
    "    result,result_labels,weighted,weighted_labels,blood,blood_labels,ask,ask_labels=prepareDatasetNoSmote(label,asklabel)\n",
    "    res_feat=importance(result,result_labels)\n",
    "    wei_feat=importance(weighted,weighted_labels)\n",
    "    blood_feat=importance(blood,blood_labels)\n",
    "    ask_feat=importance(ask,ask_labels)\n",
    "    res_acc,res_scores=randomForest(pd.DataFrame(result)[res_feat],result_labels,estimators,\"Result\")\n",
    "    wei_acc,wei_scores=randomForest(pd.DataFrame(weighted)[wei_feat],weighted_labels,estimators,\"Weighted\")\n",
    "    blood_acc,blood_scores=randomForest(pd.DataFrame(blood)[blood_feat],blood_labels,estimators,\"Blood\")\n",
    "    ask_acc,ask_scores=randomForest(pd.DataFrame(ask)[ask_feat],ask_labels,estimators,\"Ask\")\n",
    "    print(\"Res: Accuracy: \" + str(res_acc)+\" # \"+ \"Scores: \"+str(res_scores))\n",
    "    print(\"Wei: Accuracy: \" + str(wei_acc)+\" # \"+ \"Scores: \"+str(wei_scores))\n",
    "    print(\"Bld: Accuracy: \" + str(blood_acc)+\" # \"+ \"Scores: \"+str(blood_scores))\n",
    "    print(\"Ask: Accuracy: \" + str(ask_acc)+\" # \"+ \"Scores: \"+str(ask_scores))\n",
    "    res_Stats=res_Stats.append({'Estimators':estimators,'Accuracy':res_acc,'Precision':res_scores[0],'Recall':res_scores[1],'FScore':res_scores[2]},ignore_index=True)\n",
    "    wei_Stats=wei_Stats.append({'Estimators':estimators,'Accuracy':wei_acc,'Precision':wei_scores[0],'Recall':wei_scores[1],'FScore':wei_scores[2]},ignore_index=True)\n",
    "    bld_Stats=bld_Stats.append({'Estimators':estimators,'Accuracy':blood_acc,'Precision':blood_scores[0],'Recall':blood_scores[1],'FScore':blood_scores[2]},ignore_index=True)\n",
    "    ask_Stats=ask_Stats.append({'Estimators':estimators,'Accuracy':ask_acc,'Precision':ask_scores[0],'Recall':ask_scores[1],'FScore':ask_scores[2]},ignore_index=True)\n",
    "\n",
    "writer = pd.ExcelWriter('Forrest_Stats'+label+'importancesmoteless.xlsx', engine='xlsxwriter')\n",
    "res_Stats.to_excel(writer, sheet_name='Sheet1') \n",
    "wei_Stats.to_excel(writer, sheet_name='Sheet2') \n",
    "bld_Stats.to_excel(writer, sheet_name='Sheet3') \n",
    "ask_Stats.to_excel(writer, sheet_name='Sheet4')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier Function 10-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average(scores):\n",
    "    FScore=0\n",
    "    Recall=0\n",
    "    Precision=0\n",
    "\n",
    "    for i in scores:\n",
    "        Precision+=i[0]\n",
    "        Recall+=i[1]\n",
    "        FScore+=i[2]\n",
    "    return (Precision/10,Recall/10,FScore/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomForest10Fold(result,result_labels,estimators,DataSet):\n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn.metrics import f1_score\n",
    "    from collections import Counter\n",
    "    kf = KFold(n_splits=10)\n",
    "\n",
    "    accuracy=[]\n",
    "\n",
    "    scores_rf=[]\n",
    "    print(Counter(result_labels))\n",
    "    count = 1\n",
    "    for train_index, test_index in kf.split(result):\n",
    "        X_train, X_test, Y_train, Y_test = result[train_index], result[test_index], result_labels[train_index],result_labels[test_index]\n",
    "        clf = RandomForestClassifier(n_estimators=estimators, max_depth=2,random_state=0)\n",
    "        clf.fit(X_train, Y_train)\n",
    "        pred=clf.predict(X_test)\n",
    "        accuracy.append(accuracy_score(Y_test, pred))\n",
    "        scores_rf.append(precision_recall_fscore_support(Y_test,pred, average='macro'))\n",
    "        \n",
    "        #print(str(count)+DataSet)\n",
    "        #print(f1_score(Y_test, pred, average='micro'))\n",
    "        count+=1\n",
    "        #print (pred)\n",
    "        #print(classification_report(Y_test,pred,labels=[0,1]))\n",
    "    accuracy = np.mean(accuracy,axis=0)   \n",
    "    return accuracy,average(scores_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomForest10FoldNotSmote(result,result_labels,estimators,DataSet):\n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn.metrics import f1_score\n",
    "    from collections import Counter\n",
    "    kf = KFold(n_splits=10)\n",
    "\n",
    "    accuracy=[]\n",
    "\n",
    "    scores_rf=[]\n",
    "    print(Counter(result_labels))\n",
    "    count = 1\n",
    "    for train_index, test_index in kf.split(result):\n",
    "        X_train, X_test, Y_train, Y_test = result.iloc[train_index], result.iloc[test_index], result_labels.iloc[train_index],result_labels.iloc[test_index]\n",
    "        clf = RandomForestClassifier(n_estimators=estimators, max_depth=2,random_state=0)\n",
    "        clf.fit(X_train, Y_train)\n",
    "        pred=clf.predict(X_test)\n",
    "        accuracy.append(accuracy_score(Y_test, pred))\n",
    "        scores_rf.append(precision_recall_fscore_support(Y_test,pred, average='macro'))\n",
    "        \n",
    "        #print(str(count)+DataSet)\n",
    "        #print(f1_score(Y_test, pred, average='micro'))\n",
    "        count+=1\n",
    "        #print (pred)\n",
    "        #print(classification_report(Y_test,pred,labels=[0,1]))\n",
    "    accuracy = np.mean(accuracy,axis=0)   \n",
    "    return accuracy,average(scores_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with 10-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 997, 1: 997})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 93, 1: 93})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 325, 0: 325})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 562, 1: 562})\n",
      "Res: Accuracy: 0.8055201005025123 # Scores: (0.7428154281209286, 0.7443423105940068, 0.7115928683933681)\n",
      "Wei: Accuracy: 0.775438596491228 # Scores: (0.6733820346320345, 0.6771764346764347, 0.6546866670441457)\n",
      "Bld: Accuracy: 0.7892307692307692 # Scores: (0.7012252754673653, 0.7383487606529205, 0.6910037378794464)\n",
      "Ask: Accuracy: 0.9039902022756005 # Scores: (0.8845130565473553, 0.9217322844668475, 0.8819805552784356)\n",
      "Counter({0: 997, 1: 997})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 93, 1: 93})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 325, 0: 325})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 562, 1: 562})\n",
      "Res: Accuracy: 0.7999798994974875 # Scores: (0.7429409044698072, 0.7422556441670094, 0.7102791146027869)\n",
      "Wei: Accuracy: 0.775438596491228 # Scores: (0.6708044733044732, 0.673009768009768, 0.6529434837568449)\n",
      "Bld: Accuracy: 0.8015384615384615 # Scores: (0.719288099248086, 0.7547945098030835, 0.7080904675107481)\n",
      "Ask: Accuracy: 0.9039902022756005 # Scores: (0.8845130565473553, 0.9217322844668475, 0.8819805552784356)\n",
      "Counter({0: 997, 1: 997})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 93, 1: 93})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 325, 0: 325})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 562, 1: 562})\n",
      "Res: Accuracy: 0.8090050251256281 # Scores: (0.7488003037048016, 0.7503452351741823, 0.7187804371092665)\n",
      "Wei: Accuracy: 0.7862573099415203 # Scores: (0.6772709235209236, 0.6841208791208792, 0.6613697214975987)\n",
      "Bld: Accuracy: 0.8076923076923078 # Scores: (0.7189608257596062, 0.755184304937656, 0.7079329969710683)\n",
      "Ask: Accuracy: 0.9039902022756005 # Scores: (0.8845130565473553, 0.9217322844668475, 0.8819805552784356)\n",
      "Counter({0: 997, 1: 997})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 93, 1: 93})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 325, 0: 325})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 562, 1: 562})\n",
      "Res: Accuracy: 0.8165251256281406 # Scores: (0.7529970915285316, 0.7566557666621108, 0.7252567677693073)\n",
      "Wei: Accuracy: 0.7812865497076023 # Scores: (0.6693939393939394, 0.6794810744810745, 0.653285287815339)\n",
      "Bld: Accuracy: 0.8092307692307692 # Scores: (0.7181126370693468, 0.7601278871520376, 0.7055870985558003)\n",
      "Ask: Accuracy: 0.9039902022756005 # Scores: (0.8845130565473553, 0.9217322844668475, 0.8819805552784356)\n",
      "Counter({0: 997, 1: 997})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 93, 1: 93})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 325, 0: 325})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 562, 1: 562})\n",
      "Res: Accuracy: 0.8145150753768844 # Scores: (0.7530652500194186, 0.7555626489261876, 0.7246436826314789)\n",
      "Wei: Accuracy: 0.7812865497076023 # Scores: (0.6693939393939394, 0.6794810744810745, 0.653285287815339)\n",
      "Bld: Accuracy: 0.8046153846153847 # Scores: (0.7191138910574472, 0.757556812508704, 0.7071154315349972)\n",
      "Ask: Accuracy: 0.9039902022756005 # Scores: (0.8845130565473553, 0.9217322844668475, 0.8819805552784356)\n",
      "Counter({0: 997, 1: 997})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 93, 1: 93})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 325, 0: 325})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 562, 1: 562})\n",
      "Res: Accuracy: 0.8130075376884423 # Scores: (0.7508242169119981, 0.7534232053492602, 0.7237976985627668)\n",
      "Wei: Accuracy: 0.7757309941520467 # Scores: (0.6693939393939394, 0.6767032967032968, 0.6515807423607936)\n",
      "Bld: Accuracy: 0.8092307692307694 # Scores: (0.7190153695627406, 0.75747574068592, 0.7088111508009108)\n",
      "Ask: Accuracy: 0.9039902022756005 # Scores: (0.8845130565473553, 0.9217322844668475, 0.8819805552784356)\n",
      "Counter({0: 997, 1: 997})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 93, 1: 93})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 325, 0: 325})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 562, 1: 562})\n",
      "Res: Accuracy: 0.8150150753768844 # Scores: (0.7505385800984646, 0.7542809173286138, 0.7250290136370507)\n",
      "Wei: Accuracy: 0.7809941520467836 # Scores: (0.673320707070707, 0.6805494505494506, 0.6564979266258038)\n",
      "Bld: Accuracy: 0.803076923076923 # Scores: (0.7132391031462303, 0.752498213955328, 0.7030670432609399)\n",
      "Ask: Accuracy: 0.9039902022756005 # Scores: (0.8845130565473553, 0.9217322844668475, 0.8819805552784356)\n",
      "Counter({0: 997, 1: 997})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 93, 1: 93})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 325, 0: 325})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 562, 1: 562})\n",
      "Res: Accuracy: 0.8165201005025124 # Scores: (0.7527065672365418, 0.7560981097715596, 0.7258035358826243)\n",
      "Wei: Accuracy: 0.7865497076023392 # Scores: (0.673320707070707, 0.6833272283272284, 0.6582024720803492)\n",
      "Bld: Accuracy: 0.8061538461538461 # Scores: (0.713631029452056, 0.7539893941699125, 0.7040383797616977)\n",
      "Ask: Accuracy: 0.9039902022756005 # Scores: (0.8845130565473553, 0.9217322844668475, 0.8819805552784356)\n",
      "Counter({0: 997, 1: 997})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 93, 1: 93})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 325, 0: 325})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 562, 1: 562})\n",
      "Res: Accuracy: 0.8170251256281407 # Scores: (0.7516516495523513, 0.7557980253895977, 0.7259090743443609)\n",
      "Wei: Accuracy: 0.7918128654970761 # Scores: (0.6772709235209236, 0.6868986568986569, 0.6630742669521441)\n",
      "Bld: Accuracy: 0.8046153846153846 # Scores: (0.7143991406103474, 0.7536492530448877, 0.7046285689192118)\n",
      "Ask: Accuracy: 0.9039902022756005 # Scores: (0.8845130565473553, 0.9217322844668475, 0.8819805552784356)\n"
     ]
    }
   ],
   "source": [
    "label='ADRCount'\n",
    "asklabel='ADRCount'\n",
    "\n",
    "res_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "wei_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "bld_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "ask_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "for estimators in range (100,1000,100):\n",
    "    result,result_labels,weighted,weighted_labels,blood,blood_labels,ask,ask_labels=prepareDataset(label,asklabel)\n",
    "    res_acc,res_scores=randomForest10Fold(result,result_labels,estimators,\"Result\")\n",
    "    wei_acc,wei_scores=randomForest10Fold(weighted,weighted_labels,estimators,\"Weighted\")\n",
    "    blood_acc,blood_scores=randomForest10Fold(blood,blood_labels,estimators,\"Blood\")\n",
    "    ask_acc,ask_scores=randomForest10Fold(ask,ask_labels,1000,\"Ask\")\n",
    "    print(\"Res: Accuracy: \" + str(res_acc)+\" # \"+ \"Scores: \"+str(res_scores))\n",
    "    print(\"Wei: Accuracy: \" + str(wei_acc)+\" # \"+ \"Scores: \"+str(wei_scores))\n",
    "    print(\"Bld: Accuracy: \" + str(blood_acc)+\" # \"+ \"Scores: \"+str(blood_scores))\n",
    "    print(\"Ask: Accuracy: \" + str(ask_acc)+\" # \"+ \"Scores: \"+str(ask_scores))\n",
    "    res_Stats=res_Stats.append({'Estimators':estimators,'Accuracy':res_acc,'Precision':res_scores[0],'Recall':res_scores[1],'FScore':res_scores[2]},ignore_index=True)\n",
    "    wei_Stats=wei_Stats.append({'Estimators':estimators,'Accuracy':wei_acc,'Precision':wei_scores[0],'Recall':wei_scores[1],'FScore':wei_scores[2]},ignore_index=True)\n",
    "    bld_Stats=bld_Stats.append({'Estimators':estimators,'Accuracy':blood_acc,'Precision':blood_scores[0],'Recall':blood_scores[1],'FScore':blood_scores[2]},ignore_index=True)\n",
    "    ask_Stats=ask_Stats.append({'Estimators':estimators,'Accuracy':ask_acc,'Precision':ask_scores[0],'Recall':ask_scores[1],'FScore':ask_scores[2]},ignore_index=True)\n",
    "res_Stats.to_excel('ForrestFoldresult_Stats'+label+'.xlsx') \n",
    "wei_Stats.to_excel('ForrestFoldweight_Stats'+label+'.xlsx') \n",
    "bld_Stats.to_excel('ForrestFoldblood_Stats'+label+'.xlsx') \n",
    "ask_Stats.to_excel('ForrestFoldask_Stats'+asklabel+'.xlsx') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 997, 0: 560})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 93, 0: 37})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 325, 0: 137})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 562, 0: 194})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Res: Accuracy: 0.6423159636062862 # Scores: (0.3569986842567488, 0.5055481874447392, 0.40097391324841175)\n",
      "Wei: Accuracy: 0.7461538461538462 # Scores: (0.5682692307692307, 0.5425, 0.4926513269339356)\n",
      "Bld: Accuracy: 0.7031914893617021 # Scores: (0.35159574468085114, 0.5, 0.41193330712998666)\n",
      "Ask: Accuracy: 0.7431929824561403 # Scores: (0.37159649122807015, 0.5, 0.4245288434175614)\n",
      "Counter({1: 997, 0: 560})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 93, 0: 37})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 325, 0: 137})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 562, 0: 194})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Res: Accuracy: 0.6416708023159636 # Scores: (0.3543592519193299, 0.5042661361626879, 0.39883028666261955)\n",
      "Wei: Accuracy: 0.7615384615384616 # Scores: (0.6245629370629371, 0.5675, 0.5300755693581781)\n",
      "Bld: Accuracy: 0.7031914893617021 # Scores: (0.35159574468085114, 0.5, 0.41193330712998666)\n",
      "Ask: Accuracy: 0.7431929824561403 # Scores: (0.37159649122807015, 0.5, 0.4245288434175614)\n",
      "Counter({1: 997, 0: 560})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 93, 0: 37})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 325, 0: 137})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 562, 0: 194})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Res: Accuracy: 0.6403804797353184 # Scores: (0.3201902398676592, 0.5, 0.3897269578934828)\n",
      "Wei: Accuracy: 0.7461538461538462 # Scores: (0.5682692307692307, 0.5425, 0.4926513269339356)\n",
      "Bld: Accuracy: 0.7031914893617021 # Scores: (0.35159574468085114, 0.5, 0.41193330712998666)\n",
      "Ask: Accuracy: 0.7431929824561403 # Scores: (0.37159649122807015, 0.5, 0.4245288434175614)\n",
      "Counter({1: 997, 0: 560})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 93, 0: 37})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 325, 0: 137})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 562, 0: 194})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Res: Accuracy: 0.6403804797353184 # Scores: (0.3201902398676592, 0.5, 0.3897269578934828)\n",
      "Wei: Accuracy: 0.7461538461538462 # Scores: (0.5682692307692307, 0.5425, 0.4926513269339356)\n",
      "Bld: Accuracy: 0.7031914893617021 # Scores: (0.35159574468085114, 0.5, 0.41193330712998666)\n",
      "Ask: Accuracy: 0.7431929824561403 # Scores: (0.37159649122807015, 0.5, 0.4245288434175614)\n",
      "Counter({1: 997, 0: 560})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 93, 0: 37})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 325, 0: 137})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 562, 0: 194})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Res: Accuracy: 0.6403804797353184 # Scores: (0.3201902398676592, 0.5, 0.3897269578934828)\n",
      "Wei: Accuracy: 0.7461538461538462 # Scores: (0.5682692307692307, 0.5425, 0.4926513269339356)\n",
      "Bld: Accuracy: 0.7031914893617021 # Scores: (0.35159574468085114, 0.5, 0.41193330712998666)\n",
      "Ask: Accuracy: 0.7431929824561403 # Scores: (0.37159649122807015, 0.5, 0.4245288434175614)\n",
      "Counter({1: 997, 0: 560})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 93, 0: 37})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 325, 0: 137})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 562, 0: 194})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Res: Accuracy: 0.6403804797353184 # Scores: (0.3201902398676592, 0.5, 0.3897269578934828)\n",
      "Wei: Accuracy: 0.7461538461538462 # Scores: (0.5682692307692307, 0.5425, 0.4926513269339356)\n",
      "Bld: Accuracy: 0.7031914893617021 # Scores: (0.35159574468085114, 0.5, 0.41193330712998666)\n",
      "Ask: Accuracy: 0.7431929824561403 # Scores: (0.37159649122807015, 0.5, 0.4245288434175614)\n",
      "Counter({1: 997, 0: 560})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 93, 0: 37})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 325, 0: 137})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 562, 0: 194})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Res: Accuracy: 0.6403804797353184 # Scores: (0.3201902398676592, 0.5, 0.3897269578934828)\n",
      "Wei: Accuracy: 0.7461538461538462 # Scores: (0.5682692307692307, 0.5425, 0.4926513269339356)\n",
      "Bld: Accuracy: 0.7031914893617021 # Scores: (0.35159574468085114, 0.5, 0.41193330712998666)\n",
      "Ask: Accuracy: 0.7431929824561403 # Scores: (0.37159649122807015, 0.5, 0.4245288434175614)\n",
      "Counter({1: 997, 0: 560})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 93, 0: 37})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 325, 0: 137})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 562, 0: 194})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Res: Accuracy: 0.6403804797353184 # Scores: (0.3201902398676592, 0.5, 0.3897269578934828)\n",
      "Wei: Accuracy: 0.7461538461538462 # Scores: (0.5682692307692307, 0.5425, 0.4926513269339356)\n",
      "Bld: Accuracy: 0.7031914893617021 # Scores: (0.35159574468085114, 0.5, 0.41193330712998666)\n",
      "Ask: Accuracy: 0.7431929824561403 # Scores: (0.37159649122807015, 0.5, 0.4245288434175614)\n",
      "Counter({1: 997, 0: 560})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 93, 0: 37})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 325, 0: 137})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 562, 0: 194})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Res: Accuracy: 0.6403804797353184 # Scores: (0.3201902398676592, 0.5, 0.3897269578934828)\n",
      "Wei: Accuracy: 0.7461538461538462 # Scores: (0.5682692307692307, 0.5425, 0.4926513269339356)\n",
      "Bld: Accuracy: 0.7031914893617021 # Scores: (0.35159574468085114, 0.5, 0.41193330712998666)\n",
      "Ask: Accuracy: 0.7431929824561403 # Scores: (0.37159649122807015, 0.5, 0.4245288434175614)\n"
     ]
    }
   ],
   "source": [
    "label='ADRCount'\n",
    "asklabel='ADRCount'\n",
    "\n",
    "res_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "wei_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "bld_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "ask_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "for estimators in range (100,1000,100):\n",
    "    result,result_labels,weighted,weighted_labels,blood,blood_labels,ask,ask_labels=prepareDatasetNoSmote(label,asklabel)\n",
    "    res_acc,res_scores=randomForest10FoldNotSmote(result,result_labels,estimators,\"Result\")\n",
    "    wei_acc,wei_scores=randomForest10FoldNotSmote(weighted,weighted_labels,estimators,\"Weighted\")\n",
    "    blood_acc,blood_scores=randomForest10FoldNotSmote(blood,blood_labels,estimators,\"Blood\")\n",
    "    ask_acc,ask_scores=randomForest10FoldNotSmote(ask,ask_labels,1000,\"Ask\")\n",
    "    print(\"Res: Accuracy: \" + str(res_acc)+\" # \"+ \"Scores: \"+str(res_scores))\n",
    "    print(\"Wei: Accuracy: \" + str(wei_acc)+\" # \"+ \"Scores: \"+str(wei_scores))\n",
    "    print(\"Bld: Accuracy: \" + str(blood_acc)+\" # \"+ \"Scores: \"+str(blood_scores))\n",
    "    print(\"Ask: Accuracy: \" + str(ask_acc)+\" # \"+ \"Scores: \"+str(ask_scores))\n",
    "    res_Stats=res_Stats.append({'Estimators':estimators,'Accuracy':res_acc,'Precision':res_scores[0],'Recall':res_scores[1],'FScore':res_scores[2]},ignore_index=True)\n",
    "    wei_Stats=wei_Stats.append({'Estimators':estimators,'Accuracy':wei_acc,'Precision':wei_scores[0],'Recall':wei_scores[1],'FScore':wei_scores[2]},ignore_index=True)\n",
    "    bld_Stats=bld_Stats.append({'Estimators':estimators,'Accuracy':blood_acc,'Precision':blood_scores[0],'Recall':blood_scores[1],'FScore':blood_scores[2]},ignore_index=True)\n",
    "    ask_Stats=ask_Stats.append({'Estimators':estimators,'Accuracy':ask_acc,'Precision':ask_scores[0],'Recall':ask_scores[1],'FScore':ask_scores[2]},ignore_index=True)\n",
    "res_Stats.to_excel('ForrestFoldresult_Stats'+label+'smoteless.xlsx') \n",
    "wei_Stats.to_excel('ForrestFoldweight_Stats'+label+'smoteless.xlsx') \n",
    "bld_Stats.to_excel('ForrestFoldblood_Stats'+label+'smoteless.xlsx') \n",
    "ask_Stats.to_excel('ForrestFoldask_Stats'+asklabel+'smoteless.xlsx') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ask_scores[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Classifier Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM(result,result_labels,DataSet):\n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn.metrics import f1_score\n",
    "    from collections import Counter\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(result, result_labels, test_size=0.30, random_state=42)\n",
    "    print(Counter(result_labels))\n",
    "    clf = SVC(gamma='auto')\n",
    "    clf.fit(X_train, Y_train)\n",
    "    pred=clf.predict(X_test)\n",
    "    accuracy=(accuracy_score(Y_test, pred))\n",
    "    #print (accuracy)\n",
    "    scores_rf=(precision_recall_fscore_support(Y_test,pred, average='macro'))\n",
    "    #print(DataSet)\n",
    "    #print (pred)\n",
    "    #print(classification_report(Y_test,pred,labels=[0,1,2]))\n",
    "        \n",
    "    return accuracy,scores_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 834, 0: 834})\n",
      "Counter({1: 80, 0: 80})\n",
      "Counter({1: 274, 0: 274})\n",
      "Counter({0: 608, 1: 608})\n",
      "Res: Accuracy: 0.688622754491018 # Scores: (0.688735650510204, 0.6886454183266932, 0.6885917378554124, None)\n",
      "Wei: Accuracy: 0.75 # Scores: (0.7571428571428571, 0.75, 0.7482517482517481, None)\n",
      "Bld: Accuracy: 0.7575757575757576 # Scores: (0.7569852941176471, 0.7575154730327144, 0.7571386517515455, None)\n",
      "Ask: Accuracy: 0.7726027397260274 # Scores: (0.7878745837957825, 0.7829545454545455, 0.7723566850264124, None)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "label='Hypertensive disease '\n",
    "asklabel='Hypertensive disease '\n",
    "Stats = pd.DataFrame(columns = ['Dataset','Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "\n",
    "\n",
    "result,result_labels,weighted,weighted_labels,blood,blood_labels,ask,ask_labels=prepareDataset(label,asklabel)\n",
    "res_acc,res_scores=SVM(result,result_labels,\"Result\")\n",
    "wei_acc,wei_scores=SVM(weighted,weighted_labels,\"Weighted\")\n",
    "blood_acc,blood_scores=SVM(blood,blood_labels,\"Blood\")\n",
    "ask_acc,ask_scores=SVM(ask,ask_labels,\"Ask\")\n",
    "print(\"Res: Accuracy: \" + str(res_acc)+\" # \"+ \"Scores: \"+str(res_scores))\n",
    "print(\"Wei: Accuracy: \" + str(wei_acc)+\" # \"+ \"Scores: \"+str(wei_scores))\n",
    "print(\"Bld: Accuracy: \" + str(blood_acc)+\" # \"+ \"Scores: \"+str(blood_scores))\n",
    "print(\"Ask: Accuracy: \" + str(ask_acc)+\" # \"+ \"Scores: \"+str(ask_scores))\n",
    "Stats=Stats.append({'Dataset':\"Complete\",'Accuracy':res_acc,'Precision':res_scores[0],'Recall':res_scores[1],'FScore':res_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Weighted\",'Accuracy':wei_acc,'Precision':wei_scores[0],'Recall':wei_scores[1],'FScore':wei_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Blood\",'Accuracy':blood_acc,'Precision':blood_scores[0],'Recall':blood_scores[1],'FScore':blood_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"AskAPatient\",'Accuracy':ask_acc,'Precision':ask_scores[0],'Recall':ask_scores[1],'FScore':ask_scores[2]},ignore_index=True)\n",
    "#Stats.to_excel('SVMresult_Stats'+label+'.xlsx') \n",
    "\n",
    "plotResult(label+\" SVM With Smote\",Stats,Stats,Stats,Stats,0,1,2,3)\n",
    "\n",
    "import os.path\n",
    "if not os.path.exists('SVM'+'.xlsx'):\n",
    "    writer = pd.ExcelWriter('SVM'+'.xlsx', engine = 'xlsxwriter')\n",
    "\n",
    "    writer.save()\n",
    "    writer.close()\n",
    "writer = pd.ExcelWriter('SVM'+'.xlsx', engine='openpyxl')\n",
    "book = load_workbook('SVM'+'.xlsx')\n",
    "writer.book = book\n",
    "writer.sheets = dict((ws.title, ws) for ws in book.worksheets)\n",
    "\n",
    "Stats.to_excel(writer, sheet_name=label)\n",
    "writer.save()\n",
    "writer.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 834, 0: 834})\n",
      "Counter({1: 80, 0: 80})\n",
      "Counter({1: 274, 0: 274})\n",
      "Counter({0: 608, 1: 608})\n",
      "Res: Accuracy: 0.688622754491018 # Scores: (0.688735650510204, 0.6886454183266932, 0.6885917378554124, None)\n",
      "Wei: Accuracy: 0.7708333333333334 # Scores: (0.8151515151515152, 0.7708333333333334, 0.7624831309041837, None)\n",
      "Bld: Accuracy: 0.7636363636363637 # Scores: (0.7724089635854342, 0.7579575596816976, 0.7585275244849713, None)\n",
      "Ask: Accuracy: 0.7315068493150685 # Scores: (0.7546895724120508, 0.7443939393939394, 0.7304364864050159, None)\n"
     ]
    }
   ],
   "source": [
    "label='Hypertensive disease '\n",
    "asklabel='Hypertensive disease '\n",
    "Stats = pd.DataFrame(columns = ['Dataset','Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "\n",
    "\n",
    "result,result_labels,weighted,weighted_labels,blood,blood_labels,ask,ask_labels=prepareDataset(label,asklabel)\n",
    "res_feat=importance(result,result_labels)\n",
    "wei_feat=importance(weighted,weighted_labels)\n",
    "blood_feat=importance(blood,blood_labels)\n",
    "ask_feat=importance(ask,ask_labels)\n",
    "res_acc,res_scores=SVM(pd.DataFrame(result)[res_feat],result_labels,\"Result\")\n",
    "wei_acc,wei_scores=SVM(pd.DataFrame(weighted)[wei_feat],weighted_labels,\"Weighted\")\n",
    "blood_acc,blood_scores=SVM(pd.DataFrame(blood)[blood_feat],blood_labels,\"Blood\")\n",
    "ask_acc,ask_scores=SVM(pd.DataFrame(ask)[ask_feat],ask_labels,\"Ask\")\n",
    "print(\"Res: Accuracy: \" + str(res_acc)+\" # \"+ \"Scores: \"+str(res_scores))\n",
    "print(\"Wei: Accuracy: \" + str(wei_acc)+\" # \"+ \"Scores: \"+str(wei_scores))\n",
    "print(\"Bld: Accuracy: \" + str(blood_acc)+\" # \"+ \"Scores: \"+str(blood_scores))\n",
    "print(\"Ask: Accuracy: \" + str(ask_acc)+\" # \"+ \"Scores: \"+str(ask_scores))\n",
    "Stats=Stats.append({'Dataset':\"Complete\",'Accuracy':res_acc,'Precision':res_scores[0],'Recall':res_scores[1],'FScore':res_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Weighted\",'Accuracy':wei_acc,'Precision':wei_scores[0],'Recall':wei_scores[1],'FScore':wei_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Blood\",'Accuracy':blood_acc,'Precision':blood_scores[0],'Recall':blood_scores[1],'FScore':blood_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"AskAPatient\",'Accuracy':ask_acc,'Precision':ask_scores[0],'Recall':ask_scores[1],'FScore':ask_scores[2]},ignore_index=True)\n",
    "Stats.to_excel('SVMresult_Stats'+label+'importance.xlsx') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 834, 1: 723})\n",
      "Counter({1: 80, 0: 50})\n",
      "Counter({1: 274, 0: 188})\n",
      "Counter({0: 608, 1: 148})\n",
      "Res: Accuracy: 0.7008547008547008 # Scores: (0.7057175312381674, 0.6985745614035088, 0.697400750032329, None)\n",
      "Wei: Accuracy: 0.7692307692307693 # Scores: (0.8783783783783784, 0.5909090909090909, 0.5846153846153846, None)\n",
      "Bld: Accuracy: 0.7050359712230215 # Scores: (0.6891483516483516, 0.6521883289124668, 0.6570379731600168, None)\n",
      "Ask: Accuracy: 0.8414096916299559 # Scores: (0.9203539823008849, 0.5135135135135135, 0.48304655870445345, None)\n"
     ]
    }
   ],
   "source": [
    "label='Hypertensive disease '\n",
    "asklabel='Hypertensive disease '\n",
    "Stats = pd.DataFrame(columns = ['Dataset','Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "\n",
    "\n",
    "result,result_labels,weighted,weighted_labels,blood,blood_labels,ask,ask_labels=prepareDatasetNoSmote(label,asklabel)\n",
    "res_acc,res_scores=SVM(result,result_labels,\"Result\")\n",
    "wei_acc,wei_scores=SVM(weighted,weighted_labels,\"Weighted\")\n",
    "blood_acc,blood_scores=SVM(blood,blood_labels,\"Blood\")\n",
    "ask_acc,ask_scores=SVM(ask,ask_labels,\"Ask\")\n",
    "print(\"Res: Accuracy: \" + str(res_acc)+\" # \"+ \"Scores: \"+str(res_scores))\n",
    "print(\"Wei: Accuracy: \" + str(wei_acc)+\" # \"+ \"Scores: \"+str(wei_scores))\n",
    "print(\"Bld: Accuracy: \" + str(blood_acc)+\" # \"+ \"Scores: \"+str(blood_scores))\n",
    "print(\"Ask: Accuracy: \" + str(ask_acc)+\" # \"+ \"Scores: \"+str(ask_scores))\n",
    "Stats=Stats.append({'Dataset':\"Complete\",'Accuracy':res_acc,'Precision':res_scores[0],'Recall':res_scores[1],'FScore':res_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Weighted\",'Accuracy':wei_acc,'Precision':wei_scores[0],'Recall':wei_scores[1],'FScore':wei_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Blood\",'Accuracy':blood_acc,'Precision':blood_scores[0],'Recall':blood_scores[1],'FScore':blood_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"AskAPatient\",'Accuracy':ask_acc,'Precision':ask_scores[0],'Recall':ask_scores[1],'FScore':ask_scores[2]},ignore_index=True)\n",
    "Stats.to_excel('SVMresult_Stats'+label+'smoteless.xlsx') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 834, 1: 723})\n",
      "Counter({1: 80, 0: 50})\n",
      "Counter({1: 274, 0: 188})\n",
      "Counter({0: 608, 1: 148})\n",
      "Res: Accuracy: 0.6538461538461539 # Scores: (0.6583358848744643, 0.6512061403508772, 0.6488179055806715, None)\n",
      "Wei: Accuracy: 0.7692307692307693 # Scores: (0.8783783783783784, 0.5909090909090909, 0.5846153846153846, None)\n",
      "Bld: Accuracy: 0.697841726618705 # Scores: (0.7097902097902098, 0.6193633952254642, 0.6132750397456279, None)\n",
      "Ask: Accuracy: 0.8281938325991189 # Scores: (0.5874811463046757, 0.5165007112375534, 0.49906637243252416, None)\n"
     ]
    }
   ],
   "source": [
    "label='Hypertensive disease '\n",
    "asklabel='Hypertensive disease '\n",
    "Stats = pd.DataFrame(columns = ['Dataset','Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "\n",
    "\n",
    "result,result_labels,weighted,weighted_labels,blood,blood_labels,ask,ask_labels=prepareDatasetNoSmote(label,asklabel)\n",
    "res_feat=importance(result,result_labels)\n",
    "wei_feat=importance(weighted,weighted_labels)\n",
    "blood_feat=importance(blood,blood_labels)\n",
    "ask_feat=importance(ask,ask_labels)\n",
    "res_acc,res_scores=SVM(pd.DataFrame(result)[res_feat],result_labels,\"Result\")\n",
    "wei_acc,wei_scores=SVM(pd.DataFrame(weighted)[wei_feat],weighted_labels,\"Weighted\")\n",
    "blood_acc,blood_scores=SVM(pd.DataFrame(blood)[blood_feat],blood_labels,\"Blood\")\n",
    "ask_acc,ask_scores=SVM(pd.DataFrame(ask)[ask_feat],ask_labels,\"Ask\")\n",
    "print(\"Res: Accuracy: \" + str(res_acc)+\" # \"+ \"Scores: \"+str(res_scores))\n",
    "print(\"Wei: Accuracy: \" + str(wei_acc)+\" # \"+ \"Scores: \"+str(wei_scores))\n",
    "print(\"Bld: Accuracy: \" + str(blood_acc)+\" # \"+ \"Scores: \"+str(blood_scores))\n",
    "print(\"Ask: Accuracy: \" + str(ask_acc)+\" # \"+ \"Scores: \"+str(ask_scores))\n",
    "Stats=Stats.append({'Dataset':\"Complete\",'Accuracy':res_acc,'Precision':res_scores[0],'Recall':res_scores[1],'FScore':res_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Weighted\",'Accuracy':wei_acc,'Precision':wei_scores[0],'Recall':wei_scores[1],'FScore':wei_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Blood\",'Accuracy':blood_acc,'Precision':blood_scores[0],'Recall':blood_scores[1],'FScore':blood_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"AskAPatient\",'Accuracy':ask_acc,'Precision':ask_scores[0],'Recall':ask_scores[1],'FScore':ask_scores[2]},ignore_index=True)\n",
    "Stats.to_excel('SVMresult_Stats'+label+'importancesmoteless.xlsx') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM 10-Fold Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM10Fold(result,result_labels,DataSet):\n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn.metrics import f1_score\n",
    "    from collections import Counter\n",
    "    kf = KFold(n_splits=10)\n",
    "\n",
    "    accuracy=[]\n",
    "\n",
    "    scores_rf=[]\n",
    "    print(Counter(result_labels))\n",
    "    count = 1\n",
    "    for train_index, test_index in kf.split(result):\n",
    "        X_train, X_test, Y_train, Y_test = result[train_index], result[test_index], result_labels[train_index],result_labels[test_index]\n",
    "        clf = SVC(gamma='auto')\n",
    "        clf.fit(X_train, Y_train)\n",
    "        pred=clf.predict(X_test)\n",
    "        accuracy.append(accuracy_score(Y_test, pred))\n",
    "        scores_rf.append(precision_recall_fscore_support(Y_test,pred, average='macro'))\n",
    "        \n",
    "        #print(str(count)+DataSet)\n",
    "        #print(f1_score(Y_test, pred, average='micro'))\n",
    "        count+=1\n",
    "        #print (pred)\n",
    "        #print(classification_report(Y_test,pred,labels=[0,1]))\n",
    "    accuracy = np.mean(accuracy,axis=0)   \n",
    "    return accuracy,average(scores_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM10FoldNoSmote(result,result_labels,DataSet):\n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn.metrics import f1_score\n",
    "    from collections import Counter\n",
    "    kf = KFold(n_splits=10)\n",
    "    accuracy=[]\n",
    "\n",
    "    scores_rf=[]\n",
    "    print(Counter(result_labels))\n",
    "    count = 1\n",
    "    for train_index, test_index in kf.split(result):\n",
    "        X_train, X_test, Y_train, Y_test = result.iloc[train_index], result.iloc[test_index], result_labels.iloc[train_index],result_labels.iloc[test_index]\n",
    "        clf = SVC(gamma='auto')\n",
    "        clf.fit(X_train, Y_train)\n",
    "        pred=clf.predict(X_test)\n",
    "        accuracy.append(accuracy_score(Y_test, pred))\n",
    "        scores_rf.append(precision_recall_fscore_support(Y_test,pred, average='macro'))\n",
    "        \n",
    "        #print(str(count)+DataSet)\n",
    "        #print(f1_score(Y_test, pred, average='micro'))\n",
    "        count+=1\n",
    "        #print (pred)\n",
    "        #print(classification_report(Y_test,pred,labels=[0,1]))\n",
    "    accuracy = np.mean(accuracy,axis=0)   \n",
    "    return accuracy,average(scores_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM 10-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 834, 0: 834})\n",
      "Counter({1: 80, 0: 80})\n",
      "Counter({1: 274, 0: 274})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 608, 1: 608})\n",
      "Res: Accuracy: 0.663101507827718 # Scores: (0.6725628520390469, 0.6761496377396277, 0.6544962946953283)\n",
      "Wei: Accuracy: 0.71875 # Scores: (0.6280934343434343, 0.5980259324009325, 0.5963648583247174)\n",
      "Bld: Accuracy: 0.721010101010101 # Scores: (0.6759517266538593, 0.6614434322260432, 0.6522931172587427)\n",
      "Ask: Accuracy: 0.7445874542744886 # Scores: (0.611755069769185, 0.647484170480776, 0.585458690933904)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "Stats = pd.DataFrame(columns = ['Dataset','Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "\n",
    "label='Hypertensive disease '\n",
    "asklabel='Hypertensive disease '\n",
    "result,result_labels,weighted,weighted_labels,blood,blood_labels,ask,ask_labels=prepareDataset(label,asklabel)\n",
    "res_acc,res_scores=SVM10Fold(result,result_labels,\"Result\")\n",
    "wei_acc,wei_scores=SVM10Fold(weighted,weighted_labels,\"Weighted\")\n",
    "blood_acc,blood_scores=SVM10Fold(blood,blood_labels,\"Blood\")\n",
    "ask_acc,ask_scores=SVM10Fold(ask,ask_labels,\"Ask\")\n",
    "print(\"Res: Accuracy: \" + str(res_acc)+\" # \"+ \"Scores: \"+str(res_scores))\n",
    "print(\"Wei: Accuracy: \" + str(wei_acc)+\" # \"+ \"Scores: \"+str(wei_scores))\n",
    "print(\"Bld: Accuracy: \" + str(blood_acc)+\" # \"+ \"Scores: \"+str(blood_scores))\n",
    "print(\"Ask: Accuracy: \" + str(ask_acc)+\" # \"+ \"Scores: \"+str(ask_scores))\n",
    "Stats=Stats.append({'Dataset':\"Complete\",'Accuracy':res_acc,'Precision':res_scores[0],'Recall':res_scores[1],'FScore':res_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Weighted\",'Accuracy':wei_acc,'Precision':wei_scores[0],'Recall':wei_scores[1],'FScore':wei_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Blood\",'Accuracy':blood_acc,'Precision':blood_scores[0],'Recall':blood_scores[1],'FScore':blood_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"AskAPatient\",'Accuracy':ask_acc,'Precision':ask_scores[0],'Recall':ask_scores[1],'FScore':ask_scores[2]},ignore_index=True)\n",
    "Stats.to_excel('SVMresult_Stats10Fold'+label+'.xlsx') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 834, 1: 723})\n",
      "Counter({1: 80, 0: 50})\n",
      "Counter({1: 274, 0: 188})\n",
      "Counter({0: 608, 1: 148})\n",
      "Res: Accuracy: 0.6455004135649297 # Scores: (0.6500318744362645, 0.6541848478293254, 0.6292282548625472)\n",
      "Wei: Accuracy: 0.6615384615384615 # Scores: (0.7013419913419913, 0.6378571428571428, 0.5933210253798489)\n",
      "Bld: Accuracy: 0.7140610545790935 # Scores: (0.7208260334375953, 0.6703590938075548, 0.66206667853428)\n",
      "Ask: Accuracy: 0.8039298245614035 # Scores: (0.40196491228070175, 0.5, 0.4449683813348536)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "Stats = pd.DataFrame(columns = ['Dataset','Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "\n",
    "label='Hypertensive disease '\n",
    "asklabel='Hypertensive disease '\n",
    "result,result_labels,weighted,weighted_labels,blood,blood_labels,ask,ask_labels=prepareDatasetNoSmote(label,asklabel)\n",
    "res_acc,res_scores=SVM10FoldNoSmote(result,result_labels,\"Result\")\n",
    "wei_acc,wei_scores=SVM10FoldNoSmote(weighted,weighted_labels,\"Weighted\")\n",
    "blood_acc,blood_scores=SVM10FoldNoSmote(blood,blood_labels,\"Blood\")\n",
    "ask_acc,ask_scores=SVM10FoldNoSmote(ask,ask_labels,\"Ask\")\n",
    "print(\"Res: Accuracy: \" + str(res_acc)+\" # \"+ \"Scores: \"+str(res_scores))\n",
    "print(\"Wei: Accuracy: \" + str(wei_acc)+\" # \"+ \"Scores: \"+str(wei_scores))\n",
    "print(\"Bld: Accuracy: \" + str(blood_acc)+\" # \"+ \"Scores: \"+str(blood_scores))\n",
    "print(\"Ask: Accuracy: \" + str(ask_acc)+\" # \"+ \"Scores: \"+str(ask_scores))\n",
    "Stats=Stats.append({'Dataset':\"Complete\",'Accuracy':res_acc,'Precision':res_scores[0],'Recall':res_scores[1],'FScore':res_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Weighted\",'Accuracy':wei_acc,'Precision':wei_scores[0],'Recall':wei_scores[1],'FScore':wei_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Blood\",'Accuracy':blood_acc,'Precision':blood_scores[0],'Recall':blood_scores[1],'FScore':blood_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"AskAPatient\",'Accuracy':ask_acc,'Precision':ask_scores[0],'Recall':ask_scores[1],'FScore':ask_scores[2]},ignore_index=True)\n",
    "Stats.to_excel('SVMresult_Stats10Fold'+label+'smoteless.xlsx') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NB(result,result_labels,DataSet):\n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn.metrics import f1_score\n",
    "    from collections import Counter\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(result, result_labels, test_size=0.30, random_state=42)\n",
    "    print(Counter(result_labels))\n",
    "    clf = GaussianNB()\n",
    "    clf.fit(X_train, Y_train)\n",
    "    pred=clf.predict(X_test)\n",
    "    accuracy=(accuracy_score(Y_test, pred))\n",
    "    #print (accuracy)\n",
    "    scores_rf=(precision_recall_fscore_support(Y_test,pred, average='macro'))\n",
    "    #print(DataSet)\n",
    "    #print (pred)\n",
    "    #print(classification_report(Y_test,pred,labels=[0,1,2]))\n",
    "        \n",
    "    return accuracy,scores_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 834, 0: 834})\n",
      "Counter({1: 80, 0: 80})\n",
      "Counter({1: 274, 0: 274})\n",
      "Counter({0: 608, 1: 608})\n",
      "Res: Accuracy: 0.6287425149700598 # Scores: (0.6315254512928932, 0.6288844621513944, 0.626921721862789, None)\n",
      "Wei: Accuracy: 0.7291666666666666 # Scores: (0.7901098901098902, 0.7291666666666667, 0.7141548327989006, None)\n",
      "Bld: Accuracy: 0.6181818181818182 # Scores: (0.6357142857142857, 0.6259946949602122, 0.6135831381733021, None)\n",
      "Ask: Accuracy: 0.7835616438356164 # Scores: (0.8007984155474408, 0.7945454545454546, 0.7832427515804824, None)\n"
     ]
    }
   ],
   "source": [
    "label='Hypertensive disease '\n",
    "asklabel='Hypertensive disease '\n",
    "Stats = pd.DataFrame(columns = ['Dataset','Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "\n",
    "\n",
    "result,result_labels,weighted,weighted_labels,blood,blood_labels,ask,ask_labels=prepareDataset(label,asklabel)\n",
    "res_acc,res_scores=NB(result,result_labels,\"Result\")\n",
    "wei_acc,wei_scores=NB(weighted,weighted_labels,\"Weighted\")\n",
    "blood_acc,blood_scores=NB(blood,blood_labels,\"Blood\")\n",
    "ask_acc,ask_scores=NB(ask,ask_labels,\"Ask\")\n",
    "print(\"Res: Accuracy: \" + str(res_acc)+\" # \"+ \"Scores: \"+str(res_scores))\n",
    "print(\"Wei: Accuracy: \" + str(wei_acc)+\" # \"+ \"Scores: \"+str(wei_scores))\n",
    "print(\"Bld: Accuracy: \" + str(blood_acc)+\" # \"+ \"Scores: \"+str(blood_scores))\n",
    "print(\"Ask: Accuracy: \" + str(ask_acc)+\" # \"+ \"Scores: \"+str(ask_scores))\n",
    "Stats=Stats.append({'Dataset':\"Complete\",'Accuracy':res_acc,'Precision':res_scores[0],'Recall':res_scores[1],'FScore':res_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Weighted\",'Accuracy':wei_acc,'Precision':wei_scores[0],'Recall':wei_scores[1],'FScore':wei_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Blood\",'Accuracy':blood_acc,'Precision':blood_scores[0],'Recall':blood_scores[1],'FScore':blood_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"AskAPatient\",'Accuracy':ask_acc,'Precision':ask_scores[0],'Recall':ask_scores[1],'FScore':ask_scores[2]},ignore_index=True)\n",
    "Stats.to_excel('NBresult_Stats'+label+'.xlsx') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 834, 0: 834})\n",
      "Counter({1: 80, 0: 80})\n",
      "Counter({1: 274, 0: 274})\n",
      "Counter({0: 608, 1: 608})\n",
      "Res: Accuracy: 0.7005988023952096 # Scores: (0.7024743560886202, 0.7006932270916335, 0.6999664633172571, None)\n",
      "Wei: Accuracy: 0.6041666666666666 # Scores: (0.6043478260869566, 0.6041666666666667, 0.6039947894051236, None)\n",
      "Bld: Accuracy: 0.7090909090909091 # Scores: (0.7106270238445687, 0.7108753315649867, 0.7090802233323539, None)\n",
      "Ask: Accuracy: 0.7342465753424657 # Scores: (0.7854922456787593, 0.7532575757575758, 0.7299575162650924, None)\n"
     ]
    }
   ],
   "source": [
    "label='Hypertensive disease '\n",
    "asklabel='Hypertensive disease '\n",
    "Stats = pd.DataFrame(columns = ['Dataset','Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "\n",
    "result,result_labels,weighted,weighted_labels,blood,blood_labels,ask,ask_labels=prepareDataset(label,asklabel)\n",
    "res_feat=importance(result,result_labels)\n",
    "wei_feat=importance(weighted,weighted_labels)\n",
    "blood_feat=importance(blood,blood_labels)\n",
    "ask_feat=importance(ask,ask_labels)\n",
    "res_acc,res_scores=NB(pd.DataFrame(result)[res_feat],result_labels,\"Result\")\n",
    "wei_acc,wei_scores=NB(pd.DataFrame(weighted)[wei_feat],weighted_labels,\"Weighted\")\n",
    "blood_acc,blood_scores=NB(pd.DataFrame(blood)[blood_feat],blood_labels,\"Blood\")\n",
    "ask_acc,ask_scores=NB(pd.DataFrame(ask)[ask_feat],ask_labels,\"Ask\")\n",
    "print(\"Res: Accuracy: \" + str(res_acc)+\" # \"+ \"Scores: \"+str(res_scores))\n",
    "print(\"Wei: Accuracy: \" + str(wei_acc)+\" # \"+ \"Scores: \"+str(wei_scores))\n",
    "print(\"Bld: Accuracy: \" + str(blood_acc)+\" # \"+ \"Scores: \"+str(blood_scores))\n",
    "print(\"Ask: Accuracy: \" + str(ask_acc)+\" # \"+ \"Scores: \"+str(ask_scores))\n",
    "Stats=Stats.append({'Dataset':\"Complete\",'Accuracy':res_acc,'Precision':res_scores[0],'Recall':res_scores[1],'FScore':res_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Weighted\",'Accuracy':wei_acc,'Precision':wei_scores[0],'Recall':wei_scores[1],'FScore':wei_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Blood\",'Accuracy':blood_acc,'Precision':blood_scores[0],'Recall':blood_scores[1],'FScore':blood_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"AskAPatient\",'Accuracy':ask_acc,'Precision':ask_scores[0],'Recall':ask_scores[1],'FScore':ask_scores[2]},ignore_index=True)\n",
    "Stats.to_excel('NBresult_Stats'+label+'importance.xlsx') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 834, 1: 723})\n",
      "Counter({1: 80, 0: 50})\n",
      "Counter({1: 274, 0: 188})\n",
      "Counter({0: 608, 1: 148})\n",
      "Res: Accuracy: 0.5961538461538461 # Scores: (0.5965403562665068, 0.5941885964912281, 0.5927155519742143, None)\n",
      "Wei: Accuracy: 0.7692307692307693 # Scores: (0.7607142857142857, 0.6185064935064934, 0.6285714285714286, None)\n",
      "Bld: Accuracy: 0.6546762589928058 # Scores: (0.6555900621118013, 0.6661140583554377, 0.6494325346784363, None)\n",
      "Ask: Accuracy: 0.7268722466960352 # Scores: (0.5522242604907132, 0.5647937411095305, 0.5552957532861476, None)\n"
     ]
    }
   ],
   "source": [
    "label='Hypertensive disease '\n",
    "asklabel='Hypertensive disease '\n",
    "Stats = pd.DataFrame(columns = ['Dataset','Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "\n",
    "\n",
    "result,result_labels,weighted,weighted_labels,blood,blood_labels,ask,ask_labels=prepareDatasetNoSmote(label,asklabel)\n",
    "res_acc,res_scores=NB(result,result_labels,\"Result\")\n",
    "wei_acc,wei_scores=NB(weighted,weighted_labels,\"Weighted\")\n",
    "blood_acc,blood_scores=NB(blood,blood_labels,\"Blood\")\n",
    "ask_acc,ask_scores=NB(ask,ask_labels,\"Ask\")\n",
    "print(\"Res: Accuracy: \" + str(res_acc)+\" # \"+ \"Scores: \"+str(res_scores))\n",
    "print(\"Wei: Accuracy: \" + str(wei_acc)+\" # \"+ \"Scores: \"+str(wei_scores))\n",
    "print(\"Bld: Accuracy: \" + str(blood_acc)+\" # \"+ \"Scores: \"+str(blood_scores))\n",
    "print(\"Ask: Accuracy: \" + str(ask_acc)+\" # \"+ \"Scores: \"+str(ask_scores))\n",
    "Stats=Stats.append({'Dataset':\"Complete\",'Accuracy':res_acc,'Precision':res_scores[0],'Recall':res_scores[1],'FScore':res_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Weighted\",'Accuracy':wei_acc,'Precision':wei_scores[0],'Recall':wei_scores[1],'FScore':wei_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Blood\",'Accuracy':blood_acc,'Precision':blood_scores[0],'Recall':blood_scores[1],'FScore':blood_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"AskAPatient\",'Accuracy':ask_acc,'Precision':ask_scores[0],'Recall':ask_scores[1],'FScore':ask_scores[2]},ignore_index=True)\n",
    "Stats.to_excel('NBresult_Stats'+label+'smoteless.xlsx') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 834, 1: 723})\n",
      "Counter({1: 80, 0: 50})\n",
      "Counter({1: 274, 0: 188})\n",
      "Counter({0: 608, 1: 148})\n",
      "Res: Accuracy: 0.6602564102564102 # Scores: (0.6664379192360481, 0.6573464912280702, 0.6543847507930685, None)\n",
      "Wei: Accuracy: 0.6410256410256411 # Scores: (0.5568181818181819, 0.5568181818181819, 0.5568181818181819, None)\n",
      "Bld: Accuracy: 0.7338129496402878 # Scores: (0.7273351648351649, 0.6829133510167993, 0.690497683095625, None)\n",
      "Ask: Accuracy: 0.748898678414097 # Scores: (0.6051587301587301, 0.6432432432432433, 0.6146010186757216, None)\n"
     ]
    }
   ],
   "source": [
    "label='Hypertensive disease '\n",
    "asklabel='Hypertensive disease '\n",
    "Stats = pd.DataFrame(columns = ['Dataset','Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "\n",
    "\n",
    "result,result_labels,weighted,weighted_labels,blood,blood_labels,ask,ask_labels=prepareDatasetNoSmote(label,asklabel)\n",
    "res_feat=importance(result,result_labels)\n",
    "wei_feat=importance(weighted,weighted_labels)\n",
    "blood_feat=importance(blood,blood_labels)\n",
    "ask_feat=importance(ask,ask_labels)\n",
    "res_acc,res_scores=NB(pd.DataFrame(result)[res_feat],result_labels,\"Result\")\n",
    "wei_acc,wei_scores=NB(pd.DataFrame(weighted)[wei_feat],weighted_labels,\"Weighted\")\n",
    "blood_acc,blood_scores=NB(pd.DataFrame(blood)[blood_feat],blood_labels,\"Blood\")\n",
    "ask_acc,ask_scores=NB(pd.DataFrame(ask)[ask_feat],ask_labels,\"Ask\")\n",
    "print(\"Res: Accuracy: \" + str(res_acc)+\" # \"+ \"Scores: \"+str(res_scores))\n",
    "print(\"Wei: Accuracy: \" + str(wei_acc)+\" # \"+ \"Scores: \"+str(wei_scores))\n",
    "print(\"Bld: Accuracy: \" + str(blood_acc)+\" # \"+ \"Scores: \"+str(blood_scores))\n",
    "print(\"Ask: Accuracy: \" + str(ask_acc)+\" # \"+ \"Scores: \"+str(ask_scores))\n",
    "Stats=Stats.append({'Dataset':\"Complete\",'Accuracy':res_acc,'Precision':res_scores[0],'Recall':res_scores[1],'FScore':res_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Weighted\",'Accuracy':wei_acc,'Precision':wei_scores[0],'Recall':wei_scores[1],'FScore':wei_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Blood\",'Accuracy':blood_acc,'Precision':blood_scores[0],'Recall':blood_scores[1],'FScore':blood_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"AskAPatient\",'Accuracy':ask_acc,'Precision':ask_scores[0],'Recall':ask_scores[1],'FScore':ask_scores[2]},ignore_index=True)\n",
    "Stats.to_excel('NBresult_Stats'+label+'importancesmoteless.xlsx') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes 10-Fold Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NB10Fold(result,result_labels,DataSet):\n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn.metrics import f1_score\n",
    "    from collections import Counter\n",
    "    kf = KFold(n_splits=10)\n",
    "\n",
    "    accuracy=[]\n",
    "\n",
    "    scores_rf=[]\n",
    "    print(Counter(result_labels))\n",
    "    count = 1\n",
    "    for train_index, test_index in kf.split(result):\n",
    "        X_train, X_test, Y_train, Y_test = result[train_index], result[test_index], result_labels[train_index],result_labels[test_index]\n",
    "        clf = GaussianNB()\n",
    "        clf.fit(X_train, Y_train)\n",
    "        pred=clf.predict(X_test)\n",
    "        accuracy.append(accuracy_score(Y_test, pred))\n",
    "        scores_rf.append(precision_recall_fscore_support(Y_test,pred, average='macro'))\n",
    "        \n",
    "        #print(str(count)+DataSet)\n",
    "        #print(f1_score(Y_test, pred, average='micro'))\n",
    "        count+=1\n",
    "        #print (pred)\n",
    "        #print(classification_report(Y_test,pred,labels=[0,1]))\n",
    "    accuracy = np.mean(accuracy,axis=0)   \n",
    "    return accuracy,average(scores_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NB10FoldNoSmote(result,result_labels,DataSet):\n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn.metrics import f1_score\n",
    "    from collections import Counter\n",
    "    kf = KFold(n_splits=10)\n",
    "\n",
    "    accuracy=[]\n",
    "\n",
    "    scores_rf=[]\n",
    "    print(Counter(result_labels))\n",
    "    count = 1\n",
    "    for train_index, test_index in kf.split(result):\n",
    "        X_train, X_test, Y_train, Y_test = result.iloc[train_index], result.iloc[test_index], result_labels.iloc[train_index],result_labels.iloc[test_index]\n",
    "        clf = GaussianNB()\n",
    "        clf.fit(X_train, Y_train)\n",
    "        pred=clf.predict(X_test)\n",
    "        accuracy.append(accuracy_score(Y_test, pred))\n",
    "        scores_rf.append(precision_recall_fscore_support(Y_test,pred, average='macro'))\n",
    "        \n",
    "        #print(str(count)+DataSet)\n",
    "        #print(f1_score(Y_test, pred, average='micro'))\n",
    "        count+=1\n",
    "        #print (pred)\n",
    "        #print(classification_report(Y_test,pred,labels=[0,1]))\n",
    "    accuracy = np.mean(accuracy,axis=0)   \n",
    "    return accuracy,average(scores_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes 10-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 834, 0: 834})\n",
      "Counter({1: 80, 0: 80})\n",
      "Counter({1: 274, 0: 274})\n",
      "Counter({0: 608, 1: 608})\n",
      "Res: Accuracy: 0.6234579034701682 # Scores: (0.6318923229476339, 0.6370319013726595, 0.616576877324976)\n",
      "Wei: Accuracy: 0.64375 # Scores: (0.6608391608391608, 0.6215792540792541, 0.6038139775601076)\n",
      "Bld: Accuracy: 0.6396296296296295 # Scores: (0.6491948105664025, 0.6535476874467434, 0.6193045413380015)\n",
      "Ask: Accuracy: 0.7949193876168541 # Scores: (0.631730492224762, 0.6596810810067578, 0.6086214410048887)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "Stats = pd.DataFrame(columns = ['Dataset','Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "\n",
    "label='Hypertensive disease '\n",
    "asklabel='Hypertensive disease '\n",
    "result,result_labels,weighted,weighted_labels,blood,blood_labels,ask,ask_labels=prepareDataset(label,asklabel)\n",
    "res_acc,res_scores=NB10Fold(result,result_labels,\"Result\")\n",
    "wei_acc,wei_scores=NB10Fold(weighted,weighted_labels,\"Weighted\")\n",
    "blood_acc,blood_scores=NB10Fold(blood,blood_labels,\"Blood\")\n",
    "ask_acc,ask_scores=NB10Fold(ask,ask_labels,\"Ask\")\n",
    "print(\"Res: Accuracy: \" + str(res_acc)+\" # \"+ \"Scores: \"+str(res_scores))\n",
    "print(\"Wei: Accuracy: \" + str(wei_acc)+\" # \"+ \"Scores: \"+str(wei_scores))\n",
    "print(\"Bld: Accuracy: \" + str(blood_acc)+\" # \"+ \"Scores: \"+str(blood_scores))\n",
    "print(\"Ask: Accuracy: \" + str(ask_acc)+\" # \"+ \"Scores: \"+str(ask_scores))\n",
    "Stats=Stats.append({'Dataset':\"Complete\",'Accuracy':res_acc,'Precision':res_scores[0],'Recall':res_scores[1],'FScore':res_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Weighted\",'Accuracy':wei_acc,'Precision':wei_scores[0],'Recall':wei_scores[1],'FScore':wei_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Blood\",'Accuracy':blood_acc,'Precision':blood_scores[0],'Recall':blood_scores[1],'FScore':blood_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"AskAPatient\",'Accuracy':ask_acc,'Precision':ask_scores[0],'Recall':ask_scores[1],'FScore':ask_scores[2]},ignore_index=True)\n",
    "Stats.to_excel('NBresult_Stats10Fold'+label+'.xlsx') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 834, 1: 723})\n",
      "Counter({1: 80, 0: 50})\n",
      "Counter({1: 274, 0: 188})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 608, 1: 148})\n",
      "Res: Accuracy: 0.6255831265508685 # Scores: (0.6182491779207331, 0.6213850965425614, 0.6065100342360275)\n",
      "Wei: Accuracy: 0.6615384615384615 # Scores: (0.6634271284271284, 0.637815934065934, 0.6191472090001502)\n",
      "Bld: Accuracy: 0.5820536540240517 # Scores: (0.6295602920081275, 0.6227280945618786, 0.5750316306946438)\n",
      "Ask: Accuracy: 0.7247719298245615 # Scores: (0.5558101469813034, 0.5342128228029481, 0.5139073914356317)\n"
     ]
    }
   ],
   "source": [
    "Stats = pd.DataFrame(columns = ['Dataset','Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "\n",
    "label='Hypertensive disease '\n",
    "asklabel='Hypertensive disease '\n",
    "result,result_labels,weighted,weighted_labels,blood,blood_labels,ask,ask_labels=prepareDatasetNoSmote(label,asklabel)\n",
    "res_acc,res_scores=NB10FoldNoSmote(result,result_labels,\"Result\")\n",
    "wei_acc,wei_scores=NB10FoldNoSmote(weighted,weighted_labels,\"Weighted\")\n",
    "blood_acc,blood_scores=NB10FoldNoSmote(blood,blood_labels,\"Blood\")\n",
    "ask_acc,ask_scores=NB10FoldNoSmote(ask,ask_labels,\"Ask\")\n",
    "print(\"Res: Accuracy: \" + str(res_acc)+\" # \"+ \"Scores: \"+str(res_scores))\n",
    "print(\"Wei: Accuracy: \" + str(wei_acc)+\" # \"+ \"Scores: \"+str(wei_scores))\n",
    "print(\"Bld: Accuracy: \" + str(blood_acc)+\" # \"+ \"Scores: \"+str(blood_scores))\n",
    "print(\"Ask: Accuracy: \" + str(ask_acc)+\" # \"+ \"Scores: \"+str(ask_scores))\n",
    "Stats=Stats.append({'Dataset':\"Complete\",'Accuracy':res_acc,'Precision':res_scores[0],'Recall':res_scores[1],'FScore':res_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Weighted\",'Accuracy':wei_acc,'Precision':wei_scores[0],'Recall':wei_scores[1],'FScore':wei_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Blood\",'Accuracy':blood_acc,'Precision':blood_scores[0],'Recall':blood_scores[1],'FScore':blood_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"AskAPatient\",'Accuracy':ask_acc,'Precision':ask_scores[0],'Recall':ask_scores[1],'FScore':ask_scores[2]},ignore_index=True)\n",
    "Stats.to_excel('NBresult_Stats10Fold'+label+'smoteless.xlsx') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from collections import Counter\\nfrom imblearn.over_sampling import SMOTENC\\nsm = SMOTENC(random_state=42, categorical_features=[0, 1,3])\\nX_res, y_res = sm.fit_resample(result, result_labels)\\nprint(Counter(result_labels))\\nprint(Counter(y_res))\\nprint(X_res)\\nprint(y_res)\\nprint(result_labels)'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from collections import Counter\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "sm = SMOTENC(random_state=42, categorical_features=[0, 1,3])\n",
    "X_res, y_res = sm.fit_resample(result, result_labels)\n",
    "print(Counter(result_labels))\n",
    "print(Counter(y_res))\n",
    "print(X_res)\n",
    "print(y_res)\n",
    "print(result_labels)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    834\n",
      "1    723\n",
      "Name: Hypertensive disease , dtype: int64\n",
      "1    80\n",
      "0    50\n",
      "Name: Hypertensive disease , dtype: int64\n",
      "1    274\n",
      "0    188\n",
      "Name: Hypertensive disease , dtype: int64\n",
      "0    608\n",
      "1    148\n",
      "Name: Hypertensive disease , dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(result_labels.value_counts())\n",
    "print(weighted_labels.value_counts())\n",
    "print(blood_labels.value_counts())\n",
    "print(ask_labels.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    834\n",
      "1    723\n",
      "Name: Hypertensive disease , dtype: int64\n",
      "1    80\n",
      "0    50\n",
      "Name: Hypertensive disease , dtype: int64\n",
      "1    274\n",
      "0    188\n",
      "Name: Hypertensive disease , dtype: int64\n",
      "0    608\n",
      "1    148\n",
      "Name: Hypertensive disease , dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(result_labels.value_counts())\n",
    "print(weighted_labels.value_counts())\n",
    "print(blood_labels.value_counts())\n",
    "print(ask_labels.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6182491779207331"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_scores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>DrugFamily</th>\n",
       "      <th>Drug</th>\n",
       "      <th>ADRCount</th>\n",
       "      <th>MentalCount</th>\n",
       "      <th>DieaseCount</th>\n",
       "      <th>Pain</th>\n",
       "      <th>Fatigue</th>\n",
       "      <th>Vertigo</th>\n",
       "      <th>...</th>\n",
       "      <th>Headache</th>\n",
       "      <th>Anxiety</th>\n",
       "      <th>Mental Suffering</th>\n",
       "      <th>Pvc</th>\n",
       "      <th>MUNGAN SYNDROME</th>\n",
       "      <th>MICROCEPHALY , EPILEPSY , AND DIABETES SYNDROME</th>\n",
       "      <th>Brachial Amyotrophic Diplegia</th>\n",
       "      <th>Infection</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>Sinusitis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>42.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>32.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>42.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>42.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>46.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>53.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>42.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>53.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>53.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>68.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>42.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>71.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527</th>\n",
       "      <td>42.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1528</th>\n",
       "      <td>47.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1529</th>\n",
       "      <td>49.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1530</th>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1531</th>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1532</th>\n",
       "      <td>59.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1533</th>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1534</th>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535</th>\n",
       "      <td>58.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1536</th>\n",
       "      <td>54.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1537</th>\n",
       "      <td>59.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1538</th>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1539</th>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1540</th>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1541</th>\n",
       "      <td>66.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542</th>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1543</th>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1544</th>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1545</th>\n",
       "      <td>42.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1546</th>\n",
       "      <td>42.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1547</th>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1548</th>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1549</th>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1550</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551</th>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1552</th>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1553</th>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1554</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1555</th>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1556</th>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1557 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age Gender  DrugFamily  Drug  ADRCount  MentalCount  DieaseCount  Pain  \\\n",
       "0     42.0      0           2     0         0            0            1     0   \n",
       "1     40.0      1           2     0         1            1            2     0   \n",
       "2     42.0      0           2     0         0            0            1     0   \n",
       "3     26.0      0           2     0         0            0            1     0   \n",
       "4     70.0      0           2     0         0            0            0     0   \n",
       "5     63.0      1           2     0         1            0            1     0   \n",
       "6     45.0      0           2     0         0            1            2     0   \n",
       "7     42.0      1           2     0         1            0            2     1   \n",
       "8     32.0      1           2     0         1            0            2     1   \n",
       "9     21.0      0           2     0         0            1            2     0   \n",
       "10    42.0      1           2     0         1            0            2     1   \n",
       "11    42.0      0           2     0         0            0            1     0   \n",
       "12    31.0      0           2     0         1            0            1     1   \n",
       "13    25.0      0           2     0         0            1            1     0   \n",
       "14    42.0      1           2     0         1            0            2     1   \n",
       "15    40.0      0           2     0         1            1            1     0   \n",
       "16    46.0      1           2     0         0            0            1     0   \n",
       "17    26.0      1           2     0         0            0            2     0   \n",
       "18    53.0      1           2     0         0            0            1     0   \n",
       "19    42.0      1           2     0         0            0            1     0   \n",
       "20    63.0      1           2     0         1            1            1     1   \n",
       "21    53.0      1           2     0         1            0            1     0   \n",
       "22    53.0      1           2     0         1            0            1     0   \n",
       "23    70.0      0           2     0         0            0            0     0   \n",
       "24    42.0      0           2     0         1            0            1     0   \n",
       "25    42.0      0           2     0         0            0            1     0   \n",
       "26    68.0      0           2     0         0            0            0     0   \n",
       "27    42.0      1           2     0         0            0            2     0   \n",
       "28    47.0      1           2     0         1            0            0     0   \n",
       "29    71.0      0           2     0         1            0            1     0   \n",
       "...    ...    ...         ...   ...       ...          ...          ...   ...   \n",
       "1527  42.0      1           1     5         0            0            1     0   \n",
       "1528  47.0      0           1     5         0            1            1     0   \n",
       "1529  49.0      1           1     5         1            0            2     0   \n",
       "1530  29.0      1           1     5         1            1            2     0   \n",
       "1531  29.0      0           1     5         0            1            1     0   \n",
       "1532  59.0      1           1     5         1            1            1     0   \n",
       "1533  61.0      0           1     5         1            0            2     1   \n",
       "1534  42.0      0           1     5         0            1            1     0   \n",
       "1535  58.0      1           1     5         0            0            0     0   \n",
       "1536  54.0      1           1     5         1            0            1     0   \n",
       "1537  59.0      0           1     5         1            1            1     1   \n",
       "1538  42.0      0           1     5         1            0            2     1   \n",
       "1539  42.0      0           1     5         1            1            2     0   \n",
       "1540  42.0      0           1     5         1            0            1     0   \n",
       "1541  66.0      1           1     5         1            0            1     0   \n",
       "1542  42.0      0           1     5         1            0            1     1   \n",
       "1543  42.0      0           1     5         0            1            1     0   \n",
       "1544  23.0      0           1     5         1            0            2     0   \n",
       "1545  42.0      1           1     5         0            1            1     0   \n",
       "1546  42.0      1           1     5         0            0            0     0   \n",
       "1547  25.0      1           1     5         0            1            1     0   \n",
       "1548  28.0      0           1     5         1            2            2     1   \n",
       "1549  28.0      0           1     5         1            0            2     0   \n",
       "1550  15.0      0           1     5         0            0            0     0   \n",
       "1551  42.0      0           1     5         0            1            1     0   \n",
       "1552  27.0      0           1     5         1            1            1     1   \n",
       "1553  38.0      1           1     5         1            0            0     1   \n",
       "1554  50.0      0           1     5         1            0            0     0   \n",
       "1555  42.0      0           1     5         1            1            1     0   \n",
       "1556  42.0      0           1     5         1            1            1     0   \n",
       "\n",
       "      Fatigue  Vertigo  ...  Headache  Anxiety  Mental Suffering  Pvc  \\\n",
       "0           0        0  ...         0        0                 0    0   \n",
       "1           0        0  ...         0        0                 0    0   \n",
       "2           0        0  ...         0        0                 0    0   \n",
       "3           0        0  ...         0        0                 0    0   \n",
       "4           0        0  ...         0        0                 0    0   \n",
       "5           0        0  ...         0        0                 0    0   \n",
       "6           0        0  ...         0        0                 1    0   \n",
       "7           1        0  ...         0        0                 0    0   \n",
       "8           0        0  ...         0        0                 0    0   \n",
       "9           0        0  ...         0        0                 0    0   \n",
       "10          0        0  ...         1        0                 0    1   \n",
       "11          0        0  ...         0        0                 0    0   \n",
       "12          0        0  ...         0        0                 0    0   \n",
       "13          0        0  ...         0        0                 1    0   \n",
       "14          0        0  ...         1        0                 0    0   \n",
       "15          1        0  ...         0        0                 1    0   \n",
       "16          0        0  ...         0        0                 0    0   \n",
       "17          0        0  ...         0        0                 0    0   \n",
       "18          0        0  ...         0        0                 0    0   \n",
       "19          0        0  ...         0        0                 0    0   \n",
       "20          0        0  ...         0        0                 1    0   \n",
       "21          0        0  ...         0        0                 0    0   \n",
       "22          0        0  ...         0        0                 0    0   \n",
       "23          0        0  ...         0        0                 0    0   \n",
       "24          0        0  ...         0        0                 0    0   \n",
       "25          0        0  ...         0        0                 0    0   \n",
       "26          0        0  ...         0        0                 0    0   \n",
       "27          0        0  ...         0        0                 0    0   \n",
       "28          0        0  ...         0        0                 0    0   \n",
       "29          0        0  ...         0        0                 0    0   \n",
       "...       ...      ...  ...       ...      ...               ...  ...   \n",
       "1527        0        0  ...         0        0                 0    0   \n",
       "1528        0        0  ...         0        0                 0    0   \n",
       "1529        0        0  ...         0        0                 0    1   \n",
       "1530        1        0  ...         0        0                 0    0   \n",
       "1531        0        0  ...         0        1                 0    0   \n",
       "1532        0        0  ...         0        0                 0    0   \n",
       "1533        0        0  ...         0        0                 0    0   \n",
       "1534        0        0  ...         0        1                 0    0   \n",
       "1535        0        0  ...         0        0                 0    0   \n",
       "1536        0        0  ...         0        0                 0    0   \n",
       "1537        1        0  ...         0        0                 1    0   \n",
       "1538        0        0  ...         1        0                 0    0   \n",
       "1539        1        0  ...         0        0                 1    1   \n",
       "1540        1        0  ...         0        0                 0    0   \n",
       "1541        0        0  ...         0        0                 0    0   \n",
       "1542        0        0  ...         0        0                 0    0   \n",
       "1543        0        0  ...         0        0                 0    0   \n",
       "1544        0        0  ...         0        0                 0    0   \n",
       "1545        0        0  ...         0        0                 1    0   \n",
       "1546        0        0  ...         0        0                 0    0   \n",
       "1547        0        0  ...         0        0                 1    0   \n",
       "1548        0        0  ...         0        1                 0    0   \n",
       "1549        1        0  ...         0        0                 0    1   \n",
       "1550        0        0  ...         0        0                 0    0   \n",
       "1551        0        0  ...         0        0                 1    0   \n",
       "1552        0        0  ...         0        1                 0    0   \n",
       "1553        0        0  ...         0        0                 0    0   \n",
       "1554        1        0  ...         0        0                 0    0   \n",
       "1555        0        0  ...         0        0                 0    1   \n",
       "1556        0        0  ...         0        1                 0    0   \n",
       "\n",
       "      MUNGAN SYNDROME   MICROCEPHALY , EPILEPSY , AND DIABETES SYNDROME   \\\n",
       "0                    1                                                 0   \n",
       "1                    1                                                 0   \n",
       "2                    0                                                 0   \n",
       "3                    0                                                 0   \n",
       "4                    0                                                 0   \n",
       "5                    1                                                 0   \n",
       "6                    1                                                 0   \n",
       "7                    0                                                 0   \n",
       "8                    0                                                 0   \n",
       "9                    0                                                 0   \n",
       "10                   0                                                 0   \n",
       "11                   0                                                 0   \n",
       "12                   0                                                 0   \n",
       "13                   0                                                 0   \n",
       "14                   0                                                 0   \n",
       "15                   0                                                 0   \n",
       "16                   0                                                 0   \n",
       "17                   0                                                 0   \n",
       "18                   0                                                 0   \n",
       "19                   0                                                 0   \n",
       "20                   0                                                 0   \n",
       "21                   0                                                 0   \n",
       "22                   0                                                 0   \n",
       "23                   0                                                 0   \n",
       "24                   0                                                 0   \n",
       "25                   0                                                 1   \n",
       "26                   0                                                 0   \n",
       "27                   0                                                 0   \n",
       "28                   0                                                 0   \n",
       "29                   1                                                 0   \n",
       "...                ...                                               ...   \n",
       "1527                 0                                                 0   \n",
       "1528                 0                                                 0   \n",
       "1529                 1                                                 0   \n",
       "1530                 0                                                 0   \n",
       "1531                 1                                                 0   \n",
       "1532                 0                                                 1   \n",
       "1533                 0                                                 1   \n",
       "1534                 0                                                 0   \n",
       "1535                 0                                                 0   \n",
       "1536                 0                                                 0   \n",
       "1537                 0                                                 0   \n",
       "1538                 0                                                 0   \n",
       "1539                 1                                                 0   \n",
       "1540                 0                                                 0   \n",
       "1541                 0                                                 0   \n",
       "1542                 0                                                 0   \n",
       "1543                 0                                                 0   \n",
       "1544                 0                                                 0   \n",
       "1545                 0                                                 0   \n",
       "1546                 0                                                 0   \n",
       "1547                 0                                                 0   \n",
       "1548                 0                                                 1   \n",
       "1549                 0                                                 0   \n",
       "1550                 0                                                 0   \n",
       "1551                 0                                                 0   \n",
       "1552                 0                                                 0   \n",
       "1553                 0                                                 0   \n",
       "1554                 0                                                 0   \n",
       "1555                 0                                                 0   \n",
       "1556                 0                                                 0   \n",
       "\n",
       "      Brachial Amyotrophic Diplegia   Infection  Diabetes  Sinusitis   \n",
       "0                                  0          0         0           0  \n",
       "1                                  0          0         1           0  \n",
       "2                                  0          0         0           0  \n",
       "3                                  0          0         0           0  \n",
       "4                                  0          0         0           0  \n",
       "5                                  0          0         0           0  \n",
       "6                                  0          0         0           0  \n",
       "7                                  0          0         0           1  \n",
       "8                                  0          0         0           0  \n",
       "9                                  0          0         0           0  \n",
       "10                                 0          0         0           0  \n",
       "11                                 0          0         0           0  \n",
       "12                                 0          0         0           0  \n",
       "13                                 0          0         0           0  \n",
       "14                                 0          0         1           0  \n",
       "15                                 0          0         0           0  \n",
       "16                                 0          0         0           0  \n",
       "17                                 0          0         0           0  \n",
       "18                                 0          0         0           0  \n",
       "19                                 0          0         0           0  \n",
       "20                                 0          0         0           0  \n",
       "21                                 0          0         0           0  \n",
       "22                                 0          0         0           0  \n",
       "23                                 0          0         0           0  \n",
       "24                                 0          0         0           0  \n",
       "25                                 0          0         0           0  \n",
       "26                                 0          0         0           0  \n",
       "27                                 0          0         1           0  \n",
       "28                                 0          0         0           0  \n",
       "29                                 0          0         0           0  \n",
       "...                              ...        ...       ...         ...  \n",
       "1527                               0          0         0           0  \n",
       "1528                               0          0         0           0  \n",
       "1529                               0          0         0           0  \n",
       "1530                               1          1         0           0  \n",
       "1531                               0          0         0           0  \n",
       "1532                               0          0         0           0  \n",
       "1533                               1          0         0           0  \n",
       "1534                               0          0         0           0  \n",
       "1535                               0          0         0           0  \n",
       "1536                               0          0         0           0  \n",
       "1537                               1          0         0           0  \n",
       "1538                               0          0         0           1  \n",
       "1539                               0          0         0           0  \n",
       "1540                               0          0         0           0  \n",
       "1541                               0          0         0           0  \n",
       "1542                               1          0         0           0  \n",
       "1543                               0          0         0           0  \n",
       "1544                               0          0         0           0  \n",
       "1545                               0          0         0           0  \n",
       "1546                               0          0         0           0  \n",
       "1547                               0          0         0           0  \n",
       "1548                               0          0         0           0  \n",
       "1549                               0          0         0           0  \n",
       "1550                               0          0         0           0  \n",
       "1551                               0          0         1           0  \n",
       "1552                               0          0         0           0  \n",
       "1553                               0          0         0           0  \n",
       "1554                               0          0         0           0  \n",
       "1555                               0          0         0           0  \n",
       "1556                               0          0         0           0  \n",
       "\n",
       "[1557 rows x 21 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6615384615384615"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7247719298245615"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6182491779207331, 0.6213850965425614, 0.6065100342360275)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6634271284271284, 0.637815934065934, 0.6191472090001502)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5558101469813034, 0.5342128228029481, 0.5139073914356317)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 287,
   "position": {
    "height": "309px",
    "left": "1104px",
    "right": "20px",
    "top": "102px",
    "width": "649px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
