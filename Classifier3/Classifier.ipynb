{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports necessary for running the program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'df = pd.read_excel(\"MLDataSet.xlsx\")\\ndf2 = pd.read_excel(\"ADRs.xlsx\")\\ndf3 = pd.read_excel(\"DS.xlsx\")\\ndf4 = pd.read_excel(\"Mental.xlsx\")\\n\\ndf5=[df, df2,  df3, df4]\\n\\nresult = pd.concat([df,df2,df3, df4], axis=1, join_axes=[df.index])'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sun May  5 23:01:42 2019\n",
    "\n",
    "@author: Ahmed\n",
    "\"\"\"\n",
    "\n",
    "from openpyxl import load_workbook\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "'''df = pd.read_excel(\"MLDataSet.xlsx\")\n",
    "df2 = pd.read_excel(\"ADRs.xlsx\")\n",
    "df3 = pd.read_excel(\"DS.xlsx\")\n",
    "df4 = pd.read_excel(\"Mental.xlsx\")\n",
    "\n",
    "df5=[df, df2,  df3, df4]\n",
    "\n",
    "result = pd.concat([df,df2,df3, df4], axis=1, join_axes=[df.index])'''\n",
    "#result.to_excel('result.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeColumns(result):\n",
    "    del result['Pain']\n",
    "    del result['Content']\n",
    "    del result['Filtered']\n",
    "    del result['Stemmed']\n",
    "    del result['big1']\n",
    "    del result['big2']\n",
    "    del result['small1']\n",
    "    del result['small2']\n",
    "    del result['Height']\n",
    "    del result['Joined']\n",
    "    del result['Posted']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorizeCount(result):\n",
    "    '''for i in range(len(result)):\n",
    "        if result[i]==0:\n",
    "            result[i]=0\n",
    "        if result[i]>0 and result[i]<=3:\n",
    "            result[i]=1\n",
    "        if result[i]>3:\n",
    "            result[i]=2'''\n",
    "    for i in range(len(result)):\n",
    "        if result.at[i,'MentalCount']==0:\n",
    "            result.at[i,'MentalCount']=0\n",
    "        if result.at[i,'MentalCount']>0 and result.at[i,'MentalCount']<=3:\n",
    "            result.at[i,'MentalCount']=1\n",
    "        if result.at[i,'MentalCount']>3:\n",
    "            result.at[i,'MentalCount']=2\n",
    "            \n",
    "        if result.at[i,'ADRCount']==0:\n",
    "            result.at[i,'ADRCount']=0\n",
    "        if result.at[i,'ADRCount']>0 and result.at[i,'MentalCount']<=3:\n",
    "            result.at[i,'ADRCount']=1\n",
    "        if result.at[i,'ADRCount']>3:\n",
    "            result.at[i,'ADRCount']=2\n",
    "\n",
    "        if result.at[i,'DieaseCount']==0:\n",
    "            result.at[i,'DieaseCount']=0\n",
    "        if result.at[i,'DieaseCount']>0 and result.at[i,'DieaseCount']<=3:\n",
    "            result.at[i,'DieaseCount']=1\n",
    "        if result.at[i,'DieaseCount']>3:\n",
    "            result.at[i,'DieaseCount']=2\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### manipulating data to prepare for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manipulate(result,label):\n",
    "    imp_mean = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "    result['Gender']=imp_mean.fit_transform(result['Gender'].values.reshape(-1, 1))\n",
    "    result = vectorizeCount(result)\n",
    "    for i in range(len(result)):\n",
    "        if result.at[i,'Gender']=='Male':\n",
    "            result.at[i,'Gender']=0\n",
    "        if result.at[i,'Gender']=='Female':\n",
    "            result.at[i,'Gender']=1\n",
    "    result['Drug']=LabelEncoder().fit_transform(result['Drug'])\n",
    "    if 'Unnamed: 0' in result:\n",
    "        del result['Unnamed: 0'] \n",
    "    result['DrugFamily']=LabelEncoder().fit_transform(result['DrugFamily'])\n",
    "    labels=result.iloc[:][label]\n",
    "    del result[label]\n",
    "    #removeColumns(result)\n",
    "    imp_mean = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "    result['Age']=imp_mean.fit_transform(result['Age'].values.reshape(-1, 1))\n",
    "    if 'Height' in result:\n",
    "        result['Height']=imp_mean.fit_transform(result['Height'].values.reshape(-1, 1))\n",
    "    return result,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#asklabel=pd.read_excel('asklabels.xlsx')\n",
    "#labels=asklabel.iloc[:]['MICROCEPHALY , EPILEPSY , AND DIABETES SYNDROME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def SMOTE(begin,columns):\n",
    "    from imblearn.over_sampling import SMOTENC\n",
    "    x=[1]\n",
    "    x.extend(list(range(begin,len(columns))))\n",
    "    sm=SMOTENC(random_state=42, categorical_features=x)\n",
    "    return sm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label='ADRCount'\n",
    "asklabel='ADRCount'\n",
    "\n",
    "#from collections import Counter\n",
    "#X_res, y_res = sm.fit_resample(result, result_labels)\n",
    "#print(Counter(result_labels))\n",
    "#print(Counter(y_res))\n",
    "def prepareDataset(label,asklab):\n",
    "    from imblearn.over_sampling import SMOTENC\n",
    "    \n",
    "    \n",
    "    result=pd.read_excel('result_reduced.xlsx')\n",
    "    weighted=pd.read_excel('Weighted_reduced.xlsx')\n",
    "    blood=pd.read_excel('blood_reduced.xlsx')\n",
    "    ask=pd.read_excel('askapatient_reduced.xlsx')\n",
    "\n",
    "    result,result_labels=manipulate(result,label)\n",
    "    weighted,weighted_labels=manipulate(weighted,label)\n",
    "    blood,blood_labels=manipulate(blood,label)\n",
    "    ask,ask_labels=manipulate(ask,asklab)\n",
    "    \n",
    " \n",
    "\n",
    "    sm1 = SMOTE(2,result.columns)\n",
    "    sm2 = SMOTE(4,weighted.columns)\n",
    "    sm3 = SMOTE(4,blood.columns)\n",
    "    sm4 = SMOTE(2,ask.columns)\n",
    "    #Applying SMOTENC\n",
    "    result,result_labels=sm1.fit_resample(result,result_labels)\n",
    "    weighted,weighted_labels=sm2.fit_resample(weighted,weighted_labels)\n",
    "    blood,blood_labels=sm3.fit_resample(blood,blood_labels)\n",
    "    ask,ask_labels=sm4.fit_resample(ask,ask_labels)\n",
    "    return result,result_labels,weighted,weighted_labels,blood,blood_labels,ask,ask_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label='ADRCount'\n",
    "asklabel='ADRCount'\n",
    "\n",
    "#from collections import Counter\n",
    "#X_res, y_res = sm.fit_resample(result, result_labels)\n",
    "#print(Counter(result_labels))\n",
    "#print(Counter(y_res))\n",
    "def prepareDatasetNoSmote(label,asklab):\n",
    "    from imblearn.over_sampling import SMOTENC\n",
    "    \n",
    "    sm = SMOTENC(random_state=42, categorical_features=[0, 1,3])\n",
    "    \n",
    "    result=pd.read_excel('result_reduced.xlsx')\n",
    "    weighted=pd.read_excel('Weighted_reduced.xlsx')\n",
    "    blood=pd.read_excel('blood_reduced.xlsx')\n",
    "    ask=pd.read_excel('askapatient_reduced.xlsx')\n",
    "\n",
    "\n",
    "    result,result_labels=manipulate(result,label)\n",
    "    weighted,weighted_labels=manipulate(weighted,label)\n",
    "    blood,blood_labels=manipulate(blood,label)\n",
    "    ask,ask_labels=manipulate(ask,asklab)\n",
    "    \n",
    "    \n",
    "    #Applying SMOTENC\n",
    "    #result,result_labels=sm.fit_resample(result,result_labels)\n",
    "    #weighted,weighted_labels=sm.fit_resample(weighted,weighted_labels)\n",
    "    #blood,blood_labels=sm.fit_resample(blood,blood_labels)\n",
    "    #ask,ask_labels=sm.fit_resample(ask,ask_labels)\n",
    "    return result,result_labels,weighted,weighted_labels,blood,blood_labels,ask,ask_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"for i in weighted:\\n    if i not in result:\\n        if i != 'weights2':\\n            del weighted[i]\\nweighted.to_excel('Weighted.xlsx')\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''for i in weighted:\n",
    "    if i not in result:\n",
    "        if i != 'weights2':\n",
    "            del weighted[i]\n",
    "weighted.to_excel('Weighted.xlsx')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ask_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for i in weighted:\\n    print (weighted[i])'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''for i in weighted:\n",
    "    print (weighted[i])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(model, X_train,X_test,Y_train,Y_test):\n",
    "    model.fit(X_train,Y_train)\n",
    "    return model.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10-Fold Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#cross_val_score(RandomForestClassifier(n_estimators=1000),result,result_labels,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This was used for some other no longer existing purposes\n",
    "def getMissingPercentage(feature):\n",
    "    #nancount = int(result[result[feature].isnull()][feature].shape[0])\n",
    "    nancount = int(result[result[feature]==1][feature].shape[0])\n",
    "    size=int(result.shape[0])\n",
    "    print (nancount)\n",
    "    print ((nancount*100)/size)\n",
    "#getMissingPercentage('Pvc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importance(result,result_labels):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.feature_selection import SelectFromModel\n",
    "    from collections import Counter\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(result, result_labels, test_size=0.30, random_state=42)\n",
    "    X_train, X_test, Y_train, Y_test = pd.DataFrame(X_train),pd.DataFrame(X_test),pd.DataFrame(Y_train),pd.DataFrame(Y_test),\n",
    "    #print(Counter(result_labels))\n",
    "    sel = SelectFromModel(RandomForestClassifier(n_estimators = 500))\n",
    "    sel.fit(X_train, Y_train)\n",
    "    #print(sel.get_support())\n",
    "    selected_feat= X_train.columns[(sel.get_support())]\n",
    "    \n",
    "    #print(len(selected_feat))\n",
    "    print(selected_feat)\n",
    "\n",
    "\n",
    "    return selected_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotResult(name,max_res,max_wei,max_bld,max_ask,x1,x2,x3,x4):\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    fig, ax = plt.subplots()\n",
    "    width = 0.2\n",
    "\n",
    "    acc_m = (max_res['Accuracy'][x1],max_wei['Accuracy'][x2],max_bld['Accuracy'][x3],max_ask['Accuracy'][x4])\n",
    "    pre_m = (max_res['Precision'][x1],max_wei['Precision'][x2],max_bld['Precision'][x3],max_ask['Precision'][x4])\n",
    "    rec_m = (max_res['Recall'][x1],max_wei['Recall'][x2],max_bld['Recall'][x3],max_ask['Recall'][x4])\n",
    "    fse_m = (max_res['FScore'][x1],max_wei['FScore'][x2],max_bld['FScore'][x3],max_ask['FScore'][x4])\n",
    "\n",
    "    ind = np.arange(len(acc_m)) \n",
    "    old_ind =  ind\n",
    "    rects1 = ax.bar(ind,acc_m, width=width ,label='accuracy')\n",
    "    ind = ind + width\n",
    "    rects2 = ax.bar(ind,pre_m, width=width,label='Precision')\n",
    "    ind = ind + width\n",
    "    rects3 = ax.bar(ind,rec_m, width=width,label='recall')\n",
    "    ind = ind + width\n",
    "    rects4 = ax.bar(ind,fse_m, width=width ,label='fscore')\n",
    "\n",
    "\n",
    "    # Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "    ax.set_ylabel('Scores')\n",
    "    ax.set_title(name)\n",
    "    ax.set_xticks(old_ind+ width *2)\n",
    "    ax.set_xticklabels(('complete', 'weighted', 'pressure', 'ask'))\n",
    "    box = ax.get_position()\n",
    "    ax.set_position([box.x0, box.y0,box.width, box.height * 0.6])\n",
    "    ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05), fancybox=True,shadow=True, ncol=4)\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from sklearn.model_selection import KFold\\nfrom sklearn.ensemble import RandomForestClassifier\\nkf = KFold(n_splits=10)\\n\\nscores_rf=[]\\n\\nfor train_index, test_index in kf.split(result):\\n    X_train, X_test, Y_train, Y_test = result.iloc[train_index], result.iloc[test_index], result_labels.iloc[train_index],result_labels.iloc[test_index]\\n    scores_rf.append(get_score(RandomForestClassifier(n_estimators=400),X_train, X_test, Y_train, Y_test))'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "kf = KFold(n_splits=10)\n",
    "\n",
    "scores_rf=[]\n",
    "\n",
    "for train_index, test_index in kf.split(result):\n",
    "    X_train, X_test, Y_train, Y_test = result.iloc[train_index], result.iloc[test_index], result_labels.iloc[train_index],result_labels.iloc[test_index]\n",
    "    scores_rf.append(get_score(RandomForestClassifier(n_estimators=400),X_train, X_test, Y_train, Y_test))'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomForest(result,result_labels,estimators,DataSet):\n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn.metrics import f1_score\n",
    "    from collections import Counter\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(result, result_labels, test_size=0.30, random_state=42)\n",
    "    print(Counter(result_labels))\n",
    "    clf = RandomForestClassifier(n_estimators=estimators,random_state=0)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    pred=clf.predict(X_test)\n",
    "    accuracy=(accuracy_score(Y_test, pred))\n",
    "    #print (accuracy)\n",
    "    scores_rf=(precision_recall_fscore_support(Y_test,pred, average='macro'))\n",
    "    #print(DataSet)\n",
    "    #print (pred)\n",
    "    #print(classification_report(Y_test,pred,labels=[0,1,2]))\n",
    "        \n",
    "    return accuracy,scores_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "Counter({0: 1168, 1: 1168})\n",
      "Counter({0: 89, 1: 89})\n",
      "Counter({0: 334, 1: 334})\n",
      "Counter({0: 590, 1: 590})\n",
      "Res: Accuracy: 0.8202567760342369 # Scores: (0.8270632368703108, 0.8236265887842843, 0.8200630714320638, None)\n",
      "Wei: Accuracy: 0.9074074074074074 # Scores: (0.8969144460028051, 0.9161764705882353, 0.9033989266547406, None)\n",
      "Bld: Accuracy: 0.8656716417910447 # Scores: (0.8656250000000001, 0.8653350515463918, 0.8654585120360959, None)\n",
      "Ask: Accuracy: 0.7937853107344632 # Scores: (0.7964872394248935, 0.7966867469879518, 0.7937836651637873, None)\n",
      "200\n",
      "Counter({0: 1168, 1: 1168})\n",
      "Counter({0: 89, 1: 89})\n",
      "Counter({0: 334, 1: 334})\n",
      "Counter({0: 590, 1: 590})\n",
      "Res: Accuracy: 0.8202567760342369 # Scores: (0.8265126313362537, 0.8234919806164238, 0.8200953234479387, None)\n",
      "Wei: Accuracy: 0.9074074074074074 # Scores: (0.8969144460028051, 0.9161764705882353, 0.9033989266547406, None)\n",
      "Bld: Accuracy: 0.8756218905472637 # Scores: (0.8760688009544642, 0.8749504361617764, 0.875313267660852, None)\n",
      "Ask: Accuracy: 0.7853107344632768 # Scores: (0.7876344086021505, 0.7880030761343245, 0.7853038815117467, None)\n",
      "300\n",
      "Counter({0: 1168, 1: 1168})\n",
      "Counter({0: 89, 1: 89})\n",
      "Counter({0: 334, 1: 334})\n",
      "Counter({0: 590, 1: 590})\n",
      "Res: Accuracy: 0.818830242510699 # Scores: (0.8264845841181719, 0.8223987991319812, 0.8185806714554995, None)\n",
      "Wei: Accuracy: 0.9074074074074074 # Scores: (0.8969144460028051, 0.9161764705882353, 0.9033989266547406, None)\n",
      "Bld: Accuracy: 0.8805970149253731 # Scores: (0.8807845084409136, 0.8801050753370341, 0.8803571428571428, None)\n",
      "Ask: Accuracy: 0.7909604519774012 # Scores: (0.7940271725198667, 0.7940271725198667, 0.7909604519774013, None)\n",
      "400\n",
      "Counter({0: 1168, 1: 1168})\n",
      "Counter({0: 89, 1: 89})\n",
      "Counter({0: 334, 1: 334})\n",
      "Counter({0: 590, 1: 590})\n",
      "Res: Accuracy: 0.818830242510699 # Scores: (0.8270910896003971, 0.8225334072998418, 0.8185407354412914, None)\n",
      "Wei: Accuracy: 0.9259259259259259 # Scores: (0.9161931818181819, 0.9308823529411765, 0.922077922077922, None)\n",
      "Bld: Accuracy: 0.8656716417910447 # Scores: (0.8656250000000001, 0.8653350515463918, 0.8654585120360959, None)\n",
      "Ask: Accuracy: 0.7909604519774012 # Scores: (0.7948331193838254, 0.7943796462445527, 0.7909537793667007, None)\n",
      "500\n",
      "Counter({0: 1168, 1: 1168})\n",
      "Counter({0: 89, 1: 89})\n",
      "Counter({0: 334, 1: 334})\n",
      "Counter({0: 590, 1: 590})\n",
      "Res: Accuracy: 0.8216833095577746 # Scores: (0.8299908993133118, 0.8253928111080292, 0.8213983616548143, None)\n",
      "Wei: Accuracy: 0.9259259259259259 # Scores: (0.9161931818181819, 0.9308823529411765, 0.922077922077922, None)\n",
      "Bld: Accuracy: 0.8557213930348259 # Scores: (0.8560847086896003, 0.8550257731958764, 0.8553633904865885, None)\n",
      "Ask: Accuracy: 0.7937853107344632 # Scores: (0.7972582972582973, 0.7970392207126378, 0.7937836651637873, None)\n",
      "600\n",
      "Counter({0: 1168, 1: 1168})\n",
      "Counter({0: 89, 1: 89})\n",
      "Counter({0: 334, 1: 334})\n",
      "Counter({0: 590, 1: 590})\n",
      "Res: Accuracy: 0.8174037089871612 # Scores: (0.8259521443947673, 0.8211710094796782, 0.8170906718851925, None)\n",
      "Wei: Accuracy: 0.9259259259259259 # Scores: (0.9161931818181819, 0.9308823529411765, 0.922077922077922, None)\n",
      "Bld: Accuracy: 0.8606965174129353 # Scores: (0.8608242303872891, 0.8601804123711341, 0.8604166666666666, None)\n",
      "Ask: Accuracy: 0.7966101694915254 # Scores: (0.7996987951807228, 0.7996987951807228, 0.7966101694915255, None)\n",
      "700\n",
      "Counter({0: 1168, 1: 1168})\n",
      "Counter({0: 89, 1: 89})\n",
      "Counter({0: 334, 1: 334})\n",
      "Counter({0: 590, 1: 590})\n",
      "Res: Accuracy: 0.8259629101283881 # Scores: (0.8346580559695314, 0.8297492209042405, 0.8256645466405741, None)\n",
      "Wei: Accuracy: 0.9259259259259259 # Scores: (0.9161931818181819, 0.9308823529411765, 0.922077922077922, None)\n",
      "Bld: Accuracy: 0.8606965174129353 # Scores: (0.8608242303872891, 0.8601804123711341, 0.8604166666666666, None)\n",
      "Ask: Accuracy: 0.7966101694915254 # Scores: (0.7996987951807228, 0.7996987951807228, 0.7966101694915255, None)\n",
      "800\n",
      "Counter({0: 1168, 1: 1168})\n",
      "Counter({0: 89, 1: 89})\n",
      "Counter({0: 334, 1: 334})\n",
      "Counter({0: 590, 1: 590})\n",
      "Res: Accuracy: 0.8259629101283881 # Scores: (0.8340291671489277, 0.8296146127363802, 0.8257043401702155, None)\n",
      "Wei: Accuracy: 0.9259259259259259 # Scores: (0.9161931818181819, 0.9308823529411765, 0.922077922077922, None)\n",
      "Bld: Accuracy: 0.8557213930348259 # Scores: (0.8560847086896003, 0.8550257731958764, 0.8553633904865885, None)\n",
      "Ask: Accuracy: 0.7937853107344632 # Scores: (0.7972582972582973, 0.7970392207126378, 0.7937836651637873, None)\n",
      "900\n",
      "Counter({0: 1168, 1: 1168})\n",
      "Counter({0: 89, 1: 89})\n",
      "Counter({0: 334, 1: 334})\n",
      "Counter({0: 590, 1: 590})\n",
      "Res: Accuracy: 0.8288159771754636 # Scores: (0.8369268671770367, 0.8324740165445675, 0.8285616460690645, None)\n",
      "Wei: Accuracy: 0.9259259259259259 # Scores: (0.9161931818181819, 0.9308823529411765, 0.922077922077922, None)\n",
      "Bld: Accuracy: 0.8656716417910447 # Scores: (0.8656250000000001, 0.8653350515463918, 0.8654585120360959, None)\n",
      "Ask: Accuracy: 0.7966101694915254 # Scores: (0.7996987951807228, 0.7996987951807228, 0.7966101694915255, None)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "label='Pain'\n",
    "asklabel='Pain'\n",
    "res_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "wei_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "bld_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "ask_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "for estimators in range (100,1000,100):\n",
    "    print (estimators)\n",
    "    result,result_labels,weighted,weighted_labels,blood,blood_labels,ask,ask_labels=prepareDataset(label,asklabel)\n",
    "    res_acc,res_scores=randomForest(result,result_labels,estimators,\"Result\")\n",
    "    wei_acc,wei_scores=randomForest(weighted,weighted_labels,estimators,\"Weighted\")\n",
    "    blood_acc,blood_scores=randomForest(blood,blood_labels,estimators,\"Blood\")\n",
    "    ask_acc,ask_scores=randomForest(ask,ask_labels,estimators,\"Ask\")\n",
    "    print(\"Res: Accuracy: \" + str(res_acc)+\" # \"+ \"Scores: \"+str(res_scores))\n",
    "    print(\"Wei: Accuracy: \" + str(wei_acc)+\" # \"+ \"Scores: \"+str(wei_scores))\n",
    "    print(\"Bld: Accuracy: \" + str(blood_acc)+\" # \"+ \"Scores: \"+str(blood_scores))\n",
    "    print(\"Ask: Accuracy: \" + str(ask_acc)+\" # \"+ \"Scores: \"+str(ask_scores))\n",
    "    res_Stats=res_Stats.append({'Estimators':estimators,'Accuracy':res_acc,'Precision':res_scores[0],'Recall':res_scores[1],'FScore':res_scores[2]},ignore_index=True)\n",
    "    wei_Stats=wei_Stats.append({'Estimators':estimators,'Accuracy':wei_acc,'Precision':wei_scores[0],'Recall':wei_scores[1],'FScore':wei_scores[2]},ignore_index=True)\n",
    "    bld_Stats=bld_Stats.append({'Estimators':estimators,'Accuracy':blood_acc,'Precision':blood_scores[0],'Recall':blood_scores[1],'FScore':blood_scores[2]},ignore_index=True)\n",
    "    ask_Stats=ask_Stats.append({'Estimators':estimators,'Accuracy':ask_acc,'Precision':ask_scores[0],'Recall':ask_scores[1],'FScore':ask_scores[2]},ignore_index=True)\n",
    "'''writer = pd.ExcelWriter('Forrest_Stats'+label+'.xlsx', engine='xlsxwriter')\n",
    "res_Stats.to_excel(writer, sheet_name='Sheet1') \n",
    "wei_Stats.to_excel(writer, sheet_name='Sheet2') \n",
    "bld_Stats.to_excel(writer, sheet_name='Sheet3') \n",
    "ask_Stats.to_excel(writer, sheet_name='Sheet4')\n",
    "writer.save()'''\n",
    "x1=res_Stats['FScore'].tolist().index(max(res_Stats['FScore'].tolist()))\n",
    "x2=wei_Stats['FScore'].tolist().index(max(wei_Stats['FScore'].tolist()))\n",
    "x3=bld_Stats['FScore'].tolist().index(max(bld_Stats['FScore'].tolist()))\n",
    "x4=ask_Stats['FScore'].tolist().index(max(ask_Stats['FScore'].tolist()))\n",
    "max_res=res_Stats.iloc[x1].to_frame().transpose()\n",
    "max_wei=wei_Stats.iloc[x2].to_frame().transpose()\n",
    "max_bld=bld_Stats.iloc[x3].to_frame().transpose()\n",
    "max_ask=ask_Stats.iloc[x4].to_frame().transpose()\n",
    "stats=pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "max_res['Estimators']=\"Complete\"\n",
    "max_wei['Estimators']=\"Weighted\"\n",
    "max_bld['Estimators']=\"Pressure\"\n",
    "max_ask['Estimators']=\"Ask\"\n",
    "stats=stats.append(max_res)\n",
    "stats=stats.append(max_wei)\n",
    "stats=stats.append(max_bld)\n",
    "stats=stats.append(max_ask)\n",
    "\n",
    "plotResult(label+\" Random Forest With Smote\",max_res,max_wei,max_bld,max_ask,x1,x2,x3,x4)\n",
    "\n",
    "import os.path\n",
    "if not os.path.exists('Forrest_StatsTotal'+'.xlsx'):\n",
    "    writer = pd.ExcelWriter('Forrest_StatsTotal'+'.xlsx', engine = 'xlsxwriter')\n",
    "\n",
    "    writer.save()\n",
    "    writer.close()\n",
    "writer = pd.ExcelWriter('Forrest_StatsTotal'+'.xlsx', engine='openpyxl')\n",
    "book = load_workbook('Forrest_StatsTotal'+'.xlsx')\n",
    "writer.book = book\n",
    "writer.sheets = dict((ws.title, ws) for ws in book.worksheets)\n",
    "\n",
    "stats.to_excel(writer, sheet_name=label)\n",
    "writer.save()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests with importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 2, 3, 4], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 2, 3, 4, 5, 6, 7, 9, 10], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 2, 3, 4, 6, 8], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 4], dtype='int64')\n",
      "Counter({0: 1403, 1: 1403})\n",
      "Counter({0: 107, 1: 107})\n",
      "Counter({0: 399, 1: 399})\n",
      "Counter({0: 643, 1: 643})\n",
      "Res: Accuracy: 0.8004750593824228 # Scores: (0.8011535680390474, 0.8008544403810556, 0.8004570461278037, None)\n",
      "Wei: Accuracy: 0.9230769230769231 # Scores: (0.9236242884250474, 0.9228219696969697, 0.9230040274816395, None)\n",
      "Bld: Accuracy: 0.8833333333333333 # Scores: (0.883023061961656, 0.8838763575605681, 0.8832035595105674, None)\n",
      "Ask: Accuracy: 0.8471502590673575 # Scores: (0.8664113243817901, 0.8392664509169363, 0.8424020981682547, None)\n",
      "200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 2, 3, 4], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 2, 3, 4, 5, 6, 7, 9], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 2, 3, 4, 6, 8], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 4], dtype='int64')\n",
      "Counter({0: 1403, 1: 1403})\n",
      "Counter({0: 107, 1: 107})\n",
      "Counter({0: 399, 1: 399})\n",
      "Counter({0: 643, 1: 643})\n",
      "Res: Accuracy: 0.8040380047505938 # Scores: (0.8051215498668295, 0.8045171339563864, 0.8039912809768692, None)\n",
      "Wei: Accuracy: 0.8769230769230769 # Scores: (0.8768939393939394, 0.8768939393939394, 0.8768939393939394, None)\n",
      "Bld: Accuracy: 0.9 # Scores: (0.899610678531702, 0.9001670843776107, 0.8998260869565218, None)\n",
      "Ask: Accuracy: 0.8471502590673575 # Scores: (0.8664113243817901, 0.8392664509169363, 0.8424020981682547, None)\n",
      "300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 2, 3, 4], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 2, 3, 4, 5, 6, 7, 9], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 2, 3, 4, 6, 8], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 4], dtype='int64')\n",
      "Counter({0: 1403, 1: 1403})\n",
      "Counter({0: 107, 1: 107})\n",
      "Counter({0: 399, 1: 399})\n",
      "Counter({0: 643, 1: 643})\n",
      "Res: Accuracy: 0.8004750593824228 # Scores: (0.8011535680390474, 0.8008544403810556, 0.8004570461278037, None)\n",
      "Wei: Accuracy: 0.8615384615384616 # Scores: (0.861954459203036, 0.8612689393939394, 0.8614072494669509, None)\n",
      "Bld: Accuracy: 0.8916666666666667 # Scores: (0.8912680756395995, 0.8918128654970761, 0.8914782608695652, None)\n",
      "Ask: Accuracy: 0.8471502590673575 # Scores: (0.8664113243817901, 0.8392664509169363, 0.8424020981682547, None)\n",
      "400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 2, 3, 4], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 2, 3, 4, 6, 7, 9, 10], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 2, 3, 4, 6, 8], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 4], dtype='int64')\n",
      "Counter({0: 1403, 1: 1403})\n",
      "Counter({0: 107, 1: 107})\n",
      "Counter({0: 399, 1: 399})\n",
      "Counter({0: 643, 1: 643})\n",
      "Res: Accuracy: 0.8004750593824228 # Scores: (0.8013020480130204, 0.8008939455505892, 0.8004469122426869, None)\n",
      "Wei: Accuracy: 0.9076923076923077 # Scores: (0.9076704545454546, 0.9076704545454546, 0.9076704545454546, None)\n",
      "Bld: Accuracy: 0.9083333333333333 # Scores: (0.9079532814238043, 0.9085213032581454, 0.9081739130434783, None)\n",
      "Ask: Accuracy: 0.8471502590673575 # Scores: (0.8664113243817901, 0.8392664509169363, 0.8424020981682547, None)\n",
      "500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 2, 3, 4], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 2, 3, 4, 5, 6, 7, 9, 10], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 2, 3, 4, 6, 8], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 4], dtype='int64')\n",
      "Counter({0: 1403, 1: 1403})\n",
      "Counter({0: 107, 1: 107})\n",
      "Counter({0: 399, 1: 399})\n",
      "Counter({0: 643, 1: 643})\n",
      "Res: Accuracy: 0.7980997624703088 # Scores: (0.7989228717392287, 0.7985179917829247, 0.798071280245576, None)\n",
      "Wei: Accuracy: 0.9230769230769231 # Scores: (0.9236242884250474, 0.9228219696969697, 0.9230040274816395, None)\n",
      "Bld: Accuracy: 0.9083333333333333 # Scores: (0.9079532814238043, 0.9085213032581454, 0.9081739130434783, None)\n",
      "Ask: Accuracy: 0.8471502590673575 # Scores: (0.8664113243817901, 0.8392664509169363, 0.8424020981682547, None)\n",
      "600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 2, 3, 4], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 2, 3, 4, 5, 6, 7, 9, 10], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 2, 3, 4, 6, 8], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 4], dtype='int64')\n",
      "Counter({0: 1403, 1: 1403})\n",
      "Counter({0: 107, 1: 107})\n",
      "Counter({0: 399, 1: 399})\n",
      "Counter({0: 643, 1: 643})\n",
      "Res: Accuracy: 0.8016627078384798 # Scores: (0.802273433307916, 0.802022664680121, 0.8016489988221437, None)\n",
      "Wei: Accuracy: 0.9230769230769231 # Scores: (0.9236242884250474, 0.9228219696969697, 0.9230040274816395, None)\n",
      "Bld: Accuracy: 0.9083333333333333 # Scores: (0.9079532814238043, 0.9085213032581454, 0.9081739130434783, None)\n",
      "Ask: Accuracy: 0.8471502590673575 # Scores: (0.8664113243817901, 0.8392664509169363, 0.8424020981682547, None)\n",
      "700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 2, 3, 4], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 2, 3, 4, 5, 6, 7, 9, 10], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 2, 3, 4, 6, 8], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 4], dtype='int64')\n",
      "Counter({0: 1403, 1: 1403})\n",
      "Counter({0: 107, 1: 107})\n",
      "Counter({0: 399, 1: 399})\n",
      "Counter({0: 643, 1: 643})\n",
      "Res: Accuracy: 0.8028503562945368 # Scores: (0.8035318841234691, 0.80323039414872, 0.802832557483425, None)\n",
      "Wei: Accuracy: 0.9230769230769231 # Scores: (0.9236242884250474, 0.9228219696969697, 0.9230040274816395, None)\n",
      "Bld: Accuracy: 0.9083333333333333 # Scores: (0.9079532814238043, 0.9085213032581454, 0.9081739130434783, None)\n",
      "Ask: Accuracy: 0.8471502590673575 # Scores: (0.8664113243817901, 0.8392664509169363, 0.8424020981682547, None)\n",
      "800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 2, 3, 4], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 2, 3, 4, 5, 6, 7, 9, 10], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 2, 3, 4, 6, 8], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 4], dtype='int64')\n",
      "Counter({0: 1403, 1: 1403})\n",
      "Counter({0: 107, 1: 107})\n",
      "Counter({0: 399, 1: 399})\n",
      "Counter({0: 643, 1: 643})\n",
      "Res: Accuracy: 0.8040380047505938 # Scores: (0.804794191598158, 0.804438123617319, 0.804015613295847, None)\n",
      "Wei: Accuracy: 0.9230769230769231 # Scores: (0.9236242884250474, 0.9228219696969697, 0.9230040274816395, None)\n",
      "Bld: Accuracy: 0.9083333333333333 # Scores: (0.9079532814238043, 0.9085213032581454, 0.9081739130434783, None)\n",
      "Ask: Accuracy: 0.8471502590673575 # Scores: (0.8664113243817901, 0.8392664509169363, 0.8424020981682547, None)\n",
      "900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 2, 3, 4], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 2, 3, 4, 5, 6, 7, 9], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 2, 3, 4, 6, 8], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 4], dtype='int64')\n",
      "Counter({0: 1403, 1: 1403})\n",
      "Counter({0: 107, 1: 107})\n",
      "Counter({0: 399, 1: 399})\n",
      "Counter({0: 643, 1: 643})\n",
      "Res: Accuracy: 0.8016627078384798 # Scores: (0.8021451520917915, 0.8019831595105873, 0.8016557136791741, None)\n",
      "Wei: Accuracy: 0.8615384615384616 # Scores: (0.861954459203036, 0.8612689393939394, 0.8614072494669509, None)\n",
      "Bld: Accuracy: 0.9041666666666667 # Scores: (0.9037940379403794, 0.9045530492898914, 0.9040317112606269, None)\n",
      "Ask: Accuracy: 0.8471502590673575 # Scores: (0.8664113243817901, 0.8392664509169363, 0.8424020981682547, None)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "label='Vertigo'\n",
    "asklabel='Vertigo'\n",
    "res_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "wei_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "bld_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "ask_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "for estimators in range (100,1000,100):\n",
    "    print (estimators)\n",
    "    result,result_labels,weighted,weighted_labels,blood,blood_labels,ask,ask_labels=prepareDataset(label,asklabel)\n",
    "    res_feat=importance(result,result_labels)\n",
    "    wei_feat=importance(weighted,weighted_labels)\n",
    "    blood_feat=importance(blood,blood_labels)\n",
    "    ask_feat=importance(ask,ask_labels)\n",
    "    res_acc,res_scores=randomForest(pd.DataFrame(result)[res_feat],result_labels,estimators,\"Result\")\n",
    "    wei_acc,wei_scores=randomForest(pd.DataFrame(weighted)[wei_feat],weighted_labels,estimators,\"Weighted\")\n",
    "    blood_acc,blood_scores=randomForest(pd.DataFrame(blood)[blood_feat],blood_labels,estimators,\"Blood\")\n",
    "    ask_acc,ask_scores=randomForest(pd.DataFrame(ask)[ask_feat],ask_labels,estimators,\"Ask\")\n",
    "    print(\"Res: Accuracy: \" + str(res_acc)+\" # \"+ \"Scores: \"+str(res_scores))\n",
    "    print(\"Wei: Accuracy: \" + str(wei_acc)+\" # \"+ \"Scores: \"+str(wei_scores))\n",
    "    print(\"Bld: Accuracy: \" + str(blood_acc)+\" # \"+ \"Scores: \"+str(blood_scores))\n",
    "    print(\"Ask: Accuracy: \" + str(ask_acc)+\" # \"+ \"Scores: \"+str(ask_scores))\n",
    "    res_Stats=res_Stats.append({'Estimators':estimators,'Accuracy':res_acc,'Precision':res_scores[0],'Recall':res_scores[1],'FScore':res_scores[2]},ignore_index=True)\n",
    "    wei_Stats=wei_Stats.append({'Estimators':estimators,'Accuracy':wei_acc,'Precision':wei_scores[0],'Recall':wei_scores[1],'FScore':wei_scores[2]},ignore_index=True)\n",
    "    bld_Stats=bld_Stats.append({'Estimators':estimators,'Accuracy':blood_acc,'Precision':blood_scores[0],'Recall':blood_scores[1],'FScore':blood_scores[2]},ignore_index=True)\n",
    "    ask_Stats=ask_Stats.append({'Estimators':estimators,'Accuracy':ask_acc,'Precision':ask_scores[0],'Recall':ask_scores[1],'FScore':ask_scores[2]},ignore_index=True)\n",
    "x1=res_Stats['FScore'].tolist().index(max(res_Stats['FScore'].tolist()))\n",
    "x2=wei_Stats['FScore'].tolist().index(max(wei_Stats['FScore'].tolist()))\n",
    "x3=bld_Stats['FScore'].tolist().index(max(bld_Stats['FScore'].tolist()))\n",
    "x4=ask_Stats['FScore'].tolist().index(max(ask_Stats['FScore'].tolist()))\n",
    "max_res=res_Stats.iloc[x1].to_frame().transpose()\n",
    "max_wei=wei_Stats.iloc[x2].to_frame().transpose()\n",
    "max_bld=bld_Stats.iloc[x3].to_frame().transpose()\n",
    "max_ask=ask_Stats.iloc[x4].to_frame().transpose()\n",
    "stats=pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "max_res['Estimators']=\"Complete\"\n",
    "max_wei['Estimators']=\"Weighted\"\n",
    "max_bld['Estimators']=\"Pressure\"\n",
    "max_ask['Estimators']=\"Ask\"\n",
    "stats=stats.append(max_res)\n",
    "stats=stats.append(max_wei)\n",
    "stats=stats.append(max_bld)\n",
    "stats=stats.append(max_ask)\n",
    "\n",
    "plotResult(label+\" Random Forest With Feature Filtering\",max_res,max_wei,max_bld,max_ask,x1,x2,x3,x4)\n",
    "\n",
    "import os.path\n",
    "if not os.path.exists('Forrest_StatsImportanceTotal'+'.xlsx'):\n",
    "    writer = pd.ExcelWriter('Forrest_StatsImportanceTotal'+'.xlsx', engine = 'xlsxwriter')\n",
    "\n",
    "    writer.save()\n",
    "    writer.close()\n",
    "writer = pd.ExcelWriter('Forrest_StatsImportanceTotal'+'.xlsx', engine='openpyxl')\n",
    "book = load_workbook('Forrest_StatsImportanceTotal'+'.xlsx')\n",
    "writer.book = book\n",
    "writer.sheets = dict((ws.title, ws) for ws in book.worksheets)\n",
    "\n",
    "stats.to_excel(writer, sheet_name=label)\n",
    "writer.save()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "Counter({0: 834, 1: 723})\n",
      "Counter({1: 80, 0: 50})\n",
      "Counter({1: 274, 0: 188})\n",
      "Counter({0: 608, 1: 148})\n",
      "Res: Accuracy: 0.7008547008547008 # Scores: (0.7007251153592617, 0.7003289473684211, 0.7004115226337448, None)\n",
      "Wei: Accuracy: 0.717948717948718 # Scores: (0.6370967741935484, 0.6103896103896104, 0.6173059768064229, None)\n",
      "Bld: Accuracy: 0.8273381294964028 # Scores: (0.8401511203751955, 0.7885720601237842, 0.8028368794326242, None)\n",
      "Ask: Accuracy: 0.7444933920704846 # Scores: (0.5572548028311426, 0.5644381223328592, 0.5599598930481284, None)\n",
      "200\n",
      "Counter({0: 834, 1: 723})\n",
      "Counter({1: 80, 0: 50})\n",
      "Counter({1: 274, 0: 188})\n",
      "Counter({0: 608, 1: 148})\n",
      "Res: Accuracy: 0.7029914529914529 # Scores: (0.7027983539094651, 0.7026315789473685, 0.7026860269014027, None)\n",
      "Wei: Accuracy: 0.6923076923076923 # Scores: (0.6201298701298701, 0.6201298701298701, 0.6201298701298701, None)\n",
      "Bld: Accuracy: 0.8057553956834532 # Scores: (0.8159777424483307, 0.7635941644562334, 0.7768860353130016, None)\n",
      "Ask: Accuracy: 0.748898678414097 # Scores: (0.5680576254346745, 0.5779516358463728, 0.5717406414457352, None)\n",
      "300\n",
      "Counter({0: 834, 1: 723})\n",
      "Counter({1: 80, 0: 50})\n",
      "Counter({1: 274, 0: 188})\n",
      "Counter({0: 608, 1: 148})\n",
      "Res: Accuracy: 0.7029914529914529 # Scores: (0.7027983539094651, 0.7026315789473685, 0.7026860269014027, None)\n",
      "Wei: Accuracy: 0.6923076923076923 # Scores: (0.6201298701298701, 0.6201298701298701, 0.6201298701298701, None)\n",
      "Bld: Accuracy: 0.8201438848920863 # Scores: (0.834393216746158, 0.7789566755083996, 0.7934129956601866, None)\n",
      "Ask: Accuracy: 0.7577092511013216 # Scores: (0.5752895752895753, 0.5832147937411095, 0.5785654008438819, None)\n",
      "400\n",
      "Counter({0: 834, 1: 723})\n",
      "Counter({1: 80, 0: 50})\n",
      "Counter({1: 274, 0: 188})\n",
      "Counter({0: 608, 1: 148})\n",
      "Res: Accuracy: 0.7008547008547008 # Scores: (0.7006509178673297, 0.7005482456140351, 0.7005867622059334, None)\n",
      "Wei: Accuracy: 0.717948717948718 # Scores: (0.6574074074074074, 0.6655844155844155, 0.6608695652173913, None)\n",
      "Bld: Accuracy: 0.8201438848920863 # Scores: (0.834393216746158, 0.7789566755083996, 0.7934129956601866, None)\n",
      "Ask: Accuracy: 0.7444933920704846 # Scores: (0.5572548028311426, 0.5644381223328592, 0.5599598930481284, None)\n",
      "500\n",
      "Counter({0: 834, 1: 723})\n",
      "Counter({1: 80, 0: 50})\n",
      "Counter({1: 274, 0: 188})\n",
      "Counter({0: 608, 1: 148})\n",
      "Res: Accuracy: 0.7158119658119658 # Scores: (0.7156378600823046, 0.7154605263157894, 0.7155197235819175, None)\n",
      "Wei: Accuracy: 0.717948717948718 # Scores: (0.6574074074074074, 0.6655844155844155, 0.6608695652173913, None)\n",
      "Bld: Accuracy: 0.8201438848920863 # Scores: (0.834393216746158, 0.7789566755083996, 0.7934129956601866, None)\n",
      "Ask: Accuracy: 0.748898678414097 # Scores: (0.5680576254346745, 0.5779516358463728, 0.5717406414457352, None)\n",
      "600\n",
      "Counter({0: 834, 1: 723})\n",
      "Counter({1: 80, 0: 50})\n",
      "Counter({1: 274, 0: 188})\n",
      "Counter({0: 608, 1: 148})\n",
      "Res: Accuracy: 0.7115384615384616 # Scores: (0.711358024691358, 0.7111842105263158, 0.7112418246884127, None)\n",
      "Wei: Accuracy: 0.6923076923076923 # Scores: (0.6201298701298701, 0.6201298701298701, 0.6201298701298701, None)\n",
      "Bld: Accuracy: 0.8201438848920863 # Scores: (0.8418956043956044, 0.7750884173297966, 0.7908768129024493, None)\n",
      "Ask: Accuracy: 0.7533039647577092 # Scores: (0.5785103785103785, 0.5914651493598863, 0.5832677681615526, None)\n",
      "700\n",
      "Counter({0: 834, 1: 723})\n",
      "Counter({1: 80, 0: 50})\n",
      "Counter({1: 274, 0: 188})\n",
      "Counter({0: 608, 1: 148})\n",
      "Res: Accuracy: 0.7115384615384616 # Scores: (0.711344069314713, 0.7112938596491227, 0.7113157113157114, None)\n",
      "Wei: Accuracy: 0.6923076923076923 # Scores: (0.6346153846153846, 0.6477272727272727, 0.6388888888888888, None)\n",
      "Bld: Accuracy: 0.8273381294964028 # Scores: (0.8473570658036678, 0.7847038019451813, 0.8004784688995217, None)\n",
      "Ask: Accuracy: 0.7533039647577092 # Scores: (0.5785103785103785, 0.5914651493598863, 0.5832677681615526, None)\n",
      "800\n",
      "Counter({0: 834, 1: 723})\n",
      "Counter({1: 80, 0: 50})\n",
      "Counter({1: 274, 0: 188})\n",
      "Counter({0: 608, 1: 148})\n",
      "Res: Accuracy: 0.7115384615384616 # Scores: (0.711358024691358, 0.7111842105263158, 0.7112418246884127, None)\n",
      "Wei: Accuracy: 0.6923076923076923 # Scores: (0.6346153846153846, 0.6477272727272727, 0.6388888888888888, None)\n",
      "Bld: Accuracy: 0.8345323741007195 # Scores: (0.8528086910439852, 0.7943191865605659, 0.8099399560073718, None)\n",
      "Ask: Accuracy: 0.7533039647577092 # Scores: (0.5785103785103785, 0.5914651493598863, 0.5832677681615526, None)\n",
      "900\n",
      "Counter({0: 834, 1: 723})\n",
      "Counter({1: 80, 0: 50})\n",
      "Counter({1: 274, 0: 188})\n",
      "Counter({0: 608, 1: 148})\n",
      "Res: Accuracy: 0.7072649572649573 # Scores: (0.7070781893004114, 0.7069078947368421, 0.7069639257949076, None)\n",
      "Wei: Accuracy: 0.6923076923076923 # Scores: (0.6346153846153846, 0.6477272727272727, 0.6388888888888888, None)\n",
      "Bld: Accuracy: 0.8345323741007195 # Scores: (0.8528086910439852, 0.7943191865605659, 0.8099399560073718, None)\n",
      "Ask: Accuracy: 0.7533039647577092 # Scores: (0.5785103785103785, 0.5914651493598863, 0.5832677681615526, None)\n"
     ]
    }
   ],
   "source": [
    "label='Hypertensive disease '\n",
    "asklabel='Hypertensive disease '\n",
    "res_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "wei_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "bld_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "ask_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "for estimators in range (100,1000,100):\n",
    "    print (estimators)\n",
    "    result,result_labels,weighted,weighted_labels,blood,blood_labels,ask,ask_labels=prepareDatasetNoSmote(label,asklabel)\n",
    "    res_acc,res_scores=randomForest(result,result_labels,estimators,\"Result\")\n",
    "    wei_acc,wei_scores=randomForest(weighted,weighted_labels,estimators,\"Weighted\")\n",
    "    blood_acc,blood_scores=randomForest(blood,blood_labels,estimators,\"Blood\")\n",
    "    ask_acc,ask_scores=randomForest(ask,ask_labels,estimators,\"Ask\")\n",
    "    print(\"Res: Accuracy: \" + str(res_acc)+\" # \"+ \"Scores: \"+str(res_scores))\n",
    "    print(\"Wei: Accuracy: \" + str(wei_acc)+\" # \"+ \"Scores: \"+str(wei_scores))\n",
    "    print(\"Bld: Accuracy: \" + str(blood_acc)+\" # \"+ \"Scores: \"+str(blood_scores))\n",
    "    print(\"Ask: Accuracy: \" + str(ask_acc)+\" # \"+ \"Scores: \"+str(ask_scores))\n",
    "    res_Stats=res_Stats.append({'Estimators':estimators,'Accuracy':res_acc,'Precision':res_scores[0],'Recall':res_scores[1],'FScore':res_scores[2]},ignore_index=True)\n",
    "    wei_Stats=wei_Stats.append({'Estimators':estimators,'Accuracy':wei_acc,'Precision':wei_scores[0],'Recall':wei_scores[1],'FScore':wei_scores[2]},ignore_index=True)\n",
    "    bld_Stats=bld_Stats.append({'Estimators':estimators,'Accuracy':blood_acc,'Precision':blood_scores[0],'Recall':blood_scores[1],'FScore':blood_scores[2]},ignore_index=True)\n",
    "    ask_Stats=ask_Stats.append({'Estimators':estimators,'Accuracy':ask_acc,'Precision':ask_scores[0],'Recall':ask_scores[1],'FScore':ask_scores[2]},ignore_index=True)\n",
    "writer = pd.ExcelWriter('Forrest_Stats'+label+'smoteless.xlsx', engine='xlsxwriter')\n",
    "res_Stats.to_excel(writer, sheet_name='Sheet1') \n",
    "wei_Stats.to_excel(writer, sheet_name='Sheet2') \n",
    "bld_Stats.to_excel(writer, sheet_name='Sheet3') \n",
    "ask_Stats.to_excel(writer, sheet_name='Sheet4')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 834, 1: 723})\n",
      "Counter({1: 80, 0: 50})\n",
      "Counter({1: 274, 0: 188})\n",
      "Counter({0: 608, 1: 148})\n",
      "Res: Accuracy: 0.6837606837606838 # Scores: (0.6870343893445707, 0.681688596491228, 0.6806756781677024, None)\n",
      "Wei: Accuracy: 0.7435897435897436 # Scores: (0.6834415584415584, 0.6834415584415584, 0.6834415584415584, None)\n",
      "Bld: Accuracy: 0.7769784172661871 # Scores: (0.7679263565891472, 0.74447391688771, 0.7521426517112453, None)\n",
      "Ask: Accuracy: 0.7929515418502202 # Scores: (0.6177283304246655, 0.615149359886202, 0.6164024017545752, None)\n",
      "200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 834, 1: 723})\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-921e0af3b741>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mblood_feat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimportance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblood\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mblood_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mask_feat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimportance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mask_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mres_acc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mres_scores\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandomForest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mres_feat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mresult_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mestimators\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Result\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0mwei_acc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwei_scores\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandomForest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweighted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mwei_feat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweighted_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mestimators\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Weighted\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mblood_acc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mblood_scores\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandomForest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblood\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mblood_feat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mblood_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mestimators\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Blood\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-ff2ddd00d2e1>\u001b[0m in \u001b[0;36mrandomForest\u001b[1;34m(result, result_labels, estimators, DataSet)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCounter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mestimators\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mpred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0maccuracy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    331\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[1;32m--> 333\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 920\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    921\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[0;32m    117\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'balanced'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    799\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    800\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 801\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m    802\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    803\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    274\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m             min_weight_leaf = (self.min_weight_fraction_leaf *\n\u001b[1;32m--> 276\u001b[1;33m                                np.sum(sample_weight))\n\u001b[0m\u001b[0;32m    277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_impurity_split\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[1;34m(a, axis, dtype, out, keepdims, initial)\u001b[0m\n\u001b[0;32m   2074\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2075\u001b[0m     return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n\u001b[1;32m-> 2076\u001b[1;33m                           initial=initial)\n\u001b[0m\u001b[0;32m   2077\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2078\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     84\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "label='Hypertensive disease '\n",
    "asklabel='Hypertensive disease '\n",
    "res_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "wei_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "bld_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "ask_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "for estimators in range (100,1000,100):\n",
    "    print (estimators)\n",
    "    result,result_labels,weighted,weighted_labels,blood,blood_labels,ask,ask_labels=prepareDatasetNoSmote(label,asklabel)\n",
    "    res_feat=importance(result,result_labels)\n",
    "    wei_feat=importance(weighted,weighted_labels)\n",
    "    blood_feat=importance(blood,blood_labels)\n",
    "    ask_feat=importance(ask,ask_labels)\n",
    "    res_acc,res_scores=randomForest(pd.DataFrame(result)[res_feat],result_labels,estimators,\"Result\")\n",
    "    wei_acc,wei_scores=randomForest(pd.DataFrame(weighted)[wei_feat],weighted_labels,estimators,\"Weighted\")\n",
    "    blood_acc,blood_scores=randomForest(pd.DataFrame(blood)[blood_feat],blood_labels,estimators,\"Blood\")\n",
    "    ask_acc,ask_scores=randomForest(pd.DataFrame(ask)[ask_feat],ask_labels,estimators,\"Ask\")\n",
    "    print(\"Res: Accuracy: \" + str(res_acc)+\" # \"+ \"Scores: \"+str(res_scores))\n",
    "    print(\"Wei: Accuracy: \" + str(wei_acc)+\" # \"+ \"Scores: \"+str(wei_scores))\n",
    "    print(\"Bld: Accuracy: \" + str(blood_acc)+\" # \"+ \"Scores: \"+str(blood_scores))\n",
    "    print(\"Ask: Accuracy: \" + str(ask_acc)+\" # \"+ \"Scores: \"+str(ask_scores))\n",
    "    res_Stats=res_Stats.append({'Estimators':estimators,'Accuracy':res_acc,'Precision':res_scores[0],'Recall':res_scores[1],'FScore':res_scores[2]},ignore_index=True)\n",
    "    wei_Stats=wei_Stats.append({'Estimators':estimators,'Accuracy':wei_acc,'Precision':wei_scores[0],'Recall':wei_scores[1],'FScore':wei_scores[2]},ignore_index=True)\n",
    "    bld_Stats=bld_Stats.append({'Estimators':estimators,'Accuracy':blood_acc,'Precision':blood_scores[0],'Recall':blood_scores[1],'FScore':blood_scores[2]},ignore_index=True)\n",
    "    ask_Stats=ask_Stats.append({'Estimators':estimators,'Accuracy':ask_acc,'Precision':ask_scores[0],'Recall':ask_scores[1],'FScore':ask_scores[2]},ignore_index=True)\n",
    "\n",
    "writer = pd.ExcelWriter('Forrest_Stats'+label+'importancesmoteless.xlsx', engine='xlsxwriter')\n",
    "res_Stats.to_excel(writer, sheet_name='Sheet1') \n",
    "wei_Stats.to_excel(writer, sheet_name='Sheet2') \n",
    "bld_Stats.to_excel(writer, sheet_name='Sheet3') \n",
    "ask_Stats.to_excel(writer, sheet_name='Sheet4')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier Function 10-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average(scores):\n",
    "    FScore=0\n",
    "    Recall=0\n",
    "    Precision=0\n",
    "\n",
    "    for i in scores:\n",
    "        Precision+=i[0]\n",
    "        Recall+=i[1]\n",
    "        FScore+=i[2]\n",
    "    return (Precision/10,Recall/10,FScore/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomForest10Fold(result,result_labels,estimators,DataSet):\n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn.metrics import f1_score\n",
    "    from collections import Counter\n",
    "    kf = KFold(n_splits=10)\n",
    "\n",
    "    accuracy=[]\n",
    "\n",
    "    scores_rf=[]\n",
    "    print(Counter(result_labels))\n",
    "    count = 1\n",
    "    for train_index, test_index in kf.split(result):\n",
    "        X_train, X_test, Y_train, Y_test = result[train_index], result[test_index], result_labels[train_index],result_labels[test_index]\n",
    "        clf = RandomForestClassifier(n_estimators=estimators, max_depth=2,random_state=0)\n",
    "        clf.fit(X_train, Y_train)\n",
    "        pred=clf.predict(X_test)\n",
    "        accuracy.append(accuracy_score(Y_test, pred))\n",
    "        scores_rf.append(precision_recall_fscore_support(Y_test,pred, average='macro'))\n",
    "        \n",
    "        #print(str(count)+DataSet)\n",
    "        #print(f1_score(Y_test, pred, average='micro'))\n",
    "        count+=1\n",
    "        #print (pred)\n",
    "        #print(classification_report(Y_test,pred,labels=[0,1]))\n",
    "    accuracy = np.mean(accuracy,axis=0)   \n",
    "    return accuracy,average(scores_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomForest10FoldNotSmote(result,result_labels,estimators,DataSet):\n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn.metrics import f1_score\n",
    "    from collections import Counter\n",
    "    kf = KFold(n_splits=10)\n",
    "\n",
    "    accuracy=[]\n",
    "\n",
    "    scores_rf=[]\n",
    "    print(Counter(result_labels))\n",
    "    count = 1\n",
    "    for train_index, test_index in kf.split(result):\n",
    "        X_train, X_test, Y_train, Y_test = result.iloc[train_index], result.iloc[test_index], result_labels.iloc[train_index],result_labels.iloc[test_index]\n",
    "        clf = RandomForestClassifier(n_estimators=estimators, max_depth=2,random_state=0)\n",
    "        clf.fit(X_train, Y_train)\n",
    "        pred=clf.predict(X_test)\n",
    "        accuracy.append(accuracy_score(Y_test, pred))\n",
    "        scores_rf.append(precision_recall_fscore_support(Y_test,pred, average='macro'))\n",
    "        \n",
    "        #print(str(count)+DataSet)\n",
    "        #print(f1_score(Y_test, pred, average='micro'))\n",
    "        count+=1\n",
    "        #print (pred)\n",
    "        #print(classification_report(Y_test,pred,labels=[0,1]))\n",
    "    accuracy = np.mean(accuracy,axis=0)   \n",
    "    return accuracy,average(scores_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with 10-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 997, 1: 997})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 93, 1: 93})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 325, 0: 325})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 562, 1: 562})\n",
      "Res: Accuracy: 0.8055201005025123 # Scores: (0.7428154281209286, 0.7443423105940068, 0.7115928683933681)\n",
      "Wei: Accuracy: 0.775438596491228 # Scores: (0.6733820346320345, 0.6771764346764347, 0.6546866670441457)\n",
      "Bld: Accuracy: 0.7892307692307692 # Scores: (0.7012252754673653, 0.7383487606529205, 0.6910037378794464)\n",
      "Ask: Accuracy: 0.9039902022756005 # Scores: (0.8845130565473553, 0.9217322844668475, 0.8819805552784356)\n",
      "Counter({0: 997, 1: 997})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 93, 1: 93})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 325, 0: 325})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 562, 1: 562})\n",
      "Res: Accuracy: 0.7999798994974875 # Scores: (0.7429409044698072, 0.7422556441670094, 0.7102791146027869)\n",
      "Wei: Accuracy: 0.775438596491228 # Scores: (0.6708044733044732, 0.673009768009768, 0.6529434837568449)\n",
      "Bld: Accuracy: 0.8015384615384615 # Scores: (0.719288099248086, 0.7547945098030835, 0.7080904675107481)\n",
      "Ask: Accuracy: 0.9039902022756005 # Scores: (0.8845130565473553, 0.9217322844668475, 0.8819805552784356)\n",
      "Counter({0: 997, 1: 997})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 93, 1: 93})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 325, 0: 325})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 562, 1: 562})\n",
      "Res: Accuracy: 0.8090050251256281 # Scores: (0.7488003037048016, 0.7503452351741823, 0.7187804371092665)\n",
      "Wei: Accuracy: 0.7862573099415203 # Scores: (0.6772709235209236, 0.6841208791208792, 0.6613697214975987)\n",
      "Bld: Accuracy: 0.8076923076923078 # Scores: (0.7189608257596062, 0.755184304937656, 0.7079329969710683)\n",
      "Ask: Accuracy: 0.9039902022756005 # Scores: (0.8845130565473553, 0.9217322844668475, 0.8819805552784356)\n",
      "Counter({0: 997, 1: 997})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 93, 1: 93})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 325, 0: 325})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 562, 1: 562})\n",
      "Res: Accuracy: 0.8165251256281406 # Scores: (0.7529970915285316, 0.7566557666621108, 0.7252567677693073)\n",
      "Wei: Accuracy: 0.7812865497076023 # Scores: (0.6693939393939394, 0.6794810744810745, 0.653285287815339)\n",
      "Bld: Accuracy: 0.8092307692307692 # Scores: (0.7181126370693468, 0.7601278871520376, 0.7055870985558003)\n",
      "Ask: Accuracy: 0.9039902022756005 # Scores: (0.8845130565473553, 0.9217322844668475, 0.8819805552784356)\n",
      "Counter({0: 997, 1: 997})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 93, 1: 93})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 325, 0: 325})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 562, 1: 562})\n",
      "Res: Accuracy: 0.8145150753768844 # Scores: (0.7530652500194186, 0.7555626489261876, 0.7246436826314789)\n",
      "Wei: Accuracy: 0.7812865497076023 # Scores: (0.6693939393939394, 0.6794810744810745, 0.653285287815339)\n",
      "Bld: Accuracy: 0.8046153846153847 # Scores: (0.7191138910574472, 0.757556812508704, 0.7071154315349972)\n",
      "Ask: Accuracy: 0.9039902022756005 # Scores: (0.8845130565473553, 0.9217322844668475, 0.8819805552784356)\n",
      "Counter({0: 997, 1: 997})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 93, 1: 93})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 325, 0: 325})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 562, 1: 562})\n",
      "Res: Accuracy: 0.8130075376884423 # Scores: (0.7508242169119981, 0.7534232053492602, 0.7237976985627668)\n",
      "Wei: Accuracy: 0.7757309941520467 # Scores: (0.6693939393939394, 0.6767032967032968, 0.6515807423607936)\n",
      "Bld: Accuracy: 0.8092307692307694 # Scores: (0.7190153695627406, 0.75747574068592, 0.7088111508009108)\n",
      "Ask: Accuracy: 0.9039902022756005 # Scores: (0.8845130565473553, 0.9217322844668475, 0.8819805552784356)\n",
      "Counter({0: 997, 1: 997})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 93, 1: 93})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 325, 0: 325})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 562, 1: 562})\n",
      "Res: Accuracy: 0.8150150753768844 # Scores: (0.7505385800984646, 0.7542809173286138, 0.7250290136370507)\n",
      "Wei: Accuracy: 0.7809941520467836 # Scores: (0.673320707070707, 0.6805494505494506, 0.6564979266258038)\n",
      "Bld: Accuracy: 0.803076923076923 # Scores: (0.7132391031462303, 0.752498213955328, 0.7030670432609399)\n",
      "Ask: Accuracy: 0.9039902022756005 # Scores: (0.8845130565473553, 0.9217322844668475, 0.8819805552784356)\n",
      "Counter({0: 997, 1: 997})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 93, 1: 93})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 325, 0: 325})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 562, 1: 562})\n",
      "Res: Accuracy: 0.8165201005025124 # Scores: (0.7527065672365418, 0.7560981097715596, 0.7258035358826243)\n",
      "Wei: Accuracy: 0.7865497076023392 # Scores: (0.673320707070707, 0.6833272283272284, 0.6582024720803492)\n",
      "Bld: Accuracy: 0.8061538461538461 # Scores: (0.713631029452056, 0.7539893941699125, 0.7040383797616977)\n",
      "Ask: Accuracy: 0.9039902022756005 # Scores: (0.8845130565473553, 0.9217322844668475, 0.8819805552784356)\n",
      "Counter({0: 997, 1: 997})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 93, 1: 93})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 325, 0: 325})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 562, 1: 562})\n",
      "Res: Accuracy: 0.8170251256281407 # Scores: (0.7516516495523513, 0.7557980253895977, 0.7259090743443609)\n",
      "Wei: Accuracy: 0.7918128654970761 # Scores: (0.6772709235209236, 0.6868986568986569, 0.6630742669521441)\n",
      "Bld: Accuracy: 0.8046153846153846 # Scores: (0.7143991406103474, 0.7536492530448877, 0.7046285689192118)\n",
      "Ask: Accuracy: 0.9039902022756005 # Scores: (0.8845130565473553, 0.9217322844668475, 0.8819805552784356)\n"
     ]
    }
   ],
   "source": [
    "label='ADRCount'\n",
    "asklabel='ADRCount'\n",
    "\n",
    "res_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "wei_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "bld_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "ask_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "for estimators in range (100,1000,100):\n",
    "    result,result_labels,weighted,weighted_labels,blood,blood_labels,ask,ask_labels=prepareDataset(label,asklabel)\n",
    "    res_acc,res_scores=randomForest10Fold(result,result_labels,estimators,\"Result\")\n",
    "    wei_acc,wei_scores=randomForest10Fold(weighted,weighted_labels,estimators,\"Weighted\")\n",
    "    blood_acc,blood_scores=randomForest10Fold(blood,blood_labels,estimators,\"Blood\")\n",
    "    ask_acc,ask_scores=randomForest10Fold(ask,ask_labels,1000,\"Ask\")\n",
    "    print(\"Res: Accuracy: \" + str(res_acc)+\" # \"+ \"Scores: \"+str(res_scores))\n",
    "    print(\"Wei: Accuracy: \" + str(wei_acc)+\" # \"+ \"Scores: \"+str(wei_scores))\n",
    "    print(\"Bld: Accuracy: \" + str(blood_acc)+\" # \"+ \"Scores: \"+str(blood_scores))\n",
    "    print(\"Ask: Accuracy: \" + str(ask_acc)+\" # \"+ \"Scores: \"+str(ask_scores))\n",
    "    res_Stats=res_Stats.append({'Estimators':estimators,'Accuracy':res_acc,'Precision':res_scores[0],'Recall':res_scores[1],'FScore':res_scores[2]},ignore_index=True)\n",
    "    wei_Stats=wei_Stats.append({'Estimators':estimators,'Accuracy':wei_acc,'Precision':wei_scores[0],'Recall':wei_scores[1],'FScore':wei_scores[2]},ignore_index=True)\n",
    "    bld_Stats=bld_Stats.append({'Estimators':estimators,'Accuracy':blood_acc,'Precision':blood_scores[0],'Recall':blood_scores[1],'FScore':blood_scores[2]},ignore_index=True)\n",
    "    ask_Stats=ask_Stats.append({'Estimators':estimators,'Accuracy':ask_acc,'Precision':ask_scores[0],'Recall':ask_scores[1],'FScore':ask_scores[2]},ignore_index=True)\n",
    "res_Stats.to_excel('ForrestFoldresult_Stats'+label+'.xlsx') \n",
    "wei_Stats.to_excel('ForrestFoldweight_Stats'+label+'.xlsx') \n",
    "bld_Stats.to_excel('ForrestFoldblood_Stats'+label+'.xlsx') \n",
    "ask_Stats.to_excel('ForrestFoldask_Stats'+asklabel+'.xlsx') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 997, 0: 560})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 93, 0: 37})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 325, 0: 137})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 562, 0: 194})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Res: Accuracy: 0.6423159636062862 # Scores: (0.3569986842567488, 0.5055481874447392, 0.40097391324841175)\n",
      "Wei: Accuracy: 0.7461538461538462 # Scores: (0.5682692307692307, 0.5425, 0.4926513269339356)\n",
      "Bld: Accuracy: 0.7031914893617021 # Scores: (0.35159574468085114, 0.5, 0.41193330712998666)\n",
      "Ask: Accuracy: 0.7431929824561403 # Scores: (0.37159649122807015, 0.5, 0.4245288434175614)\n",
      "Counter({1: 997, 0: 560})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 93, 0: 37})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 325, 0: 137})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 562, 0: 194})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Res: Accuracy: 0.6416708023159636 # Scores: (0.3543592519193299, 0.5042661361626879, 0.39883028666261955)\n",
      "Wei: Accuracy: 0.7615384615384616 # Scores: (0.6245629370629371, 0.5675, 0.5300755693581781)\n",
      "Bld: Accuracy: 0.7031914893617021 # Scores: (0.35159574468085114, 0.5, 0.41193330712998666)\n",
      "Ask: Accuracy: 0.7431929824561403 # Scores: (0.37159649122807015, 0.5, 0.4245288434175614)\n",
      "Counter({1: 997, 0: 560})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 93, 0: 37})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 325, 0: 137})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 562, 0: 194})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Res: Accuracy: 0.6403804797353184 # Scores: (0.3201902398676592, 0.5, 0.3897269578934828)\n",
      "Wei: Accuracy: 0.7461538461538462 # Scores: (0.5682692307692307, 0.5425, 0.4926513269339356)\n",
      "Bld: Accuracy: 0.7031914893617021 # Scores: (0.35159574468085114, 0.5, 0.41193330712998666)\n",
      "Ask: Accuracy: 0.7431929824561403 # Scores: (0.37159649122807015, 0.5, 0.4245288434175614)\n",
      "Counter({1: 997, 0: 560})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 93, 0: 37})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 325, 0: 137})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 562, 0: 194})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Res: Accuracy: 0.6403804797353184 # Scores: (0.3201902398676592, 0.5, 0.3897269578934828)\n",
      "Wei: Accuracy: 0.7461538461538462 # Scores: (0.5682692307692307, 0.5425, 0.4926513269339356)\n",
      "Bld: Accuracy: 0.7031914893617021 # Scores: (0.35159574468085114, 0.5, 0.41193330712998666)\n",
      "Ask: Accuracy: 0.7431929824561403 # Scores: (0.37159649122807015, 0.5, 0.4245288434175614)\n",
      "Counter({1: 997, 0: 560})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 93, 0: 37})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 325, 0: 137})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 562, 0: 194})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Res: Accuracy: 0.6403804797353184 # Scores: (0.3201902398676592, 0.5, 0.3897269578934828)\n",
      "Wei: Accuracy: 0.7461538461538462 # Scores: (0.5682692307692307, 0.5425, 0.4926513269339356)\n",
      "Bld: Accuracy: 0.7031914893617021 # Scores: (0.35159574468085114, 0.5, 0.41193330712998666)\n",
      "Ask: Accuracy: 0.7431929824561403 # Scores: (0.37159649122807015, 0.5, 0.4245288434175614)\n",
      "Counter({1: 997, 0: 560})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 93, 0: 37})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 325, 0: 137})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 562, 0: 194})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Res: Accuracy: 0.6403804797353184 # Scores: (0.3201902398676592, 0.5, 0.3897269578934828)\n",
      "Wei: Accuracy: 0.7461538461538462 # Scores: (0.5682692307692307, 0.5425, 0.4926513269339356)\n",
      "Bld: Accuracy: 0.7031914893617021 # Scores: (0.35159574468085114, 0.5, 0.41193330712998666)\n",
      "Ask: Accuracy: 0.7431929824561403 # Scores: (0.37159649122807015, 0.5, 0.4245288434175614)\n",
      "Counter({1: 997, 0: 560})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 93, 0: 37})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 325, 0: 137})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 562, 0: 194})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Res: Accuracy: 0.6403804797353184 # Scores: (0.3201902398676592, 0.5, 0.3897269578934828)\n",
      "Wei: Accuracy: 0.7461538461538462 # Scores: (0.5682692307692307, 0.5425, 0.4926513269339356)\n",
      "Bld: Accuracy: 0.7031914893617021 # Scores: (0.35159574468085114, 0.5, 0.41193330712998666)\n",
      "Ask: Accuracy: 0.7431929824561403 # Scores: (0.37159649122807015, 0.5, 0.4245288434175614)\n",
      "Counter({1: 997, 0: 560})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 93, 0: 37})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 325, 0: 137})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 562, 0: 194})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Res: Accuracy: 0.6403804797353184 # Scores: (0.3201902398676592, 0.5, 0.3897269578934828)\n",
      "Wei: Accuracy: 0.7461538461538462 # Scores: (0.5682692307692307, 0.5425, 0.4926513269339356)\n",
      "Bld: Accuracy: 0.7031914893617021 # Scores: (0.35159574468085114, 0.5, 0.41193330712998666)\n",
      "Ask: Accuracy: 0.7431929824561403 # Scores: (0.37159649122807015, 0.5, 0.4245288434175614)\n",
      "Counter({1: 997, 0: 560})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 93, 0: 37})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 325, 0: 137})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 562, 0: 194})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Res: Accuracy: 0.6403804797353184 # Scores: (0.3201902398676592, 0.5, 0.3897269578934828)\n",
      "Wei: Accuracy: 0.7461538461538462 # Scores: (0.5682692307692307, 0.5425, 0.4926513269339356)\n",
      "Bld: Accuracy: 0.7031914893617021 # Scores: (0.35159574468085114, 0.5, 0.41193330712998666)\n",
      "Ask: Accuracy: 0.7431929824561403 # Scores: (0.37159649122807015, 0.5, 0.4245288434175614)\n"
     ]
    }
   ],
   "source": [
    "label='ADRCount'\n",
    "asklabel='ADRCount'\n",
    "\n",
    "res_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "wei_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "bld_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "ask_Stats = pd.DataFrame(columns = ['Estimators' , 'Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "for estimators in range (100,1000,100):\n",
    "    result,result_labels,weighted,weighted_labels,blood,blood_labels,ask,ask_labels=prepareDatasetNoSmote(label,asklabel)\n",
    "    res_acc,res_scores=randomForest10FoldNotSmote(result,result_labels,estimators,\"Result\")\n",
    "    wei_acc,wei_scores=randomForest10FoldNotSmote(weighted,weighted_labels,estimators,\"Weighted\")\n",
    "    blood_acc,blood_scores=randomForest10FoldNotSmote(blood,blood_labels,estimators,\"Blood\")\n",
    "    ask_acc,ask_scores=randomForest10FoldNotSmote(ask,ask_labels,1000,\"Ask\")\n",
    "    print(\"Res: Accuracy: \" + str(res_acc)+\" # \"+ \"Scores: \"+str(res_scores))\n",
    "    print(\"Wei: Accuracy: \" + str(wei_acc)+\" # \"+ \"Scores: \"+str(wei_scores))\n",
    "    print(\"Bld: Accuracy: \" + str(blood_acc)+\" # \"+ \"Scores: \"+str(blood_scores))\n",
    "    print(\"Ask: Accuracy: \" + str(ask_acc)+\" # \"+ \"Scores: \"+str(ask_scores))\n",
    "    res_Stats=res_Stats.append({'Estimators':estimators,'Accuracy':res_acc,'Precision':res_scores[0],'Recall':res_scores[1],'FScore':res_scores[2]},ignore_index=True)\n",
    "    wei_Stats=wei_Stats.append({'Estimators':estimators,'Accuracy':wei_acc,'Precision':wei_scores[0],'Recall':wei_scores[1],'FScore':wei_scores[2]},ignore_index=True)\n",
    "    bld_Stats=bld_Stats.append({'Estimators':estimators,'Accuracy':blood_acc,'Precision':blood_scores[0],'Recall':blood_scores[1],'FScore':blood_scores[2]},ignore_index=True)\n",
    "    ask_Stats=ask_Stats.append({'Estimators':estimators,'Accuracy':ask_acc,'Precision':ask_scores[0],'Recall':ask_scores[1],'FScore':ask_scores[2]},ignore_index=True)\n",
    "res_Stats.to_excel('ForrestFoldresult_Stats'+label+'smoteless.xlsx') \n",
    "wei_Stats.to_excel('ForrestFoldweight_Stats'+label+'smoteless.xlsx') \n",
    "bld_Stats.to_excel('ForrestFoldblood_Stats'+label+'smoteless.xlsx') \n",
    "ask_Stats.to_excel('ForrestFoldask_Stats'+asklabel+'smoteless.xlsx') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ask_scores[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Classifier Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM(result,result_labels,DataSet):\n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn.metrics import f1_score\n",
    "    from collections import Counter\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(result, result_labels, test_size=0.30, random_state=42)\n",
    "    print(Counter(result_labels))\n",
    "    clf = SVC(gamma='auto')\n",
    "    clf.fit(X_train, Y_train)\n",
    "    pred=clf.predict(X_test)\n",
    "    accuracy=(accuracy_score(Y_test, pred))\n",
    "    #print (accuracy)\n",
    "    scores_rf=(precision_recall_fscore_support(Y_test,pred, average='macro'))\n",
    "    #print(DataSet)\n",
    "    #print (pred)\n",
    "    #print(classification_report(Y_test,pred,labels=[0,1,2]))\n",
    "        \n",
    "    return accuracy,scores_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 1168, 1: 1168})\n",
      "Counter({0: 89, 1: 89})\n",
      "Counter({0: 334, 1: 334})\n",
      "Counter({0: 590, 1: 590})\n",
      "Res: Accuracy: 0.7646219686162625 # Scores: (0.8020652566883586, 0.7726468044836757, 0.760312082310155, None)\n",
      "Wei: Accuracy: 0.7407407407407407 # Scores: (0.7941176470588236, 0.7941176470588236, 0.7407407407407407, None)\n",
      "Bld: Accuracy: 0.7562189054726368 # Scores: (0.7579443892750745, 0.7574841395717684, 0.756194766938139, None)\n",
      "Ask: Accuracy: 0.7288135593220338 # Scores: (0.7403568617160851, 0.7348115867726224, 0.728110599078341, None)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "label='Pain'\n",
    "asklabel='Pain'\n",
    "Stats = pd.DataFrame(columns = ['Dataset','Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "\n",
    "\n",
    "result,result_labels,weighted,weighted_labels,blood,blood_labels,ask,ask_labels=prepareDataset(label,asklabel)\n",
    "res_acc,res_scores=SVM(result,result_labels,\"Result\")\n",
    "wei_acc,wei_scores=SVM(weighted,weighted_labels,\"Weighted\")\n",
    "blood_acc,blood_scores=SVM(blood,blood_labels,\"Blood\")\n",
    "ask_acc,ask_scores=SVM(ask,ask_labels,\"Ask\")\n",
    "print(\"Res: Accuracy: \" + str(res_acc)+\" # \"+ \"Scores: \"+str(res_scores))\n",
    "print(\"Wei: Accuracy: \" + str(wei_acc)+\" # \"+ \"Scores: \"+str(wei_scores))\n",
    "print(\"Bld: Accuracy: \" + str(blood_acc)+\" # \"+ \"Scores: \"+str(blood_scores))\n",
    "print(\"Ask: Accuracy: \" + str(ask_acc)+\" # \"+ \"Scores: \"+str(ask_scores))\n",
    "Stats=Stats.append({'Dataset':\"Complete\",'Accuracy':res_acc,'Precision':res_scores[0],'Recall':res_scores[1],'FScore':res_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Weighted\",'Accuracy':wei_acc,'Precision':wei_scores[0],'Recall':wei_scores[1],'FScore':wei_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Blood\",'Accuracy':blood_acc,'Precision':blood_scores[0],'Recall':blood_scores[1],'FScore':blood_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"AskAPatient\",'Accuracy':ask_acc,'Precision':ask_scores[0],'Recall':ask_scores[1],'FScore':ask_scores[2]},ignore_index=True)\n",
    "#Stats.to_excel('SVMresult_Stats'+label+'.xlsx') \n",
    "\n",
    "plotResult(label+\" SVM With Smote\",Stats,Stats,Stats,Stats,0,1,2,3)\n",
    "\n",
    "import os.path\n",
    "if not os.path.exists('SVM'+'.xlsx'):\n",
    "    writer = pd.ExcelWriter('SVM'+'.xlsx', engine = 'xlsxwriter')\n",
    "\n",
    "    writer.save()\n",
    "    writer.close()\n",
    "writer = pd.ExcelWriter('SVM'+'.xlsx', engine='openpyxl')\n",
    "book = load_workbook('SVM'+'.xlsx')\n",
    "writer.book = book\n",
    "writer.sheets = dict((ws.title, ws) for ws in book.worksheets)\n",
    "\n",
    "Stats.to_excel(writer, sheet_name=label)\n",
    "writer.save()\n",
    "writer.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 2, 3, 6], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 2, 3, 4, 5, 7, 8, 17], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 2, 3, 5, 8], dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 6], dtype='int64')\n",
      "Counter({1: 834, 0: 834})\n",
      "Counter({1: 80, 0: 80})\n",
      "Counter({1: 274, 0: 274})\n",
      "Counter({0: 608, 1: 608})\n",
      "Res: Accuracy: 0.688622754491018 # Scores: (0.688735650510204, 0.6886454183266932, 0.6885917378554124, None)\n",
      "Wei: Accuracy: 0.75 # Scores: (0.78125, 0.75, 0.7428571428571429, None)\n",
      "Bld: Accuracy: 0.7272727272727273 # Scores: (0.7319230769230769, 0.7221485411140584, 0.7223364870423694, None)\n",
      "Ask: Accuracy: 0.7315068493150685 # Scores: (0.7546895724120508, 0.7443939393939394, 0.7304364864050159, None)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEuCAYAAADbW4YFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XmYFeWZ/vHvTSMoRImOHQMCyiRERdnBoATBqIjRgCESJUyijMafY9CZmESJo4waM2M2Y1SMYWYMiHE3GibBDSOuqDQRRdkkioIQg8EFF0Ts5/dHVbfFoTe0i64D9+e6ztW1vPXWc+pUn6fet+pUKSIwMzMrmlYtHYCZmVldnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKCs7Ei6WtL5W2E9UyVdnA4PkbQk73VurySNk3RPA/OHSVq5NWOylucEVcYkLZd0eMm0kyQ93ELxzJZ0St7riYjTIuKHea+nZJ0PRcQ+W3OdzUXSyZIWS1on6RVJf5S0s6QfSHqwjvK7S9og6YB0fwpJl5aUOTadPrWedS6R9LXM+OC0fOm0tyS1jojfRsTwzLyQ9NmP8Z73l3SPpNckvS5pnqQvfdT6GliPE2eOnKDsY1PC+1IBSRoK/CcwNiJ2BvYDbk5nTwcOltStZLETgAUR8Uw6/hfgeEmtM2W+CSxtYNUPAkMz44cAi+uY9mhEbNyCt9RU/wfcC+wBfAo4E3gzh/VYjvylsg2T9H1Jt5VMu0LSZenwbEn/JekJSW9I+r2k3TJlB0l6ND0CfUrSsMy82ZJ+JOkR4B2SL7shwJXpUfGVabl9Jd0raW0dR9VTJU1Oj+jXSXpc0mfSeZL0C0l/S2N7WtIBmeVqut4WSTomU2drSa9K6tfYe6hje/WV9Oc0lpuAHTPzNjlSlnSOpJfTskskHZZObyVpoqS/SPq7pJtLtuktkv6avqcHJe2fmfclSQvTOl+W9L3MvGMkzU/fx6OSetX3PkoMBOZExJMAEbE2IqZFxLqIWAn8CfhGyTLfBKZlxv8KLACOTGPZDTgYmNHAeh8kSUA1hgA/rmPag2mdtS3/TKvuqXRfOr5mAUnfTfeJ1ZLG17ViSbsD3YD/jogN6euRiKipf5iklZLOztR1bLr9l6b76rmZ+tpKukzSqvR1WTqtPXAn0CmN8y1JnRrbB2wLRIRfZfoClgOHl0w7CXg4He4IvA18Mh1vDfwN6J+OzwZeBg4A2gO3Adel8/YE/g58ieRA5oh0vDKz7EvA/mm9O6TTTsnE0h5YAYxPy/QDXgX2T+dPBdYCB6bzfwvcmM47EpgHfBIQyZF/x8xyF6fDk4DfZtZ5NLC4Ke+hZLu1AV4EvpO+l+OA9zPrGQasTIf3Sd9Xp3R8b+Az6fC/AY8BnYG2wK+BGzLr+Wdg53TeZcD8zLzVwJB0eFegXzrcL/3cPg9UACemn33bJuwjQ4B3gQuBwaXLAOOA5zLj+wAbMp/zScDDwNeBm9Jpp6fv62Jgaj3r7QpUA7ul2/5vwE7pdquZ9jpwSOl+m44H8NnM+DBgI3BR+vl8ieTAaNc61i3gOeAPwLHAHiXza+qalNb1LWANcH362ewPrAf+MS1/UfqZfgqoBB4Ffli6X2Tqb3Af8GsLvuNaOgC/PsaHl3xJvZX+o9e83in5R78T+FY6fAywMDNvNnBJZrxH+uVUAZwDTC9Z393AiZllLyqZP5tNE9TxwEMlZX4N/Ec6PBX4n8y8L/FhcvkiSRfSIKBVSR1T+TBxfBZYB7RLx38LTEqHG3wPJdMPAVYBykx7lLoT1GdJvnAPB3YoqWcRcFhmvCNJomtdxzo/SfJF3CEdfwn4f8AuJeV+VfOFmJm2BBjaxP3kKJIur9fT/eVSoCKd146k6+vgdPxHwO8zy55EkqB2Al4BOpB8+Q6mgQSV2T9HAX2BR9JpN2amrSdNmDQtQb2b3Y7pZzConnV3Bq4k6Z6sJmmpdS+pq2Yb7Jyu7/OZ5ecBx6bDfwG+lJl3JLC8dL/4KPuAXw2/3MVX/o6NiE/WvEiObrOmAf+UDv8TSVdc1orM8IskR5S7A3sBY9IupdclvQ58geSfra5l67IX8PmSOsYBn86U+Wtm+B3gEwAR8SeSL5jJwCuSpkjapXQFEbGM5Avhy5LaASNJjoRr1t/Ye6jRCXg50m+UzPbYTLrOfwMuAP4m6UZJnTLrvD2zvkXAB8AekiokXZJ2/bxJ8gUOyfYG+CpJkn5R0gOSDsrU+d2S99EljblREXFnRHyZpOUyiiQZnJLOewe4BfimJJF8PtPqqONd4I/AecDuEfFIE1Zd0813CPBQOu3hzLTHI+K9pryH1N9j0/NVtftLHfGujIgJEfEZku33NnBtSV0fpMPvpn9fycx/N1N3JzbdF16k4W1f7z7QwDJWByeobd8dQK/0/M0xJC2MrC6Z4a4kR3qvkiSf6dnkFxHtI+KSTPnSW+GXjq8AHiip4xMR8S9NCTwiLo+I/iRdLp8Dvl9P0RuAsSRfvgvTBFKz/sbeQ43VwJ7pl3SNrg3Edn1EfIHkyyhIzq/UrPOoknXuGBEvk3STjSJpeXUg6RqEpEuKiJgbEaNIupLu4MOLGVYAPyqps11E3FBffPXEXB0R95GcdzogM2sa8DWSLtCdSbrG6nIt8F02P8ipT02CGsKHCeqhzLTNriDMQ0SsIDnQOaCxsvVYRfI51+iaToPN93loeB+wLeAEtY2LiPXArSStiici4qWSIv8kqUfa+rgIuDU9sryOpFVyZHrkv2N6crlzA6t7BfjHzPgfgM9J+oakHdLXQEn7NRZ3Wu7zknYgOfpdT3IUWpcbgeHAv/Bh64ktfA9zSM5LnKnkQovRJOfG6optH0lflNQ2jevdTGxXAz+StFdatlLSqHTezsB7JOfB2pFcXVdTZxslvwXqEBHvk3S71dT538Bp6faQpPaSjpa0cz3bIxvrKEknSNo1XfZAkivpHssUe4ik+28KyTnADfVU9wBJEruisfWmHiTpyhsK1LS4FpBcwHAoDSeo0n2pydL3eqGkz6YXLOxOcu7vscaWrccNwHnpZ7k7ybmr6zJx/oOkDpnyDe0DtgWcoLYP04Ce1H3kO53knM5fSa5aOxNqjzpHAeeSnEBeQdKCaWif+SVwnJLfnlweEetIEscJJEecfyVpabRtQsy7kHwxv0bSpfJ34Gd1FYyI1SQJ5mDgpsz0Jr+H9Et5NEn312sk589+V09sbYFLSFqafyVp8dRc9fVLkqvb7pG0juRL8fPpvGvT9/IysJDNvzC/ASxPu/9OI+2ajYgqkhP5V6axLUvjbIrX0mWfI0l61wE/jYjalnTarXktSSvh2roqqSkXEfdFxNqmrDgilpKcJ1odEa+n06qBJ0g+30cbWPwCYFraTfa1BsrVZQNJ63QWyXt+huTA4KQtrKfGxUAV8DRJgv1zOo2IWEySwJ5PY+1Ew/uAbQFt2uVu2yJJXUl+g/LpiHgzM302yVV7/9NSsZmZ1cctqG2ckh/QnkXSdeMfKppZ2WjdeBErV+kPCV8h6VYa0cLhmJltEXfxmZlZIbmLz8zMCskJyszMCqnszkHtvvvusffee7d0GGZm9hHNmzfv1YiobKxc2SWovffem6qqqpYOw8zMPiJJdd5GrFSuXXySRih5FMEySRPrmN9V0v2SnlTyOIVmf6CYmZmVp9wSlKQKkvtfHUVyl+yxknqUFDsPuDki+pLcbeCqvOIxM7PykmcL6kBgWUQ8n95GpuY2+1lBcssTSG6euQozMzPyPQe1J5s+jmElm9+P6gKS+1WdQfJwu8NzjMfMzMpIni0o1TGt9FfBY0keeNaZ5Dk409Nb82xakXSqpCpJVWvWrMkhVDMzK5o8E9RKNn3WUGc278I7mfSZNxExh+Ru2ruXlCEipkTEgIgYUFnZ6JWJZma2DcgzQc0FukvqJqkNyUUQM0rKvAQcBpA+I2hHkscimJnZdi63BJU+mnkCcDfJI49vjohnJV0kaWRa7LvAtyQ9RfJMlZPCNwc0MzNy/qFuRMwEZpZMm5QZXggMzjMGMzMrT2V3JwnbjlzQofEyTarnjeapx8y2Kt8s1szMCskJyszMCskJyszMCskJyszMCskJyszMCskJyszMCskJyszMCsm/gzIzy4t/y/exOEFZs9t74h+bpZ7lOzZLNfSc1rNZ6llw4oJmqcfMmsZdfGZmVkhuQZk10aJ99/vYdey3eFEzRGLbm+21F8AtKDMzKyQnKDMzKyQnKDMzKySfgzLbnjXHZdDb4CXQRbsStbmU23lUJyizMrStfoGaZTlBmdnH0lxXmN38XxubpR5fKbnt8DkoMzMrJCcoMzMrpFwTlKQRkpZIWiZpYh3zfyFpfvpaKun1POMxM7Pykds5KEkVwGTgCGAlMFfSjIhYWFMmIr6TKX8G0DeveMzMrLzk2YI6EFgWEc9HxAbgRmBUA+XHAjfkGI+ZmZWRPBPUnsCKzPjKdNpmJO0FdAP+lGM8ZmZWRvJMUKpjWtRT9gTg1oj4oM6KpFMlVUmqWrNmTbMFaGZmxZVngloJdMmMdwZW1VP2BBro3ouIKRExICIGVFZWNmOIZmZWVHkmqLlAd0ndJLUhSUIzSgtJ2gfYFZiTYyxmZlZmcruKLyI2SpoA3A1UANdExLOSLgKqIqImWY0FboyI+rr/ml3z3Sbm6x+7jp7dujZDJP4Vvplte3K91VFEzARmlkybVDJ+QZ4xmJlZefKdJMzMrJCcoMzMrJCcoMzMrJCcoMzMrJCcoMzMrJCcoMzMrJCcoMzMrJCcoMzMrJCcoMzMrJCcoMzMrJCcoMzMrJCcoMzMrJCcoMzMrJCcoMzMrJCcoMzMrJCcoMzMrJCcoMzMrJCcoMzMrJCcoMzMrJCcoMzMrJByTVCSRkhaImmZpIn1lPmapIWSnpV0fZ7xmJlZ+WidV8WSKoDJwBHASmCupBkRsTBTpjvwA2BwRLwm6VN5xWNmZuUlzxbUgcCyiHg+IjYANwKjSsp8C5gcEa8BRMTfcozHzMzKSJ4Jak9gRWZ8ZTot63PA5yQ9IukxSSNyjMfMzMpIbl18gOqYFnWsvzswDOgMPCTpgIh4fZOKpFOBUwG6du3a/JGamVnh5NmCWgl0yYx3BlbVUeb3EfF+RLwALCFJWJuIiCkRMSAiBlRWVuYWsJmZFUeeCWou0F1SN0ltgBOAGSVl7gAOBZC0O0mX3/M5xmRmZmUitwQVERuBCcDdwCLg5oh4VtJFkkamxe4G/i5pIXA/8P2I+HteMZmZWfnI8xwUETETmFkybVJmOICz0peZmVkt30nCzMwKyQnKzMwKyQnKzMwKyQnKzMwKyQnKzMwKyQnKzMwKyQnKzMwKyQnKzMwKyQnKzMwKyQnKzMwKyQnKzMwKyQnKzMwKyQnKzMwKyQnKzMwKyQnKzMwKyQnKzMwKyQnKzMwKyQnKzMwKyQnKzMwKyQnKzMwKKdcEJWmEpCWSlkmaWMf8kyStkTQ/fZ2SZzxmZlY+WudVsaQKYDJwBLASmCtpRkQsLCl6U0RMyCsOMzMrT3m2oA4ElkXE8xGxAbgRGJXj+szMbBuSZ4LaE1iRGV+ZTiv1VUlPS7pVUpcc4zEzszKSZ4JSHdOiZPz/gL0johcwC5hWZ0XSqZKqJFWtWbOmmcM0M7MiyjNBrQSyLaLOwKpsgYj4e0S8l47+N9C/rooiYkpEDIiIAZWVlbkEa2ZmxZJngpoLdJfUTVIb4ARgRraApI6Z0ZHAohzjMTOzMpLbVXwRsVHSBOBuoAK4JiKelXQRUBURM4AzJY0ENgJrgZPyisfMzMpLbgkKICJmAjNLpk3KDP8A+EGeMZiZWXnynSTMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQmpSgJI2RtHM6fJ6k30nql29oZma2PWtqC+r8iFgn6QvAkST3zPtVfmGZmdn2rqkJ6oP079HAryLi90CbfEIyMzNreoJ6WdKvga8BMyW13YJlzczMtlhTk8zXSO6pNyIiXgd2A76fW1RmZrbda1KCioh3gL8BX0gnbQSeyysoMzOzpl7F9x/AOXx4Y9cdgOvyCsrMzKypXXxfIXle09sAEbEK2DmvoMzMzJqaoDZERJA+sl1S+/xCMjMza3qCujm9iu+Tkr4FzCJ5RLuZmVkumvTAwoj4maQjgDeBfYBJEXFvrpGZmdl2rdEEJakCuDsiDgeclMzMbKtotIsvIj4A3pHUYSvEY2ZmBjSxiw9YDyyQdC/plXwAEXFmLlGZmdl2r6kXSfwROB94EJiXeTVI0ghJSyQtkzSxgXLHSQpJA5oYj5mZbeOaepHENEltgM+lk5ZExPsNLZOeu5oMHAGsBOZKmhERC0vK7QycCTy+pcGbmdm2q6l3khhGcmujycBVwFJJhzSy2IHAsoh4PiI2ADcCo+oo90PgJyTdiGZmZkDTu/h+DgyPiKERcQjJM6F+0cgyewIrMuMr02m1JPUFukTEHxqqSNKpkqokVa1Zs6aJIZuZWTlraoLaISKW1IxExFKS+/E1RHVMi9qZUiuSJPfdxlYeEVMiYkBEDKisrGxiyGZmVs6aehVflaT/Baan4+No/CKJlUCXzHhnYFVmfGfgAGC2JIBPAzMkjYyIqibGZWZm26imJqh/Ab5NcjGDSK7mu6qRZeYC3SV1A14GTgC+XjMzIt4Adq8ZlzQb+J6Tk5mZQdMTVGvglxFxKdReode2oQUiYqOkCSQPOqwAromIZyVdBFRFxIyPEbeZmW3jmpqg7gMOB95Kx3cC7gEObmihiJgJzCyZNqmessOaGIuZmW0HmnqRxI4RUZOcSIfb5ROSmZlZ0xPU25L61Yykd3x4N5+QzMzMmt7F92/ALZJWkVwq3gk4PreozMxsu9dgC0rSQEmfjoi5wL7ATcBG4C7gha0Qn5mZbaca6+L7NbAhHT4IOJfkdkevAVNyjMvMzLZzjXXxVUTE2nT4eGBKRNwG3CZpfr6hmZnZ9qyxFlSFpJokdhjwp8y8pp6/MjMz22KNJZkbgAckvUpy1d5DAJI+C7yRc2xmZrYdazBBRcSPJN0HdATuiYiam722As7IOzgzM9t+NdpNFxGP1TFtaT7hmJmZJZr6Q10zM7OtygnKzMwKyQnKzMwKyQnKzMwKyQnKzMwKyQnKzMwKyQnKzMwKyQnKzMwKyQnKzMwKKdcEJWmEpCWSlkmaWMf80yQtkDRf0sOSeuQZj5mZlY/cEpSkCpJnRx0F9ADG1pGAro+InhHRB/gJcGle8ZiZWXnJswV1ILAsIp6PiA3AjcCobIGIeDMz2p7kcfJmZma5PtNpT2BFZnwl8PnSQpK+DZwFtAG+mGM8ZmZWRvJsQamOaZu1kCJickR8BjgHOK/OiqRTJVVJqlqzZk0zh2lmZkWUZ4JaCXTJjHcGVjVQ/kbg2LpmRMSUiBgQEQMqKyubMUQzMyuqPBPUXKC7pG6S2gAnADOyBSR1z4weDTyXYzxmZlZGcjsHFREbJU0A7gYqgGsi4llJFwFVETEDmCDpcOB94DXgxLziMTOz8pLnRRJExExgZsm0SZnhf81z/WZmVr58JwkzMyskJygzMyskJygzMyskJygzMyskJygzMyskJygzMyskJygzMyskJygzMyskJygzMyskJygzMyskJygzMyskJygzMyskJygzMyskJygzMyskJygzMyskJygzMyskJygzMyskJygzMyskJygzMyskJygzMyukXBOUpBGSlkhaJmliHfPPkrRQ0tOS7pO0V57xmJlZ+cgtQUmqACYDRwE9gLGSepQUexIYEBG9gFuBn+QVj5mZlZc8W1AHAssi4vmI2ADcCIzKFoiI+yPinXT0MaBzjvGYmVkZyTNB7QmsyIyvTKfV52TgzhzjMTOzMtI6x7pVx7Sos6D0T8AAYGg9808FTgXo2rVrc8VnZmYFlmcLaiXQJTPeGVhVWkjS4cC/AyMj4r26KoqIKRExICIGVFZW5hKsmZkVS54Jai7QXVI3SW2AE4AZ2QKS+gK/JklOf8sxFjMzKzO5JaiI2AhMAO4GFgE3R8Szki6SNDIt9lPgE8AtkuZLmlFPdWZmtp3J8xwUETETmFkybVJm+PA8129mZuXLd5IwM7NCcoIyM7NCcoIyM7NCcoIyM7NCcoIyM7NCcoIyM7NCcoIyM7NCcoIyM7NCcoIyM7NCcoIyM7NCcoIyM7NCcoIyM7NCcoIyM7NCcoIyM7NCcoIyM7NCcoIyM7NCcoIyM7NCcoIyM7NCcoIyM7NCcoIyM7NCyjVBSRohaYmkZZIm1jH/EEl/lrRR0nF5xmJmZuUltwQlqQKYDBwF9ADGSupRUuwl4CTg+rziMDOz8tQ6x7oPBJZFxPMAkm4ERgELawpExPJ0XnWOcZiZWRnKs4tvT2BFZnxlOs3MzKxReSYo1TEtPlJF0qmSqiRVrVmz5mOGZWZm5SDPBLUS6JIZ7wys+igVRcSUiBgQEQMqKyubJTgzMyu2PBPUXKC7pG6S2gAnADNyXJ+ZmW1DcktQEbERmADcDSwCbo6IZyVdJGkkgKSBklYCY4BfS3o2r3jMzKy85HkVHxExE5hZMm1SZnguSdefmZnZJnwnCTMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzKyQnKDMzK6RcE5SkEZKWSFomaWId89tKuimd/7ikvfOMx8zMykduCUpSBTAZOAroAYyV1KOk2MnAaxHxWeAXwI/zisfMzMpLni2oA4FlEfF8RGwAbgRGlZQZBUxLh28FDpOkHGMyM7MykWeC2hNYkRlfmU6rs0xEbATeAP4hx5jMzKxMtM6x7rpaQvERyiDpVODUdPQtSUs+ZmzNonmaes80pdDuwKsNFSjtO/3ICtSAbb5ICrSNC7R9wftw3rwP12uvphTKM0GtBLpkxjsDq+ops1JSa6ADsLa0ooiYAkzJKc7Ck1QVEQNaOo5tmbdxvrx987ctbuM8u/jmAt0ldZPUBjgBmFFSZgZwYjp8HPCniNisBWVmZtuf3FpQEbFR0gTgbqACuCYinpV0EVAVETOA/wWmS1pG0nI6Ia94zMysvOTZxUdEzARmlkyblBleD4zJM4ZtxHbbvbkVeRvny9s3f9vcNpZ71MzMrIh8qyMzMyskJ6gyJGmqpOMaKXOSpE5bK6Yik/Q/ddzFpLRMndtU0t6Svv4R1tnoZ2SWF0mzJZX9FX1OUNuukwAnKCAiTomIhR9x8b2BLU5Q27r0VmZba125niu34nKCakaSvinpaUlPSZouaS9J96XT7pPUNS03VdKvJN0v6XlJQyVdI2mRpKmZ+t6S9HNJf06Xr6xjnf0lPSBpnqS7JXVMj9wHAL+VNF/STnWV22obpplIOlvSmenwLyT9KR0+TNJ1koZLmpNur1skfSKdX3s0KelkSUvTaf8t6crMKg6R9Gj6mdS0fi4BhqTb8TuSKiT9VNLc9HP9f2m9knSlpIWS/gh8amttl+aWthoXS5qWvsdbJbWTtFzSJEkPA2MkfUbSXek+9ZCkfdPlx0h6Jv0/eDCdtr+kJ9Lt+LSk7ul6nsms93uSLkiHZ0v6T0kPAP8qqVLSbel2nytpcAtsmhYn6Y50ez8r6dR0f5yabu8Fkr5TUr5V+jle3FIxfywR4VczvID9gSXA7un4bsD/ASem4/8M3JEOTyW5N6FI7kf4JtCT5IBhHtAnLRfAuHR4EnBlZvnjgB2AR4HKdPrxJJfzA8wGBqTD9ZYrpxcwCLglHX4IeCJ9b/8BnAM8CLRP558DTMpuC5IW5fL0s9khrSO7TW9JP4MeJPeRBBgG/CETw6nAeelwW6AK6AaMBu4l+UlFJ+B14LiW3mYfcTvvne57g9Pxa4Dvpdvu7Ey5+4Du6fDnSX7HCLAA2DMd/mT694rMvtwG2CldzzOZ+r4HXJD5zK7KzLse+EI63BVY1NLbqYU+m93SvzuR3F6iP3BvZn7N9p6d/r/cAPx7S8f9UV9uOjefLwK3RsSrABGxVtJBJF9cANOBn2TK/19EhKQFwCsRsQBA0rMk/7jzgWrgprT8dcDvSta5D3AAcK+S249UAKvriK2p5YpuHtBf0s7Ae8CfSRLPEJIfffcAHknfYxtgTsnyBwIPRMRaAEm3AJ/LzL8jIqqBhZL2qCeG4UCvTAurA9AdOAS4ISI+AFbVtO7K2IqIeCQdvg44Mx2+CSBtnR4M3KIPb33TNv37CDBV0s18uM/OAf5dUmfgdxHxnBq/Zc5NmeHDgR6ZZXaRtHNErNvid1bezpT0lXS4C8l+/o+SrgD+CNyTKftr4OaI+NFWjrHZOEE1H1HHfQRLZOe/l/6tzgzXjNf3udR1L8NnI+KgJsTWlHKFFhHvS1oOjCdpET4NHAp8BniB5EhybANVNPaNmP0c6isr4IyIuHuTidKXaPzzLyel76Vm/O30byvg9Yjos9mCEadJ+jxwNDBfUp+IuF7S4+m0uyWdAixl09MMO5ZU9XZmuBVwUES8+9HeTvmTNIwkUR8UEe9Imk1yUNAbOBL4NvA1kt4aSP5HDpX080h+c1p2fA6q+dwHfE3SPwBI2o1kB6m5O8Y44OEtrLMVSVceJCfqS5dfAlSmLTUk7SBp/3TeOmDnJpQrNw+SdAU9SNJFdxpJa/MxYLCkzwKk50w+V7LsE8BQSbsqOfH+1SasL7sdIbkzyr9I2iFdz+cktU/jOSE9J9CRJHGWs641+wswlpJ9LyLeBF6QNAZqz8H1Toc/ExGPR/Kj/FeBLpL+EXg+Ii4nae32Al4BPiXpHyS1BY5pIJ57gAk1I5I2S4zbgQ4kz897Jz3fN4jkBrGtIuI24HygX6b8/5LcKOEWlemFJk5QzSQingV+BDwg6SngUpJukfGSnga+AfzrFlb7NrC/pHkkXYgXlaxzA0kC+3G6zvkk3S6QnFO5WtJ8ki69+sqVm4eAjsCciHgFWA88FBFrSK5cvCHd3o8B+2ZR8ep2AAAK40lEQVQXjIiXgf8EHgdmAQtJHvHSkKeBjekJ/+8A/5Mu9+f0BP+vSVq8twPPkZx/+RXwwMd/qy1qEXBiui13I3lPpcYBJ6f71LN8+Ly3n6Yn7J8hSdxPkZz3fCbdH/cFro2I90n26ceBPwCLG4jnTGBAeoHFQpIDk+3NXUDr9DP5Ick+vicwO92uU4EfZBeIiEtJusKnSyq773vfSaLAJL0VEZ9o6Ti2JZI+ERFvpUeUt5NcLHJ7S8dVJJL2Jrkw5IAWDsW2c2WXUc0+pgvSo81nSM5b3dHC8ZhZPdyCAubNm9e5VatW91RXV+9Lcz5jzMysfEWrVq0WV1dXD+/fv//KlgigLE+cNbdWrVrd8+lPf7r7HnvsoVat3Kg0M6uurtbq1av3efHFF58YOXLksTNmzHhia8fgb2Ogurp63z322KO1k5OZWaJVq1Z07NixVZs2bToCE0aOHDlkq8ewtVdYUG45mZmVaNWqFemPo18Fhm719W/tFZoVRUVFBX369OGAAw5gzJgxvPPOOx+7zqqqKs4888x6569atYrjjvNNzpvT8uXLOeCA5ILD2bNnc8wxDf2cqrxcfvnl7LfffowbN66lQ9nI5j+kzp3PQdVh74l/bNb6ll9ydLPW91Ft3LiR1q0L+pFf0KGZ62vs502w0047MX/+fADGjRvH1VdfzVlnnVU7v+Z+YFvSuh4wYAADBtT/lINOnTpx6623Nrm+PPWc1rNZ61tw4oItKv9Rtm9LWrTvfs1a336LFzVa5qqrruLOO++kW7duzbruQn8XZJTHnrEdOPbYY+nfvz/7778/U6YkT26+66676NevH7179+awww4D4K233mL8+PH07NmTXr16cdtttwHwiU98+HOpW2+9lZNOOgmAk046ibPOOotDDz2Uc845hyeeeIKDDz6Yvn37cvDBB7NkyRIAPvjgA773ve/V1nvFFVdw33338ZWvfKW23nvvvZfRo0ezLRoyZAjLli1j+fLl7Lfffpx++un069ePFStWcM8993DQQQfRr18/xowZw1tvvQXA3LlzOfjgg+nduzcHHngg69at2+QI/oEHHqBPnz706dOHvn37sm7duk2O9tevX1/7Wfbt25f7778fgKlTpzJ69GhGjBhB9+7dOfvss1tmo+SgdPtOnz69ydt2+fLlDBkyhH79+tGvXz8effTRFn43+TrttNN4/vnnGTlyJBdeeOFm+xLAT37yE3r27Env3r2ZOHEiAPPnz2fQoEH06tWLr3zlK7z22msADBs2jHPPPZehQ4fyy1/+kjVr1vDVr36VgQMHMnDgQB555JF6Y2kpxU+h24lrrrmG3XbbjXfffZeBAwcyatQovvWtb/Hggw/SrVs31q5dC8APf/hDOnTowIIFydFqzc7XkKVLlzJr1iwqKip48803efDBB2ndujWzZs3i3HPP5bbbbmPKlCm88MILPPnkk7Ru3Zq1a9ey66678u1vf5s1a9ZQWVnJb37zG8aPH5/rdmgJGzdu5M4772TEiBEALFmyhN/85jdcddVVvPrqq1x88cXMmjWL9u3b8+Mf/5hLL72UiRMncvzxx3PTTTcxcOBA3nzzTXbaaadN6v3Zz37G5MmTGTx4MG+99RY77rhpD8nkyZMBWLBgAYsXL2b48OEsXboUSL5knnzySdq2bcs+++zDGWecQZcuXbbC1shfzfa96KKLGD16dJO37ac+9SnuvfdedtxxR5577jnGjh1LVVVVS7+d3Fx99dXcdddd3H///YwfP36zfenOO+/kjjvu4PHHH6ddu3a13xHf/OY3ueKKKxg6dCiTJk3iwgsv5LLLLgPg9ddf54EHkpucfP3rX+c73/kOX/jCF3jppZc48sgjWbSo8Vbd1uQEVRCXX345t9+e3NBgxYoVTJkyhUMOOaS2ab/bbrsBMGvWLG688cba5XbddddG6x4zZgwVFcnz5d544w1OPPFEnnvuOSTx/vvv19Z72mmn1Tb7a9b3jW98g+uuu47x48czZ84crr322mZ6xy3v3XffpU+f5JZuQ4YM4eSTT2bVqlXstddeDBo0CIDHHnuMhQsXMnhw8vihDRs2cNBBB7FkyRI6duzIwIEDAdhll102q3/w4MGcddZZjBs3jtGjR9O5c+dN5j/88MOcccYZAOy7777stddetQnqsMMOo0OHpNuzR48evPjii9tMgqrZvn/4wx+2aNu+/fbbTJgwgfnz51NRUVG7rbYHde1Ls2bNYvz48bRr1w5I/mffeOMNXn/9dYYOTa5nOPHEExkzZkxtPccff3zt8KxZs1i48MPneL755pusW7eOnXfO3nqyZTlBFcDs2bOZNWsWc+bMoV27dgwbNozevXvXdr9lRUTNVTWbyE5bv37TGxe3b9++dvj888/n0EMP5fbbb2f58uUMGzaswXrHjx/Pl7/8ZXbccUfGjBlTFv3WTZU9B5WV3V4RwRFHHMENN9ywSZmnn366zu2VNXHiRI4++mhmzpzJoEGDmDVr1iatqIZ+JN+2bdva4YqKCjZu3Njo+ykXNdt3S7ftL37xC/bYYw+eeuopqqurN2uRbsvq2pfq+59tSHbfrq6uZs6cOZu1/IvE56AK4I033mDXXXelXbt2LF68mMcee4z33nuPBx54gBdeeAGgtvk+fPhwrrzyw4fA1nTx7bHHHixatIjq6urallh969pzzz2B5FxHjeHDh3P11VfXfhHWrK9Tp0506tSJiy++uPa81vZk0KBBPPLIIyxbtgyAd955h6VLl7LvvvuyatUq5s6dC8C6des2SyJ/+ctf6NmzJ+eccw4DBgxg8eJN74V6yCGH8Nvf/hZIumFfeukl9tlnn63wrophS7ftG2+8QceOHWnVqhXTp0/ngw8+aMnwt6q69qXhw4dzzTXX1F59unbtWjp06MCuu+7KQw89BMD06dNrW1OlSr9L6jpYa2lOUAUwYsQINm7cSK9evTj//PMZNGgQlZWVTJkyhdGjR9O7d+/apvl5553Ha6+9xgEHHEDv3r1rT6xfcsklHHPMMXzxi1+kY8f6n+Z+9tln84Mf/IDBgwdv8g9+yimn0LVrV3r16kXv3r25/vrra+eNGzeOLl260KNHj5y2QHFVVlYydepUxo4dS69evRg0aBCLFy+mTZs23HTTTZxxxhn07t2bI444YrOW62WXXVb7Oe20004cddRRm8w//fTT+eCDD+jZsyfHH388U6dO3aTltK3b0m17+umnM23aNAYNGsTSpUs3aQ1s6+ral0aMGMHIkSMZMGAAffr04Wc/+xkA06ZN4/vf/z69evVi/vz5TJo0qc46L7/8cqqqqujVqxc9evTg6quv3ppvqUl8Lz5g3rx50b9//5YOo7AmTJhA3759Ofnkk1s6FDPbyubNm8eFF174U2DDjBkzztua6952TihYLvr370/79u35+c9/3tKhmNl2xgnKGjRv3ryWDsHMtlM+B2VmZoXkBJWI6urqlo7BzKxQqqurG/w5RN6coIBWrVotXr16dbWTlJlZorq6mtWrV1evX7/+VVroQa4+BwVUV1cPX7FixZzVq1d33tIfvpmZbYsigvXr16+dPn36dGAX4JmtHYMTFNC/f/+VI0eO3A84C9gL8LX3ZmaJXYA3gZu39or9O6iMkSNHtgU6AW1aOhYzs4LYCPx1xowZb2/tFTtBmZlZIfkiCTMzKyQnKDMzKyQnKDMzK6T/D+AwG6NGX3p0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "label='Hypertensive disease '\n",
    "asklabel='Hypertensive disease '\n",
    "Stats = pd.DataFrame(columns = ['Dataset','Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "\n",
    "\n",
    "result,result_labels,weighted,weighted_labels,blood,blood_labels,ask,ask_labels=prepareDataset(label,asklabel)\n",
    "res_feat=importance(result,result_labels)\n",
    "wei_feat=importance(weighted,weighted_labels)\n",
    "blood_feat=importance(blood,blood_labels)\n",
    "ask_feat=importance(ask,ask_labels)\n",
    "res_acc,res_scores=SVM(pd.DataFrame(result)[res_feat],result_labels,\"Result\")\n",
    "wei_acc,wei_scores=SVM(pd.DataFrame(weighted)[wei_feat],weighted_labels,\"Weighted\")\n",
    "blood_acc,blood_scores=SVM(pd.DataFrame(blood)[blood_feat],blood_labels,\"Blood\")\n",
    "ask_acc,ask_scores=SVM(pd.DataFrame(ask)[ask_feat],ask_labels,\"Ask\")\n",
    "print(\"Res: Accuracy: \" + str(res_acc)+\" # \"+ \"Scores: \"+str(res_scores))\n",
    "print(\"Wei: Accuracy: \" + str(wei_acc)+\" # \"+ \"Scores: \"+str(wei_scores))\n",
    "print(\"Bld: Accuracy: \" + str(blood_acc)+\" # \"+ \"Scores: \"+str(blood_scores))\n",
    "print(\"Ask: Accuracy: \" + str(ask_acc)+\" # \"+ \"Scores: \"+str(ask_scores))\n",
    "Stats=Stats.append({'Dataset':\"Complete\",'Accuracy':res_acc,'Precision':res_scores[0],'Recall':res_scores[1],'FScore':res_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Weighted\",'Accuracy':wei_acc,'Precision':wei_scores[0],'Recall':wei_scores[1],'FScore':wei_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Blood\",'Accuracy':blood_acc,'Precision':blood_scores[0],'Recall':blood_scores[1],'FScore':blood_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"AskAPatient\",'Accuracy':ask_acc,'Precision':ask_scores[0],'Recall':ask_scores[1],'FScore':ask_scores[2]},ignore_index=True)\n",
    "#Stats.to_excel('SVMresult_Stats'+label+'.xlsx') \n",
    "\n",
    "plotResult(label+\" SVM With Smote\",Stats,Stats,Stats,Stats,0,1,2,3)\n",
    "\n",
    "import os.path\n",
    "if not os.path.exists('SVM'+'.xlsx'):\n",
    "    writer = pd.ExcelWriter('SVM'+'.xlsx', engine = 'xlsxwriter')\n",
    "\n",
    "    writer.save()\n",
    "    writer.close()\n",
    "writer = pd.ExcelWriter('SVM'+'.xlsx', engine='openpyxl')\n",
    "book = load_workbook('SVM'+'.xlsx')\n",
    "writer.book = book\n",
    "writer.sheets = dict((ws.title, ws) for ws in book.worksheets)\n",
    "\n",
    "Stats.to_excel(writer, sheet_name=label)\n",
    "writer.save()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 834, 1: 723})\n",
      "Counter({1: 80, 0: 50})\n",
      "Counter({1: 274, 0: 188})\n",
      "Counter({0: 608, 1: 148})\n",
      "Res: Accuracy: 0.7008547008547008 # Scores: (0.7057175312381674, 0.6985745614035088, 0.697400750032329, None)\n",
      "Wei: Accuracy: 0.7692307692307693 # Scores: (0.8783783783783784, 0.5909090909090909, 0.5846153846153846, None)\n",
      "Bld: Accuracy: 0.7050359712230215 # Scores: (0.6891483516483516, 0.6521883289124668, 0.6570379731600168, None)\n",
      "Ask: Accuracy: 0.8414096916299559 # Scores: (0.9203539823008849, 0.5135135135135135, 0.48304655870445345, None)\n"
     ]
    }
   ],
   "source": [
    "label='Hypertensive disease '\n",
    "asklabel='Hypertensive disease '\n",
    "Stats = pd.DataFrame(columns = ['Dataset','Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "\n",
    "\n",
    "result,result_labels,weighted,weighted_labels,blood,blood_labels,ask,ask_labels=prepareDatasetNoSmote(label,asklabel)\n",
    "res_acc,res_scores=SVM(result,result_labels,\"Result\")\n",
    "wei_acc,wei_scores=SVM(weighted,weighted_labels,\"Weighted\")\n",
    "blood_acc,blood_scores=SVM(blood,blood_labels,\"Blood\")\n",
    "ask_acc,ask_scores=SVM(ask,ask_labels,\"Ask\")\n",
    "print(\"Res: Accuracy: \" + str(res_acc)+\" # \"+ \"Scores: \"+str(res_scores))\n",
    "print(\"Wei: Accuracy: \" + str(wei_acc)+\" # \"+ \"Scores: \"+str(wei_scores))\n",
    "print(\"Bld: Accuracy: \" + str(blood_acc)+\" # \"+ \"Scores: \"+str(blood_scores))\n",
    "print(\"Ask: Accuracy: \" + str(ask_acc)+\" # \"+ \"Scores: \"+str(ask_scores))\n",
    "Stats=Stats.append({'Dataset':\"Complete\",'Accuracy':res_acc,'Precision':res_scores[0],'Recall':res_scores[1],'FScore':res_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Weighted\",'Accuracy':wei_acc,'Precision':wei_scores[0],'Recall':wei_scores[1],'FScore':wei_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Blood\",'Accuracy':blood_acc,'Precision':blood_scores[0],'Recall':blood_scores[1],'FScore':blood_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"AskAPatient\",'Accuracy':ask_acc,'Precision':ask_scores[0],'Recall':ask_scores[1],'FScore':ask_scores[2]},ignore_index=True)\n",
    "Stats.to_excel('SVMresult_Stats'+label+'smoteless.xlsx') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 834, 1: 723})\n",
      "Counter({1: 80, 0: 50})\n",
      "Counter({1: 274, 0: 188})\n",
      "Counter({0: 608, 1: 148})\n",
      "Res: Accuracy: 0.6538461538461539 # Scores: (0.6583358848744643, 0.6512061403508772, 0.6488179055806715, None)\n",
      "Wei: Accuracy: 0.7692307692307693 # Scores: (0.8783783783783784, 0.5909090909090909, 0.5846153846153846, None)\n",
      "Bld: Accuracy: 0.697841726618705 # Scores: (0.7097902097902098, 0.6193633952254642, 0.6132750397456279, None)\n",
      "Ask: Accuracy: 0.8281938325991189 # Scores: (0.5874811463046757, 0.5165007112375534, 0.49906637243252416, None)\n"
     ]
    }
   ],
   "source": [
    "label='Hypertensive disease '\n",
    "asklabel='Hypertensive disease '\n",
    "Stats = pd.DataFrame(columns = ['Dataset','Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "\n",
    "\n",
    "result,result_labels,weighted,weighted_labels,blood,blood_labels,ask,ask_labels=prepareDatasetNoSmote(label,asklabel)\n",
    "res_feat=importance(result,result_labels)\n",
    "wei_feat=importance(weighted,weighted_labels)\n",
    "blood_feat=importance(blood,blood_labels)\n",
    "ask_feat=importance(ask,ask_labels)\n",
    "res_acc,res_scores=SVM(pd.DataFrame(result)[res_feat],result_labels,\"Result\")\n",
    "wei_acc,wei_scores=SVM(pd.DataFrame(weighted)[wei_feat],weighted_labels,\"Weighted\")\n",
    "blood_acc,blood_scores=SVM(pd.DataFrame(blood)[blood_feat],blood_labels,\"Blood\")\n",
    "ask_acc,ask_scores=SVM(pd.DataFrame(ask)[ask_feat],ask_labels,\"Ask\")\n",
    "print(\"Res: Accuracy: \" + str(res_acc)+\" # \"+ \"Scores: \"+str(res_scores))\n",
    "print(\"Wei: Accuracy: \" + str(wei_acc)+\" # \"+ \"Scores: \"+str(wei_scores))\n",
    "print(\"Bld: Accuracy: \" + str(blood_acc)+\" # \"+ \"Scores: \"+str(blood_scores))\n",
    "print(\"Ask: Accuracy: \" + str(ask_acc)+\" # \"+ \"Scores: \"+str(ask_scores))\n",
    "Stats=Stats.append({'Dataset':\"Complete\",'Accuracy':res_acc,'Precision':res_scores[0],'Recall':res_scores[1],'FScore':res_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Weighted\",'Accuracy':wei_acc,'Precision':wei_scores[0],'Recall':wei_scores[1],'FScore':wei_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Blood\",'Accuracy':blood_acc,'Precision':blood_scores[0],'Recall':blood_scores[1],'FScore':blood_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"AskAPatient\",'Accuracy':ask_acc,'Precision':ask_scores[0],'Recall':ask_scores[1],'FScore':ask_scores[2]},ignore_index=True)\n",
    "Stats.to_excel('SVMresult_Stats'+label+'importancesmoteless.xlsx') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM 10-Fold Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM10Fold(result,result_labels,DataSet):\n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn.metrics import f1_score\n",
    "    from collections import Counter\n",
    "    kf = KFold(n_splits=10)\n",
    "\n",
    "    accuracy=[]\n",
    "\n",
    "    scores_rf=[]\n",
    "    print(Counter(result_labels))\n",
    "    count = 1\n",
    "    for train_index, test_index in kf.split(result):\n",
    "        X_train, X_test, Y_train, Y_test = result[train_index], result[test_index], result_labels[train_index],result_labels[test_index]\n",
    "        clf = SVC(gamma='auto')\n",
    "        clf.fit(X_train, Y_train)\n",
    "        pred=clf.predict(X_test)\n",
    "        accuracy.append(accuracy_score(Y_test, pred))\n",
    "        scores_rf.append(precision_recall_fscore_support(Y_test,pred, average='macro'))\n",
    "        \n",
    "        #print(str(count)+DataSet)\n",
    "        #print(f1_score(Y_test, pred, average='micro'))\n",
    "        count+=1\n",
    "        #print (pred)\n",
    "        #print(classification_report(Y_test,pred,labels=[0,1]))\n",
    "    accuracy = np.mean(accuracy,axis=0)   \n",
    "    return accuracy,average(scores_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM10FoldNoSmote(result,result_labels,DataSet):\n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn.metrics import f1_score\n",
    "    from collections import Counter\n",
    "    kf = KFold(n_splits=10)\n",
    "    accuracy=[]\n",
    "\n",
    "    scores_rf=[]\n",
    "    print(Counter(result_labels))\n",
    "    count = 1\n",
    "    for train_index, test_index in kf.split(result):\n",
    "        X_train, X_test, Y_train, Y_test = result.iloc[train_index], result.iloc[test_index], result_labels.iloc[train_index],result_labels.iloc[test_index]\n",
    "        clf = SVC(gamma='auto')\n",
    "        clf.fit(X_train, Y_train)\n",
    "        pred=clf.predict(X_test)\n",
    "        accuracy.append(accuracy_score(Y_test, pred))\n",
    "        scores_rf.append(precision_recall_fscore_support(Y_test,pred, average='macro'))\n",
    "        \n",
    "        #print(str(count)+DataSet)\n",
    "        #print(f1_score(Y_test, pred, average='micro'))\n",
    "        count+=1\n",
    "        #print (pred)\n",
    "        #print(classification_report(Y_test,pred,labels=[0,1]))\n",
    "    accuracy = np.mean(accuracy,axis=0)   \n",
    "    return accuracy,average(scores_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM 10-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 834, 0: 834})\n",
      "Counter({1: 80, 0: 80})\n",
      "Counter({1: 274, 0: 274})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 608, 1: 608})\n",
      "Res: Accuracy: 0.663101507827718 # Scores: (0.6725628520390469, 0.6761496377396277, 0.6544962946953283)\n",
      "Wei: Accuracy: 0.71875 # Scores: (0.6280934343434343, 0.5980259324009325, 0.5963648583247174)\n",
      "Bld: Accuracy: 0.721010101010101 # Scores: (0.6759517266538593, 0.6614434322260432, 0.6522931172587427)\n",
      "Ask: Accuracy: 0.7445874542744886 # Scores: (0.611755069769185, 0.647484170480776, 0.585458690933904)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "Stats = pd.DataFrame(columns = ['Dataset','Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "\n",
    "label='Hypertensive disease '\n",
    "asklabel='Hypertensive disease '\n",
    "result,result_labels,weighted,weighted_labels,blood,blood_labels,ask,ask_labels=prepareDataset(label,asklabel)\n",
    "res_acc,res_scores=SVM10Fold(result,result_labels,\"Result\")\n",
    "wei_acc,wei_scores=SVM10Fold(weighted,weighted_labels,\"Weighted\")\n",
    "blood_acc,blood_scores=SVM10Fold(blood,blood_labels,\"Blood\")\n",
    "ask_acc,ask_scores=SVM10Fold(ask,ask_labels,\"Ask\")\n",
    "print(\"Res: Accuracy: \" + str(res_acc)+\" # \"+ \"Scores: \"+str(res_scores))\n",
    "print(\"Wei: Accuracy: \" + str(wei_acc)+\" # \"+ \"Scores: \"+str(wei_scores))\n",
    "print(\"Bld: Accuracy: \" + str(blood_acc)+\" # \"+ \"Scores: \"+str(blood_scores))\n",
    "print(\"Ask: Accuracy: \" + str(ask_acc)+\" # \"+ \"Scores: \"+str(ask_scores))\n",
    "Stats=Stats.append({'Dataset':\"Complete\",'Accuracy':res_acc,'Precision':res_scores[0],'Recall':res_scores[1],'FScore':res_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Weighted\",'Accuracy':wei_acc,'Precision':wei_scores[0],'Recall':wei_scores[1],'FScore':wei_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Blood\",'Accuracy':blood_acc,'Precision':blood_scores[0],'Recall':blood_scores[1],'FScore':blood_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"AskAPatient\",'Accuracy':ask_acc,'Precision':ask_scores[0],'Recall':ask_scores[1],'FScore':ask_scores[2]},ignore_index=True)\n",
    "Stats.to_excel('SVMresult_Stats10Fold'+label+'.xlsx') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 834, 1: 723})\n",
      "Counter({1: 80, 0: 50})\n",
      "Counter({1: 274, 0: 188})\n",
      "Counter({0: 608, 1: 148})\n",
      "Res: Accuracy: 0.6455004135649297 # Scores: (0.6500318744362645, 0.6541848478293254, 0.6292282548625472)\n",
      "Wei: Accuracy: 0.6615384615384615 # Scores: (0.7013419913419913, 0.6378571428571428, 0.5933210253798489)\n",
      "Bld: Accuracy: 0.7140610545790935 # Scores: (0.7208260334375953, 0.6703590938075548, 0.66206667853428)\n",
      "Ask: Accuracy: 0.8039298245614035 # Scores: (0.40196491228070175, 0.5, 0.4449683813348536)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "Stats = pd.DataFrame(columns = ['Dataset','Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "\n",
    "label='Hypertensive disease '\n",
    "asklabel='Hypertensive disease '\n",
    "result,result_labels,weighted,weighted_labels,blood,blood_labels,ask,ask_labels=prepareDatasetNoSmote(label,asklabel)\n",
    "res_acc,res_scores=SVM10FoldNoSmote(result,result_labels,\"Result\")\n",
    "wei_acc,wei_scores=SVM10FoldNoSmote(weighted,weighted_labels,\"Weighted\")\n",
    "blood_acc,blood_scores=SVM10FoldNoSmote(blood,blood_labels,\"Blood\")\n",
    "ask_acc,ask_scores=SVM10FoldNoSmote(ask,ask_labels,\"Ask\")\n",
    "print(\"Res: Accuracy: \" + str(res_acc)+\" # \"+ \"Scores: \"+str(res_scores))\n",
    "print(\"Wei: Accuracy: \" + str(wei_acc)+\" # \"+ \"Scores: \"+str(wei_scores))\n",
    "print(\"Bld: Accuracy: \" + str(blood_acc)+\" # \"+ \"Scores: \"+str(blood_scores))\n",
    "print(\"Ask: Accuracy: \" + str(ask_acc)+\" # \"+ \"Scores: \"+str(ask_scores))\n",
    "Stats=Stats.append({'Dataset':\"Complete\",'Accuracy':res_acc,'Precision':res_scores[0],'Recall':res_scores[1],'FScore':res_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Weighted\",'Accuracy':wei_acc,'Precision':wei_scores[0],'Recall':wei_scores[1],'FScore':wei_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Blood\",'Accuracy':blood_acc,'Precision':blood_scores[0],'Recall':blood_scores[1],'FScore':blood_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"AskAPatient\",'Accuracy':ask_acc,'Precision':ask_scores[0],'Recall':ask_scores[1],'FScore':ask_scores[2]},ignore_index=True)\n",
    "Stats.to_excel('SVMresult_Stats10Fold'+label+'smoteless.xlsx') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NB(result,result_labels,DataSet):\n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn.metrics import f1_score\n",
    "    from collections import Counter\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(result, result_labels, test_size=0.30, random_state=42)\n",
    "    print(Counter(result_labels))\n",
    "    clf = GaussianNB()\n",
    "    clf.fit(X_train, Y_train)\n",
    "    pred=clf.predict(X_test)\n",
    "    accuracy=(accuracy_score(Y_test, pred))\n",
    "    #print (accuracy)\n",
    "    scores_rf=(precision_recall_fscore_support(Y_test,pred, average='macro'))\n",
    "    #print(DataSet)\n",
    "    #print (pred)\n",
    "    #print(classification_report(Y_test,pred,labels=[0,1,2]))\n",
    "        \n",
    "    return accuracy,scores_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 834, 0: 834})\n",
      "Counter({1: 80, 0: 80})\n",
      "Counter({1: 274, 0: 274})\n",
      "Counter({0: 608, 1: 608})\n",
      "Res: Accuracy: 0.6287425149700598 # Scores: (0.6315254512928932, 0.6288844621513944, 0.626921721862789, None)\n",
      "Wei: Accuracy: 0.7291666666666666 # Scores: (0.7901098901098902, 0.7291666666666667, 0.7141548327989006, None)\n",
      "Bld: Accuracy: 0.6181818181818182 # Scores: (0.6357142857142857, 0.6259946949602122, 0.6135831381733021, None)\n",
      "Ask: Accuracy: 0.7835616438356164 # Scores: (0.8007984155474408, 0.7945454545454546, 0.7832427515804824, None)\n"
     ]
    }
   ],
   "source": [
    "label='Hypertensive disease '\n",
    "asklabel='Hypertensive disease '\n",
    "Stats = pd.DataFrame(columns = ['Dataset','Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "\n",
    "\n",
    "result,result_labels,weighted,weighted_labels,blood,blood_labels,ask,ask_labels=prepareDataset(label,asklabel)\n",
    "res_acc,res_scores=NB(result,result_labels,\"Result\")\n",
    "wei_acc,wei_scores=NB(weighted,weighted_labels,\"Weighted\")\n",
    "blood_acc,blood_scores=NB(blood,blood_labels,\"Blood\")\n",
    "ask_acc,ask_scores=NB(ask,ask_labels,\"Ask\")\n",
    "print(\"Res: Accuracy: \" + str(res_acc)+\" # \"+ \"Scores: \"+str(res_scores))\n",
    "print(\"Wei: Accuracy: \" + str(wei_acc)+\" # \"+ \"Scores: \"+str(wei_scores))\n",
    "print(\"Bld: Accuracy: \" + str(blood_acc)+\" # \"+ \"Scores: \"+str(blood_scores))\n",
    "print(\"Ask: Accuracy: \" + str(ask_acc)+\" # \"+ \"Scores: \"+str(ask_scores))\n",
    "Stats=Stats.append({'Dataset':\"Complete\",'Accuracy':res_acc,'Precision':res_scores[0],'Recall':res_scores[1],'FScore':res_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Weighted\",'Accuracy':wei_acc,'Precision':wei_scores[0],'Recall':wei_scores[1],'FScore':wei_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Blood\",'Accuracy':blood_acc,'Precision':blood_scores[0],'Recall':blood_scores[1],'FScore':blood_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"AskAPatient\",'Accuracy':ask_acc,'Precision':ask_scores[0],'Recall':ask_scores[1],'FScore':ask_scores[2]},ignore_index=True)\n",
    "Stats.to_excel('NBresult_Stats'+label+'.xlsx') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 834, 0: 834})\n",
      "Counter({1: 80, 0: 80})\n",
      "Counter({1: 274, 0: 274})\n",
      "Counter({0: 608, 1: 608})\n",
      "Res: Accuracy: 0.7005988023952096 # Scores: (0.7024743560886202, 0.7006932270916335, 0.6999664633172571, None)\n",
      "Wei: Accuracy: 0.6041666666666666 # Scores: (0.6043478260869566, 0.6041666666666667, 0.6039947894051236, None)\n",
      "Bld: Accuracy: 0.7090909090909091 # Scores: (0.7106270238445687, 0.7108753315649867, 0.7090802233323539, None)\n",
      "Ask: Accuracy: 0.7342465753424657 # Scores: (0.7854922456787593, 0.7532575757575758, 0.7299575162650924, None)\n"
     ]
    }
   ],
   "source": [
    "label='Hypertensive disease '\n",
    "asklabel='Hypertensive disease '\n",
    "Stats = pd.DataFrame(columns = ['Dataset','Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "\n",
    "result,result_labels,weighted,weighted_labels,blood,blood_labels,ask,ask_labels=prepareDataset(label,asklabel)\n",
    "res_feat=importance(result,result_labels)\n",
    "wei_feat=importance(weighted,weighted_labels)\n",
    "blood_feat=importance(blood,blood_labels)\n",
    "ask_feat=importance(ask,ask_labels)\n",
    "res_acc,res_scores=NB(pd.DataFrame(result)[res_feat],result_labels,\"Result\")\n",
    "wei_acc,wei_scores=NB(pd.DataFrame(weighted)[wei_feat],weighted_labels,\"Weighted\")\n",
    "blood_acc,blood_scores=NB(pd.DataFrame(blood)[blood_feat],blood_labels,\"Blood\")\n",
    "ask_acc,ask_scores=NB(pd.DataFrame(ask)[ask_feat],ask_labels,\"Ask\")\n",
    "print(\"Res: Accuracy: \" + str(res_acc)+\" # \"+ \"Scores: \"+str(res_scores))\n",
    "print(\"Wei: Accuracy: \" + str(wei_acc)+\" # \"+ \"Scores: \"+str(wei_scores))\n",
    "print(\"Bld: Accuracy: \" + str(blood_acc)+\" # \"+ \"Scores: \"+str(blood_scores))\n",
    "print(\"Ask: Accuracy: \" + str(ask_acc)+\" # \"+ \"Scores: \"+str(ask_scores))\n",
    "Stats=Stats.append({'Dataset':\"Complete\",'Accuracy':res_acc,'Precision':res_scores[0],'Recall':res_scores[1],'FScore':res_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Weighted\",'Accuracy':wei_acc,'Precision':wei_scores[0],'Recall':wei_scores[1],'FScore':wei_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Blood\",'Accuracy':blood_acc,'Precision':blood_scores[0],'Recall':blood_scores[1],'FScore':blood_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"AskAPatient\",'Accuracy':ask_acc,'Precision':ask_scores[0],'Recall':ask_scores[1],'FScore':ask_scores[2]},ignore_index=True)\n",
    "Stats.to_excel('NBresult_Stats'+label+'importance.xlsx') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 834, 1: 723})\n",
      "Counter({1: 80, 0: 50})\n",
      "Counter({1: 274, 0: 188})\n",
      "Counter({0: 608, 1: 148})\n",
      "Res: Accuracy: 0.5961538461538461 # Scores: (0.5965403562665068, 0.5941885964912281, 0.5927155519742143, None)\n",
      "Wei: Accuracy: 0.7692307692307693 # Scores: (0.7607142857142857, 0.6185064935064934, 0.6285714285714286, None)\n",
      "Bld: Accuracy: 0.6546762589928058 # Scores: (0.6555900621118013, 0.6661140583554377, 0.6494325346784363, None)\n",
      "Ask: Accuracy: 0.7268722466960352 # Scores: (0.5522242604907132, 0.5647937411095305, 0.5552957532861476, None)\n"
     ]
    }
   ],
   "source": [
    "label='Hypertensive disease '\n",
    "asklabel='Hypertensive disease '\n",
    "Stats = pd.DataFrame(columns = ['Dataset','Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "\n",
    "\n",
    "result,result_labels,weighted,weighted_labels,blood,blood_labels,ask,ask_labels=prepareDatasetNoSmote(label,asklabel)\n",
    "res_acc,res_scores=NB(result,result_labels,\"Result\")\n",
    "wei_acc,wei_scores=NB(weighted,weighted_labels,\"Weighted\")\n",
    "blood_acc,blood_scores=NB(blood,blood_labels,\"Blood\")\n",
    "ask_acc,ask_scores=NB(ask,ask_labels,\"Ask\")\n",
    "print(\"Res: Accuracy: \" + str(res_acc)+\" # \"+ \"Scores: \"+str(res_scores))\n",
    "print(\"Wei: Accuracy: \" + str(wei_acc)+\" # \"+ \"Scores: \"+str(wei_scores))\n",
    "print(\"Bld: Accuracy: \" + str(blood_acc)+\" # \"+ \"Scores: \"+str(blood_scores))\n",
    "print(\"Ask: Accuracy: \" + str(ask_acc)+\" # \"+ \"Scores: \"+str(ask_scores))\n",
    "Stats=Stats.append({'Dataset':\"Complete\",'Accuracy':res_acc,'Precision':res_scores[0],'Recall':res_scores[1],'FScore':res_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Weighted\",'Accuracy':wei_acc,'Precision':wei_scores[0],'Recall':wei_scores[1],'FScore':wei_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Blood\",'Accuracy':blood_acc,'Precision':blood_scores[0],'Recall':blood_scores[1],'FScore':blood_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"AskAPatient\",'Accuracy':ask_acc,'Precision':ask_scores[0],'Recall':ask_scores[1],'FScore':ask_scores[2]},ignore_index=True)\n",
    "Stats.to_excel('NBresult_Stats'+label+'smoteless.xlsx') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py:197: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 834, 1: 723})\n",
      "Counter({1: 80, 0: 50})\n",
      "Counter({1: 274, 0: 188})\n",
      "Counter({0: 608, 1: 148})\n",
      "Res: Accuracy: 0.6602564102564102 # Scores: (0.6664379192360481, 0.6573464912280702, 0.6543847507930685, None)\n",
      "Wei: Accuracy: 0.6410256410256411 # Scores: (0.5568181818181819, 0.5568181818181819, 0.5568181818181819, None)\n",
      "Bld: Accuracy: 0.7338129496402878 # Scores: (0.7273351648351649, 0.6829133510167993, 0.690497683095625, None)\n",
      "Ask: Accuracy: 0.748898678414097 # Scores: (0.6051587301587301, 0.6432432432432433, 0.6146010186757216, None)\n"
     ]
    }
   ],
   "source": [
    "label='Hypertensive disease '\n",
    "asklabel='Hypertensive disease '\n",
    "Stats = pd.DataFrame(columns = ['Dataset','Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "\n",
    "\n",
    "result,result_labels,weighted,weighted_labels,blood,blood_labels,ask,ask_labels=prepareDatasetNoSmote(label,asklabel)\n",
    "res_feat=importance(result,result_labels)\n",
    "wei_feat=importance(weighted,weighted_labels)\n",
    "blood_feat=importance(blood,blood_labels)\n",
    "ask_feat=importance(ask,ask_labels)\n",
    "res_acc,res_scores=NB(pd.DataFrame(result)[res_feat],result_labels,\"Result\")\n",
    "wei_acc,wei_scores=NB(pd.DataFrame(weighted)[wei_feat],weighted_labels,\"Weighted\")\n",
    "blood_acc,blood_scores=NB(pd.DataFrame(blood)[blood_feat],blood_labels,\"Blood\")\n",
    "ask_acc,ask_scores=NB(pd.DataFrame(ask)[ask_feat],ask_labels,\"Ask\")\n",
    "print(\"Res: Accuracy: \" + str(res_acc)+\" # \"+ \"Scores: \"+str(res_scores))\n",
    "print(\"Wei: Accuracy: \" + str(wei_acc)+\" # \"+ \"Scores: \"+str(wei_scores))\n",
    "print(\"Bld: Accuracy: \" + str(blood_acc)+\" # \"+ \"Scores: \"+str(blood_scores))\n",
    "print(\"Ask: Accuracy: \" + str(ask_acc)+\" # \"+ \"Scores: \"+str(ask_scores))\n",
    "Stats=Stats.append({'Dataset':\"Complete\",'Accuracy':res_acc,'Precision':res_scores[0],'Recall':res_scores[1],'FScore':res_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Weighted\",'Accuracy':wei_acc,'Precision':wei_scores[0],'Recall':wei_scores[1],'FScore':wei_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Blood\",'Accuracy':blood_acc,'Precision':blood_scores[0],'Recall':blood_scores[1],'FScore':blood_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"AskAPatient\",'Accuracy':ask_acc,'Precision':ask_scores[0],'Recall':ask_scores[1],'FScore':ask_scores[2]},ignore_index=True)\n",
    "Stats.to_excel('NBresult_Stats'+label+'importancesmoteless.xlsx') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes 10-Fold Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NB10Fold(result,result_labels,DataSet):\n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn.metrics import f1_score\n",
    "    from collections import Counter\n",
    "    kf = KFold(n_splits=10)\n",
    "\n",
    "    accuracy=[]\n",
    "\n",
    "    scores_rf=[]\n",
    "    print(Counter(result_labels))\n",
    "    count = 1\n",
    "    for train_index, test_index in kf.split(result):\n",
    "        X_train, X_test, Y_train, Y_test = result[train_index], result[test_index], result_labels[train_index],result_labels[test_index]\n",
    "        clf = GaussianNB()\n",
    "        clf.fit(X_train, Y_train)\n",
    "        pred=clf.predict(X_test)\n",
    "        accuracy.append(accuracy_score(Y_test, pred))\n",
    "        scores_rf.append(precision_recall_fscore_support(Y_test,pred, average='macro'))\n",
    "        \n",
    "        #print(str(count)+DataSet)\n",
    "        #print(f1_score(Y_test, pred, average='micro'))\n",
    "        count+=1\n",
    "        #print (pred)\n",
    "        #print(classification_report(Y_test,pred,labels=[0,1]))\n",
    "    accuracy = np.mean(accuracy,axis=0)   \n",
    "    return accuracy,average(scores_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NB10FoldNoSmote(result,result_labels,DataSet):\n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn.metrics import f1_score\n",
    "    from collections import Counter\n",
    "    kf = KFold(n_splits=10)\n",
    "\n",
    "    accuracy=[]\n",
    "\n",
    "    scores_rf=[]\n",
    "    print(Counter(result_labels))\n",
    "    count = 1\n",
    "    for train_index, test_index in kf.split(result):\n",
    "        X_train, X_test, Y_train, Y_test = result.iloc[train_index], result.iloc[test_index], result_labels.iloc[train_index],result_labels.iloc[test_index]\n",
    "        clf = GaussianNB()\n",
    "        clf.fit(X_train, Y_train)\n",
    "        pred=clf.predict(X_test)\n",
    "        accuracy.append(accuracy_score(Y_test, pred))\n",
    "        scores_rf.append(precision_recall_fscore_support(Y_test,pred, average='macro'))\n",
    "        \n",
    "        #print(str(count)+DataSet)\n",
    "        #print(f1_score(Y_test, pred, average='micro'))\n",
    "        count+=1\n",
    "        #print (pred)\n",
    "        #print(classification_report(Y_test,pred,labels=[0,1]))\n",
    "    accuracy = np.mean(accuracy,axis=0)   \n",
    "    return accuracy,average(scores_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes 10-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 834, 0: 834})\n",
      "Counter({1: 80, 0: 80})\n",
      "Counter({1: 274, 0: 274})\n",
      "Counter({0: 608, 1: 608})\n",
      "Res: Accuracy: 0.6234579034701682 # Scores: (0.6318923229476339, 0.6370319013726595, 0.616576877324976)\n",
      "Wei: Accuracy: 0.64375 # Scores: (0.6608391608391608, 0.6215792540792541, 0.6038139775601076)\n",
      "Bld: Accuracy: 0.6396296296296295 # Scores: (0.6491948105664025, 0.6535476874467434, 0.6193045413380015)\n",
      "Ask: Accuracy: 0.7949193876168541 # Scores: (0.631730492224762, 0.6596810810067578, 0.6086214410048887)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "Stats = pd.DataFrame(columns = ['Dataset','Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "\n",
    "label='Hypertensive disease '\n",
    "asklabel='Hypertensive disease '\n",
    "result,result_labels,weighted,weighted_labels,blood,blood_labels,ask,ask_labels=prepareDataset(label,asklabel)\n",
    "res_acc,res_scores=NB10Fold(result,result_labels,\"Result\")\n",
    "wei_acc,wei_scores=NB10Fold(weighted,weighted_labels,\"Weighted\")\n",
    "blood_acc,blood_scores=NB10Fold(blood,blood_labels,\"Blood\")\n",
    "ask_acc,ask_scores=NB10Fold(ask,ask_labels,\"Ask\")\n",
    "print(\"Res: Accuracy: \" + str(res_acc)+\" # \"+ \"Scores: \"+str(res_scores))\n",
    "print(\"Wei: Accuracy: \" + str(wei_acc)+\" # \"+ \"Scores: \"+str(wei_scores))\n",
    "print(\"Bld: Accuracy: \" + str(blood_acc)+\" # \"+ \"Scores: \"+str(blood_scores))\n",
    "print(\"Ask: Accuracy: \" + str(ask_acc)+\" # \"+ \"Scores: \"+str(ask_scores))\n",
    "Stats=Stats.append({'Dataset':\"Complete\",'Accuracy':res_acc,'Precision':res_scores[0],'Recall':res_scores[1],'FScore':res_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Weighted\",'Accuracy':wei_acc,'Precision':wei_scores[0],'Recall':wei_scores[1],'FScore':wei_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Blood\",'Accuracy':blood_acc,'Precision':blood_scores[0],'Recall':blood_scores[1],'FScore':blood_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"AskAPatient\",'Accuracy':ask_acc,'Precision':ask_scores[0],'Recall':ask_scores[1],'FScore':ask_scores[2]},ignore_index=True)\n",
    "Stats.to_excel('NBresult_Stats10Fold'+label+'.xlsx') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 834, 1: 723})\n",
      "Counter({1: 80, 0: 50})\n",
      "Counter({1: 274, 0: 188})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 608, 1: 148})\n",
      "Res: Accuracy: 0.6255831265508685 # Scores: (0.6182491779207331, 0.6213850965425614, 0.6065100342360275)\n",
      "Wei: Accuracy: 0.6615384615384615 # Scores: (0.6634271284271284, 0.637815934065934, 0.6191472090001502)\n",
      "Bld: Accuracy: 0.5820536540240517 # Scores: (0.6295602920081275, 0.6227280945618786, 0.5750316306946438)\n",
      "Ask: Accuracy: 0.7247719298245615 # Scores: (0.5558101469813034, 0.5342128228029481, 0.5139073914356317)\n"
     ]
    }
   ],
   "source": [
    "Stats = pd.DataFrame(columns = ['Dataset','Accuracy', 'Precision' , 'Recall','FScore'])\n",
    "\n",
    "label='Hypertensive disease '\n",
    "asklabel='Hypertensive disease '\n",
    "result,result_labels,weighted,weighted_labels,blood,blood_labels,ask,ask_labels=prepareDatasetNoSmote(label,asklabel)\n",
    "res_acc,res_scores=NB10FoldNoSmote(result,result_labels,\"Result\")\n",
    "wei_acc,wei_scores=NB10FoldNoSmote(weighted,weighted_labels,\"Weighted\")\n",
    "blood_acc,blood_scores=NB10FoldNoSmote(blood,blood_labels,\"Blood\")\n",
    "ask_acc,ask_scores=NB10FoldNoSmote(ask,ask_labels,\"Ask\")\n",
    "print(\"Res: Accuracy: \" + str(res_acc)+\" # \"+ \"Scores: \"+str(res_scores))\n",
    "print(\"Wei: Accuracy: \" + str(wei_acc)+\" # \"+ \"Scores: \"+str(wei_scores))\n",
    "print(\"Bld: Accuracy: \" + str(blood_acc)+\" # \"+ \"Scores: \"+str(blood_scores))\n",
    "print(\"Ask: Accuracy: \" + str(ask_acc)+\" # \"+ \"Scores: \"+str(ask_scores))\n",
    "Stats=Stats.append({'Dataset':\"Complete\",'Accuracy':res_acc,'Precision':res_scores[0],'Recall':res_scores[1],'FScore':res_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Weighted\",'Accuracy':wei_acc,'Precision':wei_scores[0],'Recall':wei_scores[1],'FScore':wei_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"Blood\",'Accuracy':blood_acc,'Precision':blood_scores[0],'Recall':blood_scores[1],'FScore':blood_scores[2]},ignore_index=True)\n",
    "Stats=Stats.append({'Dataset':\"AskAPatient\",'Accuracy':ask_acc,'Precision':ask_scores[0],'Recall':ask_scores[1],'FScore':ask_scores[2]},ignore_index=True)\n",
    "Stats.to_excel('NBresult_Stats10Fold'+label+'smoteless.xlsx') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from collections import Counter\\nfrom imblearn.over_sampling import SMOTENC\\nsm = SMOTENC(random_state=42, categorical_features=[0, 1,3])\\nX_res, y_res = sm.fit_resample(result, result_labels)\\nprint(Counter(result_labels))\\nprint(Counter(y_res))\\nprint(X_res)\\nprint(y_res)\\nprint(result_labels)'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from collections import Counter\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "sm = SMOTENC(random_state=42, categorical_features=[0, 1,3])\n",
    "X_res, y_res = sm.fit_resample(result, result_labels)\n",
    "print(Counter(result_labels))\n",
    "print(Counter(y_res))\n",
    "print(X_res)\n",
    "print(y_res)\n",
    "print(result_labels)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    834\n",
      "1    723\n",
      "Name: Hypertensive disease , dtype: int64\n",
      "1    80\n",
      "0    50\n",
      "Name: Hypertensive disease , dtype: int64\n",
      "1    274\n",
      "0    188\n",
      "Name: Hypertensive disease , dtype: int64\n",
      "0    608\n",
      "1    148\n",
      "Name: Hypertensive disease , dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(result_labels.value_counts())\n",
    "print(weighted_labels.value_counts())\n",
    "print(blood_labels.value_counts())\n",
    "print(ask_labels.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    834\n",
      "1    723\n",
      "Name: Hypertensive disease , dtype: int64\n",
      "1    80\n",
      "0    50\n",
      "Name: Hypertensive disease , dtype: int64\n",
      "1    274\n",
      "0    188\n",
      "Name: Hypertensive disease , dtype: int64\n",
      "0    608\n",
      "1    148\n",
      "Name: Hypertensive disease , dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(result_labels.value_counts())\n",
    "print(weighted_labels.value_counts())\n",
    "print(blood_labels.value_counts())\n",
    "print(ask_labels.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6182491779207331"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_scores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>DrugFamily</th>\n",
       "      <th>Drug</th>\n",
       "      <th>ADRCount</th>\n",
       "      <th>MentalCount</th>\n",
       "      <th>DieaseCount</th>\n",
       "      <th>Pain</th>\n",
       "      <th>Fatigue</th>\n",
       "      <th>Vertigo</th>\n",
       "      <th>...</th>\n",
       "      <th>Headache</th>\n",
       "      <th>Anxiety</th>\n",
       "      <th>Mental Suffering</th>\n",
       "      <th>Pvc</th>\n",
       "      <th>MUNGAN SYNDROME</th>\n",
       "      <th>MICROCEPHALY , EPILEPSY , AND DIABETES SYNDROME</th>\n",
       "      <th>Brachial Amyotrophic Diplegia</th>\n",
       "      <th>Infection</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>Sinusitis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>42.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>32.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>42.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>42.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>46.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>53.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>42.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>53.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>53.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>68.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>42.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>71.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527</th>\n",
       "      <td>42.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1528</th>\n",
       "      <td>47.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1529</th>\n",
       "      <td>49.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1530</th>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1531</th>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1532</th>\n",
       "      <td>59.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1533</th>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1534</th>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535</th>\n",
       "      <td>58.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1536</th>\n",
       "      <td>54.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1537</th>\n",
       "      <td>59.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1538</th>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1539</th>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1540</th>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1541</th>\n",
       "      <td>66.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542</th>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1543</th>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1544</th>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1545</th>\n",
       "      <td>42.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1546</th>\n",
       "      <td>42.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1547</th>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1548</th>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1549</th>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1550</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551</th>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1552</th>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1553</th>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1554</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1555</th>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1556</th>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1557 rows  21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age Gender  DrugFamily  Drug  ADRCount  MentalCount  DieaseCount  Pain  \\\n",
       "0     42.0      0           2     0         0            0            1     0   \n",
       "1     40.0      1           2     0         1            1            2     0   \n",
       "2     42.0      0           2     0         0            0            1     0   \n",
       "3     26.0      0           2     0         0            0            1     0   \n",
       "4     70.0      0           2     0         0            0            0     0   \n",
       "5     63.0      1           2     0         1            0            1     0   \n",
       "6     45.0      0           2     0         0            1            2     0   \n",
       "7     42.0      1           2     0         1            0            2     1   \n",
       "8     32.0      1           2     0         1            0            2     1   \n",
       "9     21.0      0           2     0         0            1            2     0   \n",
       "10    42.0      1           2     0         1            0            2     1   \n",
       "11    42.0      0           2     0         0            0            1     0   \n",
       "12    31.0      0           2     0         1            0            1     1   \n",
       "13    25.0      0           2     0         0            1            1     0   \n",
       "14    42.0      1           2     0         1            0            2     1   \n",
       "15    40.0      0           2     0         1            1            1     0   \n",
       "16    46.0      1           2     0         0            0            1     0   \n",
       "17    26.0      1           2     0         0            0            2     0   \n",
       "18    53.0      1           2     0         0            0            1     0   \n",
       "19    42.0      1           2     0         0            0            1     0   \n",
       "20    63.0      1           2     0         1            1            1     1   \n",
       "21    53.0      1           2     0         1            0            1     0   \n",
       "22    53.0      1           2     0         1            0            1     0   \n",
       "23    70.0      0           2     0         0            0            0     0   \n",
       "24    42.0      0           2     0         1            0            1     0   \n",
       "25    42.0      0           2     0         0            0            1     0   \n",
       "26    68.0      0           2     0         0            0            0     0   \n",
       "27    42.0      1           2     0         0            0            2     0   \n",
       "28    47.0      1           2     0         1            0            0     0   \n",
       "29    71.0      0           2     0         1            0            1     0   \n",
       "...    ...    ...         ...   ...       ...          ...          ...   ...   \n",
       "1527  42.0      1           1     5         0            0            1     0   \n",
       "1528  47.0      0           1     5         0            1            1     0   \n",
       "1529  49.0      1           1     5         1            0            2     0   \n",
       "1530  29.0      1           1     5         1            1            2     0   \n",
       "1531  29.0      0           1     5         0            1            1     0   \n",
       "1532  59.0      1           1     5         1            1            1     0   \n",
       "1533  61.0      0           1     5         1            0            2     1   \n",
       "1534  42.0      0           1     5         0            1            1     0   \n",
       "1535  58.0      1           1     5         0            0            0     0   \n",
       "1536  54.0      1           1     5         1            0            1     0   \n",
       "1537  59.0      0           1     5         1            1            1     1   \n",
       "1538  42.0      0           1     5         1            0            2     1   \n",
       "1539  42.0      0           1     5         1            1            2     0   \n",
       "1540  42.0      0           1     5         1            0            1     0   \n",
       "1541  66.0      1           1     5         1            0            1     0   \n",
       "1542  42.0      0           1     5         1            0            1     1   \n",
       "1543  42.0      0           1     5         0            1            1     0   \n",
       "1544  23.0      0           1     5         1            0            2     0   \n",
       "1545  42.0      1           1     5         0            1            1     0   \n",
       "1546  42.0      1           1     5         0            0            0     0   \n",
       "1547  25.0      1           1     5         0            1            1     0   \n",
       "1548  28.0      0           1     5         1            2            2     1   \n",
       "1549  28.0      0           1     5         1            0            2     0   \n",
       "1550  15.0      0           1     5         0            0            0     0   \n",
       "1551  42.0      0           1     5         0            1            1     0   \n",
       "1552  27.0      0           1     5         1            1            1     1   \n",
       "1553  38.0      1           1     5         1            0            0     1   \n",
       "1554  50.0      0           1     5         1            0            0     0   \n",
       "1555  42.0      0           1     5         1            1            1     0   \n",
       "1556  42.0      0           1     5         1            1            1     0   \n",
       "\n",
       "      Fatigue  Vertigo  ...  Headache  Anxiety  Mental Suffering  Pvc  \\\n",
       "0           0        0  ...         0        0                 0    0   \n",
       "1           0        0  ...         0        0                 0    0   \n",
       "2           0        0  ...         0        0                 0    0   \n",
       "3           0        0  ...         0        0                 0    0   \n",
       "4           0        0  ...         0        0                 0    0   \n",
       "5           0        0  ...         0        0                 0    0   \n",
       "6           0        0  ...         0        0                 1    0   \n",
       "7           1        0  ...         0        0                 0    0   \n",
       "8           0        0  ...         0        0                 0    0   \n",
       "9           0        0  ...         0        0                 0    0   \n",
       "10          0        0  ...         1        0                 0    1   \n",
       "11          0        0  ...         0        0                 0    0   \n",
       "12          0        0  ...         0        0                 0    0   \n",
       "13          0        0  ...         0        0                 1    0   \n",
       "14          0        0  ...         1        0                 0    0   \n",
       "15          1        0  ...         0        0                 1    0   \n",
       "16          0        0  ...         0        0                 0    0   \n",
       "17          0        0  ...         0        0                 0    0   \n",
       "18          0        0  ...         0        0                 0    0   \n",
       "19          0        0  ...         0        0                 0    0   \n",
       "20          0        0  ...         0        0                 1    0   \n",
       "21          0        0  ...         0        0                 0    0   \n",
       "22          0        0  ...         0        0                 0    0   \n",
       "23          0        0  ...         0        0                 0    0   \n",
       "24          0        0  ...         0        0                 0    0   \n",
       "25          0        0  ...         0        0                 0    0   \n",
       "26          0        0  ...         0        0                 0    0   \n",
       "27          0        0  ...         0        0                 0    0   \n",
       "28          0        0  ...         0        0                 0    0   \n",
       "29          0        0  ...         0        0                 0    0   \n",
       "...       ...      ...  ...       ...      ...               ...  ...   \n",
       "1527        0        0  ...         0        0                 0    0   \n",
       "1528        0        0  ...         0        0                 0    0   \n",
       "1529        0        0  ...         0        0                 0    1   \n",
       "1530        1        0  ...         0        0                 0    0   \n",
       "1531        0        0  ...         0        1                 0    0   \n",
       "1532        0        0  ...         0        0                 0    0   \n",
       "1533        0        0  ...         0        0                 0    0   \n",
       "1534        0        0  ...         0        1                 0    0   \n",
       "1535        0        0  ...         0        0                 0    0   \n",
       "1536        0        0  ...         0        0                 0    0   \n",
       "1537        1        0  ...         0        0                 1    0   \n",
       "1538        0        0  ...         1        0                 0    0   \n",
       "1539        1        0  ...         0        0                 1    1   \n",
       "1540        1        0  ...         0        0                 0    0   \n",
       "1541        0        0  ...         0        0                 0    0   \n",
       "1542        0        0  ...         0        0                 0    0   \n",
       "1543        0        0  ...         0        0                 0    0   \n",
       "1544        0        0  ...         0        0                 0    0   \n",
       "1545        0        0  ...         0        0                 1    0   \n",
       "1546        0        0  ...         0        0                 0    0   \n",
       "1547        0        0  ...         0        0                 1    0   \n",
       "1548        0        0  ...         0        1                 0    0   \n",
       "1549        1        0  ...         0        0                 0    1   \n",
       "1550        0        0  ...         0        0                 0    0   \n",
       "1551        0        0  ...         0        0                 1    0   \n",
       "1552        0        0  ...         0        1                 0    0   \n",
       "1553        0        0  ...         0        0                 0    0   \n",
       "1554        1        0  ...         0        0                 0    0   \n",
       "1555        0        0  ...         0        0                 0    1   \n",
       "1556        0        0  ...         0        1                 0    0   \n",
       "\n",
       "      MUNGAN SYNDROME   MICROCEPHALY , EPILEPSY , AND DIABETES SYNDROME   \\\n",
       "0                    1                                                 0   \n",
       "1                    1                                                 0   \n",
       "2                    0                                                 0   \n",
       "3                    0                                                 0   \n",
       "4                    0                                                 0   \n",
       "5                    1                                                 0   \n",
       "6                    1                                                 0   \n",
       "7                    0                                                 0   \n",
       "8                    0                                                 0   \n",
       "9                    0                                                 0   \n",
       "10                   0                                                 0   \n",
       "11                   0                                                 0   \n",
       "12                   0                                                 0   \n",
       "13                   0                                                 0   \n",
       "14                   0                                                 0   \n",
       "15                   0                                                 0   \n",
       "16                   0                                                 0   \n",
       "17                   0                                                 0   \n",
       "18                   0                                                 0   \n",
       "19                   0                                                 0   \n",
       "20                   0                                                 0   \n",
       "21                   0                                                 0   \n",
       "22                   0                                                 0   \n",
       "23                   0                                                 0   \n",
       "24                   0                                                 0   \n",
       "25                   0                                                 1   \n",
       "26                   0                                                 0   \n",
       "27                   0                                                 0   \n",
       "28                   0                                                 0   \n",
       "29                   1                                                 0   \n",
       "...                ...                                               ...   \n",
       "1527                 0                                                 0   \n",
       "1528                 0                                                 0   \n",
       "1529                 1                                                 0   \n",
       "1530                 0                                                 0   \n",
       "1531                 1                                                 0   \n",
       "1532                 0                                                 1   \n",
       "1533                 0                                                 1   \n",
       "1534                 0                                                 0   \n",
       "1535                 0                                                 0   \n",
       "1536                 0                                                 0   \n",
       "1537                 0                                                 0   \n",
       "1538                 0                                                 0   \n",
       "1539                 1                                                 0   \n",
       "1540                 0                                                 0   \n",
       "1541                 0                                                 0   \n",
       "1542                 0                                                 0   \n",
       "1543                 0                                                 0   \n",
       "1544                 0                                                 0   \n",
       "1545                 0                                                 0   \n",
       "1546                 0                                                 0   \n",
       "1547                 0                                                 0   \n",
       "1548                 0                                                 1   \n",
       "1549                 0                                                 0   \n",
       "1550                 0                                                 0   \n",
       "1551                 0                                                 0   \n",
       "1552                 0                                                 0   \n",
       "1553                 0                                                 0   \n",
       "1554                 0                                                 0   \n",
       "1555                 0                                                 0   \n",
       "1556                 0                                                 0   \n",
       "\n",
       "      Brachial Amyotrophic Diplegia   Infection  Diabetes  Sinusitis   \n",
       "0                                  0          0         0           0  \n",
       "1                                  0          0         1           0  \n",
       "2                                  0          0         0           0  \n",
       "3                                  0          0         0           0  \n",
       "4                                  0          0         0           0  \n",
       "5                                  0          0         0           0  \n",
       "6                                  0          0         0           0  \n",
       "7                                  0          0         0           1  \n",
       "8                                  0          0         0           0  \n",
       "9                                  0          0         0           0  \n",
       "10                                 0          0         0           0  \n",
       "11                                 0          0         0           0  \n",
       "12                                 0          0         0           0  \n",
       "13                                 0          0         0           0  \n",
       "14                                 0          0         1           0  \n",
       "15                                 0          0         0           0  \n",
       "16                                 0          0         0           0  \n",
       "17                                 0          0         0           0  \n",
       "18                                 0          0         0           0  \n",
       "19                                 0          0         0           0  \n",
       "20                                 0          0         0           0  \n",
       "21                                 0          0         0           0  \n",
       "22                                 0          0         0           0  \n",
       "23                                 0          0         0           0  \n",
       "24                                 0          0         0           0  \n",
       "25                                 0          0         0           0  \n",
       "26                                 0          0         0           0  \n",
       "27                                 0          0         1           0  \n",
       "28                                 0          0         0           0  \n",
       "29                                 0          0         0           0  \n",
       "...                              ...        ...       ...         ...  \n",
       "1527                               0          0         0           0  \n",
       "1528                               0          0         0           0  \n",
       "1529                               0          0         0           0  \n",
       "1530                               1          1         0           0  \n",
       "1531                               0          0         0           0  \n",
       "1532                               0          0         0           0  \n",
       "1533                               1          0         0           0  \n",
       "1534                               0          0         0           0  \n",
       "1535                               0          0         0           0  \n",
       "1536                               0          0         0           0  \n",
       "1537                               1          0         0           0  \n",
       "1538                               0          0         0           1  \n",
       "1539                               0          0         0           0  \n",
       "1540                               0          0         0           0  \n",
       "1541                               0          0         0           0  \n",
       "1542                               1          0         0           0  \n",
       "1543                               0          0         0           0  \n",
       "1544                               0          0         0           0  \n",
       "1545                               0          0         0           0  \n",
       "1546                               0          0         0           0  \n",
       "1547                               0          0         0           0  \n",
       "1548                               0          0         0           0  \n",
       "1549                               0          0         0           0  \n",
       "1550                               0          0         0           0  \n",
       "1551                               0          0         1           0  \n",
       "1552                               0          0         0           0  \n",
       "1553                               0          0         0           0  \n",
       "1554                               0          0         0           0  \n",
       "1555                               0          0         0           0  \n",
       "1556                               0          0         0           0  \n",
       "\n",
       "[1557 rows x 21 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6615384615384615"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7247719298245615"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6182491779207331, 0.6213850965425614, 0.6065100342360275)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6634271284271284, 0.637815934065934, 0.6191472090001502)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5558101469813034, 0.5342128228029481, 0.5139073914356317)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 287,
   "position": {
    "height": "309px",
    "left": "1104px",
    "right": "20px",
    "top": "102px",
    "width": "649px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
